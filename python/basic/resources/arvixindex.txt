<!DOCTYPE HTML>
<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Arxiv Sanity Preserver</title>

<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML">
</script>

<!-- CSS -->
<link rel="stylesheet" type="text/css" href="/static/style.css">

<!-- Favicon -->
<link rel="shortcut icon" type="image/png" href="/static/favicon.png" />

<!-- JS -->
<script src="/static/jquery-1.8.3.min.js"></script>
<script src="/static/d3.min.js"></script>
<script src="/static/as-common.js"></script>

<!-- Google Analytics JS -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-3698471-25', 'auto');
  ga('send', 'pageview');

</script>

<script>

// passed in from flask as json
var tweets = [];
var papers = [{"abstract": "Modern neural network training relies heavily on data augmentation for\nimproved generalization. After the initial success of label-preserving\naugmentations, there has been a recent surge of interest in label-perturbing\napproaches, which combine features and labels across training samples to smooth\nthe learned decision surface. In this paper, we propose a new augmentation\nmethod that leverages the first and second moments extracted and re-injected by\nfeature normalization. We replace the moments of the learned features of one\ntraining image by those of another, and also interpolate the target labels. As\nour approach is fast, operates entirely in feature space, and mixes different\nsignals than prior methods, one can effectively combine it with existing\naugmentation methods. We demonstrate its efficacy across benchmark data sets in\ncomputer vision, speech, and natural language processing, where it consistently\nimproves the generalization performance of highly competitive baseline\nnetworks.", "authors": ["Boyi Li", "Felix Wu", "Ser-Nam Lim", "Serge Belongie", "Kilian Q. Weinberger"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.11102v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11102v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11102v1", "published_time": "2/25/2020", "rawpid": "2002.11102", "tags": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "title": "On Feature Normalization and Data Augmentation"}, {"abstract": "In many applications, data is collected in batches, some of which are corrupt\nor even adversarial. Recent work derived optimal robust algorithms for\nestimating discrete distributions in this setting. We consider a general\nframework of robust learning from batches, and determine the limits of both\nclassification and distribution estimation over arbitrary, including\ncontinuous, domains. Building on these results, we derive the first robust\nagnostic computationally-efficient learning algorithms for piecewise-interval\nclassification, and for piecewise-polynomial, monotone, log-concave, and\ngaussian-mixture distribution estimation.", "authors": ["Ayush Jain", "Alon Orlitsky"], "category": "stat.ML", "comment": "First Draft", "img": "/static/thumbs/2002.11099v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11099v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11099v1", "published_time": "2/25/2020", "rawpid": "2002.11099", "tags": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "math.ST", "stat.TH"], "title": "A General Method for Robust Learning from Batches"}, {"abstract": "This paper is on highly accurate and highly efficient human pose estimation.\nRecent works based on Fully Convolutional Networks (FCNs) have demonstrated\nexcellent results for this difficult problem. While residual connections within\nFCNs have proved to be quintessential for achieving high accuracy, we\nre-analyze this design choice in the context of improving both the accuracy and\nthe efficiency over the state-of-the-art. In particular, we make the following\ncontributions: (a) We propose gated skip connections with per-channel learnable\nparameters to control the data flow for each channel within the module within\nthe macro-module. (b) We introduce a hybrid network that combines the HourGlass\nand U-Net architectures which minimizes the number of identity connections\nwithin the network and increases the performance for the same parameter budget.\nOur model achieves state-of-the-art results on the MPII and LSP datasets. In\naddition, with a reduction of 3x in model size and complexity, we show no\ndecrease in performance when compared to the original HourGlass network.", "authors": ["Adrian Bulat", "Jean Kossaifi", "Georgios Tzimiropoulos", "Maja Pantic"], "category": "cs.CV", "comment": "Accepted to FG 2020 (oral)", "img": "/static/thumbs/2002.11098v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11098v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11098v1", "published_time": "2/25/2020", "rawpid": "2002.11098", "tags": ["cs.CV"], "title": "Toward fast and accurate human pose estimation via soft-gated skip\n  connections"}, {"abstract": "Game-theoretic formulations of feature importance have become popular as a\nway to \"explain\" machine learning models. These methods define a cooperative\ngame between the features of a model and distribute influence among these input\nelements using some form of the game\u0027s unique Shapley values. Justification for\nthese methods rests on two pillars: their desirable mathematical properties,\nand their applicability to specific motivations for explanations. We show that\nmathematical problems arise when Shapley values are used for feature importance\nand that the solutions to mitigate these necessarily induce further complexity,\nsuch as the need for causal reasoning. We also draw on additional literature to\nargue that Shapley values do not provide explanations which suit human-centric\ngoals of explainability.", "authors": ["I. Elizabeth Kumar", "Suresh Venkatasubramanian", "Carlos Scheidegger", "Sorelle Friedler"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/2002.11097v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11097v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11097v1", "published_time": "2/25/2020", "rawpid": "2002.11097", "tags": ["cs.AI", "cs.LG", "stat.ML"], "title": "Problems with Shapley-value-based explanations as feature importance\n  measures"}, {"abstract": "Knowledge distillation introduced in the deep learning context is a method to\ntransfer knowledge from one architecture to another. In particular, when the\narchitectures are identical, this is called self-distillation. The idea is to\nfeed in predictions of the trained model as new target values for retraining\n(and iterate this loop possibly a few times). It has been empirically observed\nthat the self-distilled model often achieves higher accuracy on held out data.\nWhy this happens, however, has been a mystery: the self-distillation dynamics\ndoes not receive any new information about the task and solely evolves by\nlooping over training. To the best of our knowledge, there is no rigorous\nunderstanding of why this happens. This work provides the first theoretical\nanalysis of self-distillation. We focus on fitting a nonlinear function to\ntraining data, where the model space is Hilbert space and fitting is subject to\nL2 regularization in this function space. We show that self-distillation\niterations modify regularization by progressively limiting the number of basis\nfunctions that can be used to represent the solution. This implies (as we also\nverify empirically) that while a few rounds of self-distillation may reduce\nover-fitting, further rounds may lead to under-fitting and thus worse\nperformance.", "authors": ["Hossein Mobahi", "Mehrdad Farajtabar", "Peter L. Bartlett"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.05715v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.05715v2", "num_discussion": 0, "originally_published_time": "2/13/2020", "pid": "2002.05715v2", "published_time": "2/25/2020", "rawpid": "2002.05715", "tags": ["cs.LG", "stat.ML"], "title": "Self-Distillation Amplifies Regularization in Hilbert Space"}, {"abstract": "Given only data generated by a standard confounding graph with unobserved\nconfounder, the Average Treatment Effect (ATE) is not identifiable. To estimate\nthe ATE, a practitioner must then either (a) collect deconfounded data; (b) run\na clinical trial; or (c) elucidate further properties of the causal graph that\nmight render the ATE identifiable. In this paper, we consider the benefit of\nincorporating a (large) confounded observational dataset alongside a (small)\ndeconfounded observational dataset when estimating the ATE. Our theoretical\nresults show that the inclusion of confounded data can significantly reduce the\nquantity of deconfounded data required to estimate the ATE to within a desired\naccuracy level. Moreover, in some cases---say, genetics---we could imagine\nretrospectively selecting samples to deconfound. We demonstrate that by\nstrategically selecting these examples based upon the (already observed)\ntreatment and outcome, we can reduce our data dependence further. Our\ntheoretical and empirical results establish that the worst-case relative\nperformance of our approach (vs. a natural benchmark) is bounded while our\nbest-case gains are unbounded. Next, we demonstrate the benefits of selective\ndeconfounding using a large real-world dataset related to genetic mutation in\ncancer. Finally, we introduce an online version of the problem, proposing two\nadaptive heuristics.", "authors": ["Kyra Gan", "Andrew A. Li", "Zachary C. Lipton", "Sridhar Tayur"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/2002.11096v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11096v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11096v1", "published_time": "2/25/2020", "rawpid": "2002.11096", "tags": ["stat.ML", "cs.LG", "math.OC"], "title": "Causal Inference With Selectively-Deconfounded Data"}, {"abstract": "Although deep neural networks (NNs) have achievedstate-of-the-art accuracy in\nmany visual recognition tasks,the growing computational complexity and energy\ncon-sumption of networks remains an issue, especially for ap-plications on\nplatforms with limited resources and requir-ing real-time processing. Filter\npruning techniques haverecently shown promising results for the compression\nandacceleration of convolutional NNs (CNNs). However, thesetechniques involve\nnumerous steps and complex optimisa-tions because some only prune after\ntraining CNNs, whileothers prune from scratch during training by\nintegratingsparsity constraints or modifying the loss function.In this paper we\npropose a new Progressive GradientPruning (PGP) technique for iterative filter\npruning dur-ing training. In contrast to previous progressive\npruningtechniques, it relies on a novel filter selection criterion thatmeasures\nthe change in filter weights, uses a new hard andsoft pruning strategy and\neffectively adapts momentum ten-sors during the backward propagation pass.\nExperimentalresults obtained after training various CNNs on image datafor\nclassification, object detection and domain adaptationbenchmarks indicate that\nthe PGP technique can achievea better trade-off between classification accuracy\nand net-work (time and memory) complexity than PSFP and otherstate-of-the-art\nfilter pruning techniques.", "authors": ["Le Thanh Nguyen-Meidine", "Eric Granger", "Madhu Kiran", "Louis-Antoine Blais-Morin", "Marco Pedersoli"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1906.08746v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1906.08746v4", "num_discussion": 0, "originally_published_time": "6/20/2019", "pid": "1906.08746v4", "published_time": "2/25/2020", "rawpid": "1906.08746", "tags": ["cs.LG", "cs.CV", "stat.ML"], "title": "Progressive Gradient Pruning for Classification, Detection and\n  DomainAdaptation"}, {"abstract": "The SIGMORPHON 2019 shared task on cross-lingual transfer and contextual\nanalysis in morphology examined transfer learning of inflection between 100\nlanguage pairs, as well as contextual lemmatization and morphosyntactic\ndescription in 66 languages. The first task evolves past years\u0027 inflection\ntasks by examining transfer of morphological inflection knowledge from a\nhigh-resource language to a low-resource language. This year also presents a\nnew second challenge on lemmatization and morphological feature analysis in\ncontext. All submissions featured a neural component and built on either this\nyear\u0027s strong baselines or highly ranked systems from previous years\u0027 shared\ntasks. Every participating team improved in accuracy over the baselines for the\ninflection task (though not Levenshtein distance), and every team in the\ncontextual analysis task improved on both state-of-the-art neural and\nnon-neural baselines.", "authors": ["Arya D. McCarthy", "Ekaterina Vylomova", "Shijie Wu", "Chaitanya Malaviya", "Lawrence Wolf-Sonkin", "Garrett Nicolai", "Christo Kirov", "Miikka Silfverberg", "Sabrina J. Mielke", "Jeffrey Heinz", "Ryan Cotterell", "Mans Hulden"], "category": "cs.CL", "comment": "Presented at SIGMORPHON 2019", "img": "/static/thumbs/1910.11493v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1910.11493v2", "num_discussion": 0, "originally_published_time": "10/25/2019", "pid": "1910.11493v2", "published_time": "2/25/2020", "rawpid": "1910.11493", "tags": ["cs.CL"], "title": "The SIGMORPHON 2019 Shared Task: Morphological Analysis in Context and\n  Cross-Lingual Transfer for Inflection"}, {"abstract": "In this work, we propose a new solution for 3D human pose estimation in\nvideos. Instead of directly regressing the 3D joint locations, we draw\ninspiration from the human skeleton anatomy and decompose the task into bone\ndirection prediction and bone length prediction, from which the 3D joint\nlocations can be completely derived. Our motivation is the fact that the bone\nlengths of a human skeleton remain consistent across time. This promotes us to\ndevelop effective techniques to utilize global information across {\\it all} the\nframes in a video for high-accuracy bone length prediction. Moreover, for the\nbone direction prediction network, we propose a fully-convolutional propagating\narchitecture with long skip connections. Essentially, it predicts the\ndirections of different bones hierarchically without using any time-consuming\nmemory units (e.g. LSTM). A novel joint shift loss is further introduced to\nbridge the training of the bone length and bone direction prediction networks.\nFinally, we employ an implicit attention mechanism to feed the 2D keypoint\nvisibility scores into the model as extra guidance, which significantly\nmitigates the depth ambiguity in many challenging poses. Our full model\noutperforms the previous best results on Human3.6M and MPI-INF-3DHP datasets,\nwhere comprehensive evaluation validates the effectiveness of our model.", "authors": ["Tianlang Chen", "Chen Fang", "Xiaohui Shen", "Yiheng Zhu", "Zhili Chen", "Jiebo Luo"], "category": "cs.CV", "comment": "Code will be available soon", "img": "/static/thumbs/2002.10322v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10322v2", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10322v2", "published_time": "2/25/2020", "rawpid": "2002.10322", "tags": ["cs.CV"], "title": "Anatomy-aware 3D Human Pose Estimation in Videos"}, {"abstract": "How language-agnostic are current state-of-the-art NLP tools? Are there some\ntypes of language that are easier to model with current methods? In prior work\n(Cotterell et al., 2018) we attempted to address this question for language\nmodeling, and observed that recurrent neural network language models do not\nperform equally well over all the high-resource European languages found in the\nEuroparl corpus. We speculated that inflectional morphology may be the primary\nculprit for the discrepancy. In this paper, we extend these earlier experiments\nto cover 69 languages from 13 language families using a multilingual Bible\ncorpus. Methodologically, we introduce a new paired-sample multiplicative\nmixed-effects model to obtain language difficulty coefficients from\nat-least-pairwise parallel corpora. In other words, the model is aware of\ninter-sentence variation and can handle missing data. Exploiting this model, we\nshow that \"translationese\" is not any easier to model than natively written\nlanguage in a fair comparison. Trying to answer the question of what features\ndifficult languages have in common, we try and fail to reproduce our earlier\n(Cotterell et al., 2018) observation about morphological complexity and instead\nreveal far simpler statistics of the data that seem to drive complexity in a\nmuch larger sample.", "authors": ["Sabrina J. Mielke", "Ryan Cotterell", "Kyle Gorman", "Brian Roark", "Jason Eisner"], "category": "cs.CL", "comment": "Published at ACL 2019", "img": "/static/thumbs/1906.04726v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1906.04726v2", "num_discussion": 0, "originally_published_time": "6/11/2019", "pid": "1906.04726v2", "published_time": "2/25/2020", "rawpid": "1906.04726", "tags": ["cs.CL"], "title": "What Kind of Language Is Hard to Language-Model?"}, {"abstract": "Gender stereotypes are manifest in most of the world\u0027s languages and are\nconsequently propagated or amplified by NLP systems. Although research has\nfocused on mitigating gender stereotypes in English, the approaches that are\ncommonly employed produce ungrammatical sentences in morphologically rich\nlanguages. We present a novel approach for converting between\nmasculine-inflected and feminine-inflected sentences in such languages. For\nSpanish and Hebrew, our approach achieves F1 scores of 82% and 73% at the level\nof tags and accuracies of 90% and 87% at the level of forms. By evaluating our\napproach using four different languages, we show that, on average, it reduces\ngender stereotyping by a factor of 2.5 without any sacrifice to grammaticality.", "authors": ["Ran Zmigrod", "Sabrina J. Mielke", "Hanna Wallach", "Ryan Cotterell"], "category": "cs.CL", "comment": "ACL 2019", "img": "/static/thumbs/1906.04571v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1906.04571v2", "num_discussion": 0, "originally_published_time": "6/11/2019", "pid": "1906.04571v2", "published_time": "2/25/2020", "rawpid": "1906.04571", "tags": ["cs.CL"], "title": "Counterfactual Data Augmentation for Mitigating Gender Stereotypes in\n  Languages with Rich Morphology"}, {"abstract": "Multi-task reinforcement learning (RL) aims to simultaneously learn policies\nfor solving many tasks. Several prior works have found that relabeling past\nexperience with different reward functions can improve sample efficiency.\nRelabeling methods typically ask: if, in hindsight, we assume that our\nexperience was optimal for some task, for what task was it optimal? In this\npaper, we show that hindsight relabeling is inverse RL, an observation that\nsuggests that we can use inverse RL in tandem for RL algorithms to efficiently\nsolve many tasks. We use this idea to generalize goal-relabeling techniques\nfrom prior work to arbitrary classes of tasks. Our experiments confirm that\nrelabeling data using inverse RL accelerates learning in general multi-task\nsettings, including goal-reaching, domains with discrete sets of rewards, and\nthose with linear reward functions.", "authors": ["Benjamin Eysenbach", "Xinyang Geng", "Sergey Levine", "Ruslan Salakhutdinov"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.11089v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11089v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11089v1", "published_time": "2/25/2020", "rawpid": "2002.11089", "tags": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "title": "Rewriting History with Inverse RL: Hindsight Inference for Policy\n  Improvement"}, {"abstract": "Deep learning has achieved tremendous success in numerous industrial\napplications. As training a good model often needs massive high-quality data\nand computation resources, the learned models often have significant business\nvalues. However, these valuable deep models are exposed to a huge risk of\ninfringements. For example, if the attacker has the full information of one\ntarget model including the network structure and weights, the model can be\neasily finetuned on new datasets. Even if the attacker can only access the\noutput of the target model, he/she can still train another similar surrogate\nmodel by generating a large scale of input-output training pairs. How to\nprotect the intellectual property of deep models is a very important but\nseriously under-researched problem. There are a few recent attempts at\nclassification network protection only. In this paper, we propose the first\nmodel watermarking framework for protecting image processing models. To achieve\nthis goal, we leverage the spatial invisible watermarking mechanism.\nSpecifically, given a black-box target model, a unified and invisible watermark\nis hidden into its outputs, which can be regarded as a special task-agnostic\nbarrier. In this way, when the attacker trains one surrogate model by using the\ninput-output pairs of the target model, the hidden watermark will be learned\nand extracted afterward. To enable watermarks from binary bits to\nhigh-resolution images, both traditional and deep spatial invisible\nwatermarking mechanism are considered. Experiments demonstrate the robustness\nof the proposed watermarking mechanism, which can resist surrogate models\nlearned with different network structures and objective functions. Besides deep\nmodels, the proposed method is also easy to be extended to protect data and\ntraditional image processing algorithms.", "authors": ["Jie Zhang", "Dongdong Chen", "Jing Liao", "Han Fang", "Weiming Zhang", "Wenbo Zhou", "Hao Cui", "Nenghai Yu"], "category": "cs.MM", "comment": "AAAI 2020", "img": "/static/thumbs/2002.11088v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11088v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11088v1", "published_time": "2/25/2020", "rawpid": "2002.11088", "tags": ["cs.MM", "cs.CV", "eess.IV"], "title": "Model Watermarking for Image Processing Networks"}, {"abstract": "The Universal Morphology UniMorph project is a collaborative effort to\nimprove how NLP handles complex morphology across the world\u0027s languages. The\nproject releases annotated morphological data using a universal tagset, the\nUniMorph schema. Each inflected form is associated with a lemma, which\ntypically carries its underlying lexical meaning, and a bundle of morphological\nfeatures from our schema. Additional supporting data and tools are also\nreleased on a per-language basis when available. UniMorph is based at the\nCenter for Language and Speech Processing (CLSP) at Johns Hopkins University in\nBaltimore, Maryland and is sponsored by the DARPA LORELEI program. This paper\ndetails advances made to the collection, annotation, and dissemination of\nproject resources since the initial UniMorph release described at LREC 2016.\nlexical resources} }", "authors": ["Christo Kirov", "Ryan Cotterell", "John Sylak-Glassman", "G\u00e9raldine Walther", "Ekaterina Vylomova", "Patrick Xia", "Manaal Faruqui", "Sabrina J. Mielke", "Arya D. McCarthy", "Sandra K\u00fcbler", "David Yarowsky", "Jason Eisner", "Mans Hulden"], "category": "cs.CL", "comment": "LREC 2018", "img": "/static/thumbs/1810.11101v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1810.11101v2", "num_discussion": 0, "originally_published_time": "10/25/2018", "pid": "1810.11101v2", "published_time": "2/25/2020", "rawpid": "1810.11101", "tags": ["cs.CL"], "title": "UniMorph 2.0: Universal Morphology"}, {"abstract": "The CoNLL--SIGMORPHON 2018 shared task on supervised learning of\nmorphological generation featured data sets from 103 typologically diverse\nlanguages. Apart from extending the number of languages involved in earlier\nsupervised tasks of generating inflected forms, this year the shared task also\nfeatured a new second task which asked participants to inflect words in\nsentential context, similar to a cloze task. This second task featured seven\nlanguages. Task 1 received 27 submissions and task 2 received 6 submissions.\nBoth tasks featured a low, medium, and high data condition. Nearly all\nsubmissions featured a neural component and built on highly-ranked systems from\nthe earlier 2017 shared task. In the inflection task (task 1), 41 of the 52\nlanguages present in last year\u0027s inflection task showed improvement by the best\nsystems in the low-resource setting. The cloze task (task 2) proved to be\ndifficult, and few submissions managed to consistently improve upon both a\nsimple neural baseline system and a lemma-repeating baseline.", "authors": ["Ryan Cotterell", "Christo Kirov", "John Sylak-Glassman", "G\u00e9raldine Walther", "Ekaterina Vylomova", "Arya D. McCarthy", "Katharina Kann", "Sabrina J. Mielke", "Garrett Nicolai", "Miikka Silfverberg", "David Yarowsky", "Jason Eisner", "Mans Hulden"], "category": "cs.CL", "comment": "CoNLL 2018. arXiv admin note: text overlap with arXiv:1706.09031", "img": "/static/thumbs/1810.07125v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1810.07125v3", "num_discussion": 0, "originally_published_time": "10/16/2018", "pid": "1810.07125v3", "published_time": "2/25/2020", "rawpid": "1810.07125", "tags": ["cs.CL"], "title": "The CoNLL--SIGMORPHON 2018 Shared Task: Universal Morphological\n  Reinflection"}, {"abstract": "Statistical morphological inflectors are typically trained on fully\nsupervised, type-level data. One remaining open research question is the\nfollowing: How can we effectively exploit raw, token-level data to improve\ntheir performance? To this end, we introduce a novel generative latent-variable\nmodel for the semi-supervised learning of inflection generation. To enable\nposterior inference over the latent variables, we derive an efficient\nvariational inference procedure based on the wake-sleep algorithm. We\nexperiment on 23 languages, using the Universal Dependencies corpora in a\nsimulated low-resource setting, and find improvements of over 10% absolute\naccuracy in some cases.", "authors": ["Lawrence Wolf-Sonkin", "Jason Naradowsky", "Sabrina J. Mielke", "Ryan Cotterell"], "category": "cs.CL", "comment": "Published at ACL 2018", "img": "/static/thumbs/1806.03746v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.03746v2", "num_discussion": 0, "originally_published_time": "6/10/2018", "pid": "1806.03746v2", "published_time": "2/25/2020", "rawpid": "1806.03746", "tags": ["cs.CL"], "title": "A Structured Variational Autoencoder for Contextual Morphological\n  Inflection"}, {"abstract": "For general modeling methods applied to diverse languages, a natural question\nis: how well should we expect our models to work on languages with differing\ntypological profiles? In this work, we develop an evaluation framework for fair\ncross-linguistic comparison of language models, using translated text so that\nall models are asked to predict approximately the same information. We then\nconduct a study on 21 languages, demonstrating that in some languages, the\ntextual expression of the information is harder to predict with both $n$-gram\nand LSTM language models. We show complex inflectional morphology to be a cause\nof performance differences among languages.", "authors": ["Ryan Cotterell", "Sabrina J. Mielke", "Jason Eisner", "Brian Roark"], "category": "cs.CL", "comment": "Published at NAACL 2018", "img": "/static/thumbs/1806.03743v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.03743v2", "num_discussion": 0, "originally_published_time": "6/10/2018", "pid": "1806.03743v2", "published_time": "2/25/2020", "rawpid": "1806.03743", "tags": ["cs.CL"], "title": "Are All Languages Equally Hard to Language-Model?"}, {"abstract": "Applying machine learning technologies, especially deep learning, into\nmedical image segmentation is being widely studied because of its\nstate-of-the-art performance and results. It can be a key step to provide a\nreliable basis for clinical diagnosis, such as 3D reconstruction of human\ntissues, image-guided interventions, image analyzing and visualization. In this\nreview article, deep-learning-based methods for ultrasound image segmentation\nare categorized into six main groups according to their architectures and\ntraining at first. Secondly, for each group, several current representative\nalgorithms are selected, introduced, analyzed and summarized in detail. In\naddition, common evaluation methods for image segmentation and ultrasound image\nsegmentation datasets are summarized. Further, the performance of the current\nmethods and their evaluations are reviewed. In the end, the challenges and\npotential research directions for medical ultrasound image segmentation are\ndiscussed.", "authors": ["Ziyang Wang", "Zhengdong Zhang", "Jianqing Zheng", "Baoru Huang", "Irina Voiculescu", "Guang-Zhong Yang"], "category": "eess.IV", "comment": "", "img": "/static/thumbs/2002.07703v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.07703v2", "num_discussion": 0, "originally_published_time": "2/18/2020", "pid": "2002.07703v2", "published_time": "2/25/2020", "rawpid": "2002.07703", "tags": ["eess.IV", "cs.CV", "cs.LG", "stat.ML"], "title": "Deep Learning in Medical Ultrasound Image Segmentation: a Review"}, {"abstract": "Lexical ambiguity makes it difficult to compute various useful statistics of\na corpus. A given word form might represent any of several morphological\nfeature bundles. One can, however, use unsupervised learning (as in EM) to fit\na model that probabilistically disambiguates word forms. We present such an\napproach, which employs a neural network to smoothly model a prior distribution\nover feature bundles (even rare ones). Although this basic model does not\nconsider a token\u0027s context, that very property allows it to operate on a simple\nlist of unigram type counts, partitioning each count among different analyses\nof that unigram. We discuss evaluation metrics for this novel task and report\nresults on 5 languages.", "authors": ["Ryan Cotterell", "Christo Kirov", "Sabrina J. Mielke", "Jason Eisner"], "category": "cs.CL", "comment": "Published at NAACL 2018", "img": "/static/thumbs/1806.03740v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.03740v2", "num_discussion": 0, "originally_published_time": "6/10/2018", "pid": "1806.03740v2", "published_time": "2/25/2020", "rawpid": "1806.03740", "tags": ["cs.CL"], "title": "Unsupervised Disambiguation of Syncretism in Inflected Lexicons"}, {"abstract": "The communication of gradients is costly for training deep neural networks\nwith multiple devices in computer vision applications. In particular, the\ngrowing size of deep learning models leads to higher communication overheads\nthat defy the ideal linear training speedup regarding the number of devices.\nGradient quantization is one of the common methods to reduce communication\ncosts. However, it can lead to quantization error in the training and result in\nmodel performance degradation. In this work, we deduce the optimal condition of\nboth the binary and multi-level gradient quantization for \\textbf{ANY} gradient\ndistribution. Based on the optimal condition, we develop two novel quantization\nschemes: biased BinGrad and unbiased ORQ for binary and multi-level gradient\nquantization respectively, which dynamically determine the optimal quantization\nlevels. Extensive experimental results on CIFAR and ImageNet datasets with\nseveral popular convolutional neural networks show the superiority of our\nproposed methods.", "authors": ["An Xu", "Zhouyuan Huo", "Heng Huang"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.11082v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11082v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11082v1", "published_time": "2/25/2020", "rawpid": "2002.11082", "tags": ["cs.LG", "cs.DC", "stat.ML"], "title": "Optimal Gradient Quantization Condition for Communication-Efficient\n  Distributed Training"}, {"abstract": "We show how the spellings of known words can help us deal with unknown words\nin open-vocabulary NLP tasks. The method we propose can be used to extend any\nclosed-vocabulary generative model, but in this paper we specifically consider\nthe case of neural language modeling. Our Bayesian generative story combines a\nstandard RNN language model (generating the word tokens in each sentence) with\nan RNN-based spelling model (generating the letters in each word type). These\ntwo RNNs respectively capture sentence structure and word structure, and are\nkept separate as in linguistics. By invoking the second RNN to generate\nspellings for novel words in context, we obtain an open-vocabulary language\nmodel. For known words, embeddings are naturally inferred by combining evidence\nfrom type spelling and token context. Comparing to baselines (including a novel\nstrong baseline), we beat previous work and establish state-of-the-art results\non multiple datasets.", "authors": ["Sabrina J. Mielke", "Jason Eisner"], "category": "cs.CL", "comment": "Accepted for publication at AAAI 2019", "img": "/static/thumbs/1804.08205v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1804.08205v4", "num_discussion": 0, "originally_published_time": "4/23/2018", "pid": "1804.08205v4", "published_time": "2/25/2020", "rawpid": "1804.08205", "tags": ["cs.CL"], "title": "Spell Once, Summon Anywhere: A Two-Level Open-Vocabulary Language Model"}, {"abstract": "Despite remarkable success, deep neural networks are sensitive to\nhuman-imperceptible small perturbations on the data and could be adversarially\nmisled to produce incorrect or even dangerous predictions. To circumvent these\nissues, practitioners introduced adversarial training to produce adversarially\nrobust models whose predictions are robust to small perturbations to the data.\nIt is widely believed that more training data will help adversarially robust\nmodels generalize better on the test data. In this paper, however, we challenge\nthis conventional belief and show that more training data could hurt the\ngeneralization of adversarially robust models for the linear classification\nproblem. We identify three regimes based on the strength of the adversary. In\nthe weak adversary regime, more data improves the generalization of\nadversarially robust models. In the medium adversary regime, with more training\ndata, the generalization loss exhibits a double descent curve. This implies\nthat in this regime, there is an intermediate stage where more training data\nhurts their generalization. In the strong adversary regime, more data almost\nimmediately causes the generalization error to increase.", "authors": ["Yifei Min", "Lin Chen", "Amin Karbasi"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.11080v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11080v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11080v1", "published_time": "2/25/2020", "rawpid": "2002.11080", "tags": ["cs.LG", "stat.ML"], "title": "The Curious Case of Adversarially Robust Models: More Data Can Help,\n  Double Descend, or Hurt Generalization"}, {"abstract": "Different from traditional image super-resolution task, real image\nsuper-resolution(Real-SR) focus on the relationship between real-world\nhigh-resolution(HR) and low-resolution(LR) image. Most of the traditional image\nSR obtains the LR sample by applying a fixed down-sampling operator. Real-SR\nobtains the LR and HR image pair by incorporating different quality optical\nsensors. Generally, Real-SR has more challenges as well as broader application\nscenarios. Previous image SR methods fail to exhibit similar performance on\nReal-SR as the image data is not aligned inherently. In this article, we\npropose a Dual-path Dynamic Enhancement Network(DDet) for Real-SR, which\naddresses the cross-camera image mapping by realizing a dual-way dynamic\nsub-pixel weighted aggregation and refinement. Unlike conventional methods\nwhich stack up massive convolutional blocks for feature representation, we\nintroduce a content-aware framework to study non-inherently aligned image pair\nin image SR issue. First, we use a content-adaptive component to exhibit the\nMulti-scale Dynamic Attention(MDA). Second, we incorporate a long-term skip\nconnection with a Coupled Detail Manipulation(CDM) to perform collaborative\ncompensation and manipulation. The above dual-path model is joint into a\nunified model and works collaboratively. Extensive experiments on the\nchallenging benchmarks demonstrate the superiority of our model.", "authors": ["Yukai Shi", "Haoyu Zhong", "Zhijing Yang", "Xiaojun Yang", "Liang Lin"], "category": "cs.CV", "comment": "Code address: https://github.com/ykshi/DDet", "img": "/static/thumbs/2002.11079v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11079v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11079v1", "published_time": "2/25/2020", "rawpid": "2002.11079", "tags": ["cs.CV", "cs.MM", "eess.IV"], "title": "DDet: Dual-path Dynamic Enhancement Network for Real-World Image\n  Super-Resolution"}, {"abstract": "Search has for a long time been an important tool for users to retrieve\ninformation. Syntactic search is matching documents or objects containing\nspecific keywords like user-history, location, preference etc. to improve the\nresults. However, it is often possible that the query and the best answer have\nno term or very less number of terms in common and syntactic search can not\nperform properly in such cases. Semantic search, on the other hand, resolves\nthese issues but suffers from lack of annotation, absence of WordNet in case of\nlow resource languages. In this work, we have demonstrated an end to end\nprocedure to improve the performance of semantic search using semi-supervised\nand unsupervised learning algorithms. An available Bengali repository was\nchosen to have seven types of semantic properties primarily to develop the\nsystem. Performance has been tested using Support Vector Machine, Naive Bayes,\nDecision Tree and Artificial Neural Network (ANN). Our system has achieved the\nefficiency to predict the correct semantics using knowledge base over the time\nof learning. A repository containing around a million sentences, a product of\nTDIL project of Govt. of India, was used to test our system at first instance.\nThen the testing has been done for other languages. Being a cognitive system it\nmay be very useful for improving user satisfaction in e-Governance or\nm-Governance in the multilingual environment and also for other applications.", "authors": ["Arijit Das", "Diganta Saha"], "category": "cs.CL", "comment": "12 pages, 5 figures", "img": "/static/thumbs/1911.01256v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1911.01256v2", "num_discussion": 0, "originally_published_time": "11/4/2019", "pid": "1911.01256v2", "published_time": "2/25/2020", "rawpid": "1911.01256", "tags": ["cs.CL", "cs.IR"], "title": "A Novel Approach to Enhance the Performance of Semantic Search in\n  Bengali using Neural Net and other Classification Techniques"}, {"abstract": "As one of the most important paradigms of recurrent neural networks, the echo\nstate network (ESN) has been applied to a wide range of fields, from robotics\nto medicine, finance, and language processing. A key feature of the ESN\nparadigm is its reservoir --- a directed and weighted network of neurons that\nprojects the input time series into a high dimensional space where linear\nregression or classification can be applied. Despite extensive studies, the\nimpact of the reservoir network on the ESN performance remains unclear.\nCombining tools from physics, dynamical systems and network science, we attempt\nto open the black box of ESN and offer insights to understand the behavior of\ngeneral artificial neural networks. Through spectral analysis of the reservoir\nnetwork we reveal a key factor that largely determines the ESN memory capacity\nand hence affects its performance. Moreover, we find that adding short loops to\nthe reservoir network can tailor ESN for specific tasks and optimize learning.\nWe validate our findings by applying ESN to forecast both synthetic and real\nbenchmark time series. Our results provide a new way to design task-specific\nESN. More importantly, it demonstrates the power of combining tools from\nphysics, dynamical systems and network science to offer new insights in\nunderstanding the mechanisms of general artificial neural networks.", "authors": ["Pau Vilimelis Aceituno", "Yan Gang", "Yang-Yu Liu"], "category": "cs.LG", "comment": "19 pages, 10 figures", "img": "/static/thumbs/1707.02469v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1707.02469v4", "num_discussion": 0, "originally_published_time": "7/8/2017", "pid": "1707.02469v4", "published_time": "2/25/2020", "rawpid": "1707.02469", "tags": ["cs.LG", "cs.NE"], "title": "Tailoring Artificial Neural Networks for Optimal Learning"}, {"abstract": "A recent line of work studies overparametrized neural networks in the \"kernel\nregime,\" i.e. when the network behaves during training as a kernelized linear\npredictor, and thus training with gradient descent has the effect of finding\nthe minimum RKHS norm solution. This stands in contrast to other studies which\ndemonstrate how gradient descent on overparametrized multilayer networks can\ninduce rich implicit biases that are not RKHS norms. Building on an observation\nby Chizat and Bach, we show how the scale of the initialization controls the\ntransition between the \"kernel\" (aka lazy) and \"rich\" (aka active) regimes and\naffects generalization properties in multilayer homogeneous models. We provide\na complete and detailed analysis for a simple two-layer model that already\nexhibits an interesting and meaningful transition between the kernel and rich\nregimes, and we demonstrate the transition for more complex matrix\nfactorization models and multilayer non-linear networks.", "authors": ["Blake Woodworth", "Suriya Gunasekar", "Pedro Savarese", "Edward Moroshko", "Itay Golan", "Jason Lee", "Daniel Soudry", "Nathan Srebro"], "category": "cs.LG", "comment": "This paper has been substantially modified, updated, and expanded\n  with additional content (arXiv:2...", "img": "/static/thumbs/1906.05827v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1906.05827v3", "num_discussion": 0, "originally_published_time": "6/13/2019", "pid": "1906.05827v3", "published_time": "2/25/2020", "rawpid": "1906.05827", "tags": ["cs.LG", "stat.ML"], "title": "Kernel and Rich Regimes in Overparametrized Models"}, {"abstract": "Image segmentation is a fundamental research topic in image processing and\ncomputer vision. In the last decades, researchers developed a large number of\nsegmentation algorithms for various applications. Amongst these algorithms, the\nNormalized cut (Ncut) segmentation method is widely applied due to its good\nperformance. The Ncut segmentation model is an optimization problem whose\nenergy is defined on a specifically designed graph. Thus, the segmentation\nresults of the existing Ncut method are largely dependent on a pre-constructed\nsimilarity measure on the graph since this measure is usually given empirically\nby users. This flaw will lead to some undesirable segmentation results. In this\npaper, we propose a Ncut-based segmentation algorithm by integrating an\nadaptive similarity measure and spatial regularization. The proposed model\ncombines the Parzen-Rosenblatt window method, non-local weights entropy, Ncut\nenergy, and regularizer of phase field in a variational framework. Our method\ncan adaptively update the similarity measure function by estimating some\nparameters. This adaptive procedure enables the proposed algorithm finding a\nbetter similarity measure for classification than the Ncut method. We provide\nsome mathematical interpretation of the proposed adaptive similarity from\nmulti-viewpoints such as statistics and convex optimization. In addition, the\nregularizer of phase field can guarantee that the proposed algorithm has a\nrobust performance in the presence of noise, and it can also rectify the\nsimilarity measure with a spatial priori. The well-posed theory such as the\nexistence of the minimizer for the proposed model is given in the paper.\nCompared with some existing segmentation methods such as the traditional\nNcut-based model and the classical Chan-Vese model, the numerical experiments\nshow that our method can provide promising segmentation results.", "authors": ["Faqiang Wang", "Cuicui Zhao", "Jun Liu", "Haiyang Huang"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.01977v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.01977v3", "num_discussion": 0, "originally_published_time": "6/6/2018", "pid": "1806.01977v3", "published_time": "2/25/2020", "rawpid": "1806.01977", "tags": ["cs.CV"], "title": "A Variational Image Segmentation Model based on Normalized Cut with\n  Adaptive Similarity and Spatial Regularization"}, {"abstract": "Ground texture based localization is a promising approach to achieve\nhigh-accuracy positioning of vehicles. We present a self-contained method that\ncan be used for global localization as well as for subsequent local\nlocalization updates, i.e. it allows a robot to localize without any knowledge\nof its current whereabouts, but it can also take advantage of a prior pose\nestimate to reduce computation time significantly. Our method is based on a\nnovel matching strategy, which we call identity matching, that is based on\ncompact binary feature descriptors. Identity matching treats pairs of features\nas matches only if their descriptors are identical. While other methods for\nglobal localization are faster to compute, our method reaches higher\nlocalization success rates, and can switch to local localization after the\ninitial localization.", "authors": ["Jan Fabian Schmid", "Stephan F. Simon", "Rudolf Mester"], "category": "cs.CV", "comment": "Accepted for 2020 IEEE International Conference on Robotics and\n  Automation (ICRA)", "img": "/static/thumbs/2002.11061v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11061v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11061v1", "published_time": "2/25/2020", "rawpid": "2002.11061", "tags": ["cs.CV", "cs.RO"], "title": "Ground Texture Based Localization Using Compact Binary Descriptors"}, {"abstract": "We present a consensus Monte Carlo algorithm that scales existing Bayesian\nnonparametric models for clustering and feature allocation to big data. The\nalgorithm is valid for any prior on random subsets such as partitions and\nlatent feature allocation, under essentially any sampling model. Motivated by\nthree case studies, we focus on clustering induced by a Dirichlet process\nmixture sampling model, inference under an Indian buffet process prior with a\nbinomial sampling model, and with a categorical sampling model. We assess the\nproposed algorithm with simulation studies and show results for inference with\nthree datasets: an MNIST image dataset, a dataset of pancreatic cancer\nmutations, and a large set of electronic health records (EHR). Supplementary\nmaterials for this article are available online.", "authors": ["Yang Ni", "Yuan Ji", "Peter Mueller"], "category": "stat.CO", "comment": "", "img": "/static/thumbs/1906.12309v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1906.12309v2", "num_discussion": 0, "originally_published_time": "6/28/2019", "pid": "1906.12309v2", "published_time": "2/25/2020", "rawpid": "1906.12309", "tags": ["stat.CO", "stat.ML"], "title": "Consensus Monte Carlo for Random Subsets using Shared Anchors"}, {"abstract": "This work presents MLIR, a novel approach to building reusable and extensible\ncompiler infrastructure. MLIR aims to address software fragmentation, improve\ncompilation for heterogeneous hardware, significantly reduce the cost of\nbuilding domain specific compilers, and aid in connecting existing compilers\ntogether. MLIR facilitates the design and implementation of code generators,\ntranslators and optimizers at different levels of abstraction and also across\napplication domains, hardware targets and execution environments. The\ncontribution of this work includes (1) discussion of MLIR as a research\nartifact, built for extension and evolution, and identifying the challenges and\nopportunities posed by this novel design point in design, semantics,\noptimization specification, system, and engineering. (2) evaluation of MLIR as\na generalized infrastructure that reduces the cost of building\ncompilers-describing diverse use-cases to show research and educational\nopportunities for future programming languages, compilers, execution\nenvironments, and computer architecture. The paper also presents the rationale\nfor MLIR, its original design principles, structures and semantics.", "authors": ["Chris Lattner", "Jacques Pienaar", "Mehdi Amini", "Uday Bondhugula", "River Riddle", "Albert Cohen", "Tatiana Shpeisman", "Andy Davis", "Nicolas Vasilache", "Oleksandr Zinenko"], "category": "cs.PL", "comment": "", "img": "/static/thumbs/2002.11054v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11054v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11054v1", "published_time": "2/25/2020", "rawpid": "2002.11054", "tags": ["cs.PL", "cs.LG"], "title": "MLIR: A Compiler Infrastructure for the End of Moore\u0027s Law"}, {"abstract": "Deep neural networks have demonstrated state-of-the-art performance on many\nclassification tasks. However, they have no inherent capability to recognize\nwhen their predictions are wrong. There have been several efforts in the recent\npast to detect natural errors but the suggested mechanisms pose additional\nenergy requirements. To address this issue, we propose an ensemble of\nclassifiers at hidden layers to enable energy efficient detection of natural\nerrors. In particular, we append Relevant-features based Auxiliary Cells (RACs)\nwhich are class specific binary linear classifiers trained on relevant\nfeatures. The consensus of RACs is used to detect natural errors. Based on\ncombined confidence of RACs, classification can be terminated early, thereby\nresulting in energy efficient detection. We demonstrate the effectiveness of\nour technique on various image classification datasets such as CIFAR-10,\nCIFAR-100 and Tiny-ImageNet.", "authors": ["Sai Aparna Aketi", "Priyadarshini Panda", "Kaushik Roy"], "category": "cs.LG", "comment": "16 pages, 3 figures, 6 tables", "img": "/static/thumbs/2002.11052v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11052v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11052v1", "published_time": "2/25/2020", "rawpid": "2002.11052", "tags": ["cs.LG", "cs.CV", "stat.ML"], "title": "Relevant-features based Auxiliary Cells for Energy Efficient Detection\n  of Natural Errors"}, {"abstract": "Learning meaningful representations of free-hand sketches remains a\nchallenging task given the signal sparsity and the high-level abstraction of\nsketches. Existing techniques have focused on exploiting either the static\nnature of sketches with Convolutional Neural Networks (CNNs) or the temporal\nsequential property with Recurrent Neural Networks (RNNs). In this work, we\npropose a new representation of sketches as multiple sparsely connected graphs.\nWe design a novel Graph Neural Network (GNN), the Multi-Graph Transformer\n(MGT), for learning representations of sketches from multiple graphs which\nsimultaneously capture global and local geometric stroke structures, as well as\ntemporal information. We report extensive numerical experiments on a sketch\nrecognition task to demonstrate the performance of the proposed approach.\nParticularly, MGT applied on 414k sketches from Google QuickDraw: (i) achieves\nsmall recognition gap to the CNN-based performance upper bound (72.80% vs.\n74.22%), and (ii) outperforms all RNN-based models by a significant margin. To\nthe best of our knowledge, this is the first work proposing to represent\nsketches as graphs and apply GNNs for sketch recognition. Code and trained\nmodels are available at\nhttps://github.com/PengBoXiangShang/multigraph_transformer.", "authors": ["Peng Xu", "Chaitanya K. Joshi", "Xavier Bresson"], "category": "cs.CV", "comment": "Added the appendix", "img": "/static/thumbs/1912.11258v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1912.11258v2", "num_discussion": 0, "originally_published_time": "12/24/2019", "pid": "1912.11258v2", "published_time": "2/25/2020", "rawpid": "1912.11258", "tags": ["cs.CV", "cs.LG"], "title": "Multi-Graph Transformer for Free-Hand Sketch Recognition"}, {"abstract": "We propose a novel deep learning approach to efficiently perform Bayesian\ninference in partial differential equation (PDE) and integral equation models\nover potentially high-dimensional parameter spaces. The contributions of this\npaper are two-fold; the first is the introduction of a neural network approach\nto approximating the solutions of Fredholm and Volterra integral equations of\nthe first and second kind. The second is the description of a deep surrogate\nmodel which allows for efficient sampling from a Bayesian posterior\ndistribution in which the likelihood depends on the solutions of PDEs or\nintegral equations. For the latter, our method relies on the approximate\nrepresentation of parametric solutions by neural networks. This deep learning\napproach allows the accurate and efficient approximation of parametric\nsolutions in significantly higher dimensions than is possible using classical\ntechniques. Since the approximated solutions are very cheap to evaluate, the\nsolutions of Bayesian inverse problems over large parameter spaces are\ntractable using Markov chain Monte Carlo. We demonstrate the efficiency of our\nmethod using two real-world examples; these include Bayesian inference in the\nPDE and integral equation case for an example from electrochemistry, and\nBayesian inference of a function-valued heat-transfer parameter with\napplications in aviation.", "authors": ["Teo Deveney", "Eike Mueller", "Tony Shardlow"], "category": "math.NA", "comment": "", "img": "/static/thumbs/1910.01547v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1910.01547v3", "num_discussion": 0, "originally_published_time": "10/3/2019", "pid": "1910.01547v3", "published_time": "2/25/2020", "rawpid": "1910.01547", "tags": ["math.NA", "cs.LG", "cs.NA", "stat.ME"], "title": "A deep surrogate approach to efficient Bayesian inversion in PDE and\n  integral equation models"}, {"abstract": "Understanding the meaning of words is crucial for many tasks that involve\nhuman-machine interaction. This has been tackled by research in Word Sense\nDisambiguation (WSD) in the Natural Language Processing (NLP) field. Recently,\nWSD and many other NLP tasks have taken advantage of embeddings-based\nrepresentation of words, sentences, and documents. However, when it comes to\nWSD, most embeddings models suffer from ambiguity as they do not capture the\ndifferent possible meanings of the words. Even when they do, the list of\npossible meanings for a word (sense inventory) has to be known in advance at\ntraining time to be included in the embeddings space. Unfortunately, there are\nsituations in which such a sense inventory is not known in advance (e.g., an\nontology selected at run-time), or it evolves with time and its status diverges\nfrom the one at training time. This hampers the use of embeddings models for\nWSD. Furthermore, traditional WSD techniques do not perform well in situations\nin which the available linguistic information is very scarce, such as the case\nof keyword-based queries. In this paper, we propose an approach to keyword\ndisambiguation which grounds on a semantic relatedness between words and senses\nprovided by an external inventory (ontology) that is not known at training\ntime. Building on previous works, we present a semantic relatedness measure\nthat uses word embeddings, and explore different disambiguation algorithms to\nalso exploit both word and sentence representations. Experimental results show\nthat this approach achieves results comparable with the state of the art when\napplied for WSD, without training for a particular domain.", "authors": ["Mar\u00eda G. Buey", "Carlos Bobed", "Jorge Gracia", "Eduardo Mena"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/2002.11023v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11023v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11023v1", "published_time": "2/25/2020", "rawpid": "2002.11023", "tags": ["cs.CL"], "title": "Semantic Relatedness for Keyword Disambiguation: Exploiting Different\n  Embeddings"}, {"abstract": "We consider the setting where a master wants to run a distributed stochastic\ngradient descent (SGD) algorithm on $n$ workers each having a subset of the\ndata. Distributed SGD may suffer from the effect of stragglers, i.e., slow or\nunresponsive workers who cause delays. One solution studied in the literature\nis to wait at each iteration for the responses of the fastest $k\u003cn$ workers\nbefore updating the model, where $k$ is a fixed parameter. The choice of the\nvalue of $k$ presents a trade-off between the runtime (i.e., convergence rate)\nof SGD and the error of the model. Towards optimizing the error-runtime\ntrade-off, we investigate distributed SGD with adaptive $k$. We first design an\nadaptive policy for varying $k$ that optimizes this trade-off based on an upper\nbound on the error as a function of the wall-clock time which we derive. Then,\nwe propose an algorithm for adaptive distributed SGD that is based on a\nstatistical heuristic. We implement our algorithm and provide numerical\nsimulations which confirm our intuition and theoretical analysis.", "authors": ["Serge Kas Hanna", "Rawad Bitar", "Parimal Parag", "Venkat Dasari", "Salim El Rouayheb"], "category": "cs.LG", "comment": "Accepted to IEEE ICASSP 2020", "img": "/static/thumbs/2002.11005v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11005v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11005v1", "published_time": "2/25/2020", "rawpid": "2002.11005", "tags": ["cs.LG", "stat.ML"], "title": "Adaptive Distributed Stochastic Gradient Descent for Minimizing Delay in\n  the Presence of Stragglers"}, {"abstract": "Language-independent tokenisation (LIT) methods that do not require labelled\nlanguage resources or lexicons have recently gained popularity because of their\napplicability in resource-poor languages. Moreover, they compactly represent a\nlanguage using a fixed size vocabulary and can efficiently handle unseen or\nrare words. On the other hand, language-specific tokenisation (LST) methods\nhave a long and established history, and are developed using carefully created\nlexicons and training resources. Unlike subtokens produced by LIT methods, LST\nmethods produce valid morphological subwords. Despite the contrasting\ntrade-offs between LIT vs. LST methods, their performance on downstream NLP\ntasks remain unclear. In this paper, we empirically compare the two approaches\nusing semantic similarity measurement as an evaluation task across a diverse\nset of languages. Our experimental results covering eight languages show that\nLST consistently outperforms LIT when the vocabulary size is large, but LIT can\nproduce comparable or better results than LST in many languages with\ncomparatively smaller (i.e. less than 100K words) vocabulary sizes, encouraging\nthe use of LIT when language-specific resources are unavailable, incomplete or\na smaller model is required. Moreover, we find that smoothed inverse frequency\n(SIF) to be an accurate method to create word embeddings from subword\nembeddings for multilingual semantic similarity prediction tasks. Further\nanalysis of the nearest neighbours of tokens show that semantically and\nsyntactically related tokens are closely embedded in subword embedding spaces", "authors": ["Danushka Bollegala", "Ryuichi Kiryo", "Kosuke Tsujino", "Haruki Yukawa"], "category": "cs.CL", "comment": "To appear in the 12th Language Resources and Evaluation (LREC 2020)\n  Conference", "img": "/static/thumbs/2002.11004v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11004v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11004v1", "published_time": "2/25/2020", "rawpid": "2002.11004", "tags": ["cs.CL", "cs.AI", "cs.LG"], "title": "Language-Independent Tokenisation Rivals Language-Specific Tokenisation\n  for Word Similarity Prediction"}, {"abstract": "Common criticisms of state-of-the-art machine learning include poor\ngeneralisation, a lack of interpretability, and a need for large amounts of\ntraining data. We survey recent work in inductive logic programming (ILP), a\nform of machine learning that induces logic programs from data, which has shown\npromise at addressing these limitations. We focus on new methods for learning\nrecursive programs that generalise from few examples, a shift from using\nhand-crafted background knowledge to \\emph{learning} background knowledge, and\nthe use of different technologies, notably answer set programming and neural\nnetworks. As ILP approaches 30, we also discuss directions for future research.", "authors": ["Andrew Cropper", "Sebastijan Duman\u010di\u0107", "Stephen H. Muggleton"], "category": "cs.AI", "comment": "Draft ILP survey paper", "img": "/static/thumbs/2002.11002v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.11002v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.11002v1", "published_time": "2/25/2020", "rawpid": "2002.11002", "tags": ["cs.AI", "cs.LG"], "title": "Turning 30: New Ideas in Inductive Logic Programming"}, {"abstract": "In this paper we investigate the problem of automatically naming pieces of\nassembly code. Where by naming we mean assigning to an assembly function a\nstring of words that would likely be assigned by a human reverse engineer. We\nformally and precisely define the framework in which our investigation takes\nplace. That is we define the problem, we provide reasonable justifications for\nthe choices that we made for the design of training and the tests. We performed\nan analysis on a large real-world corpora constituted by nearly 9 millions of\nfunctions taken from more than 22k softwares. In such framework we test\nbaselines coming from the field of Natural Language Processing (e.g., Seq2Seq\nnetworks and Transformer). Interestingly, our evaluation shows promising\nresults beating the state-of-the-art and reaching good performance. We\ninvestigate the applicability of tine-tuning (i.e., taking a model already\ntrained on a large generic corpora and retraining it for a specific task). Such\ntechnique is popular and well-known in the NLP field. Our results confirm that\nfine-tuning is effective even when neural networks are applied to binaries. We\nshow that a model, pre-trained on the aforementioned corpora, when fine-tuned\nhas higher performances on specific domains (such as predicting names in system\nutilites, malware, etc).", "authors": ["Fiorella Artuso", "Giuseppe Antonio Di Luna", "Luca Massarelli", "Leonardo Querzoni"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1912.07946v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1912.07946v2", "num_discussion": 0, "originally_published_time": "12/17/2019", "pid": "1912.07946v2", "published_time": "2/25/2020", "rawpid": "1912.07946", "tags": ["cs.LG", "cs.CL", "stat.ML"], "title": "In Nomine Function: Naming Functions in Stripped Binaries with Neural\n  Networks"}, {"abstract": "Adversarial training yields robust models against a specific threat model,\ne.g., $L_\\infty$ adversarial examples. Typically robustness does not generalize\nto previously unseen threat models, e.g., other $L_p$ norms, or larger\nperturbations. Our confidence-calibrated adversarial training (CCAT) tackles\nthis problem by biasing the model towards low confidence predictions on\nadversarial examples. By allowing to reject examples with low confidence,\nrobustness generalizes beyond the threat model employed during training. CCAT,\ntrained only on $L_\\infty$ adversarial examples, increases robustness against\nlarger $L_\\infty$, $L_2$, $L_1$ and $L_0$ attacks, adversarial frames, distal\nadversarial examples and corrupted examples and yields better clean accuracy\ncompared to adversarial training. For thorough evaluation we developed novel\nwhite- and black-box attacks directly attacking CCAT by maximizing confidence.\nFor each threat model, we use $7$ attacks with up to $50$ restarts and $5000$\niterations and report worst-case robust test error, extended to our\nconfidence-thresholded setting, across all attacks.", "authors": ["David Stutz", "Matthias Hein", "Bernt Schiele"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1910.06259v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1910.06259v3", "num_discussion": 0, "originally_published_time": "10/14/2019", "pid": "1910.06259v3", "published_time": "2/25/2020", "rawpid": "1910.06259", "tags": ["cs.LG", "cs.CR", "cs.CV", "stat.ML"], "title": "Confidence-Calibrated Adversarial Training: Generalizing to Unseen\n  Attacks"}, {"abstract": "Fully Convolutional Neural Networks (F-CNNs) achieve state-of-the-art\nperformance for segmentation tasks in computer vision and medical imaging.\nRecently, computational blocks termed squeeze and excitation (SE) have been\nintroduced to recalibrate F-CNN feature maps both channel- and spatial-wise,\nboosting segmentation performance while only minimally increasing the model\ncomplexity. So far, the development of SE blocks has focused on 2D\narchitectures. For volumetric medical images, however, 3D F-CNNs are a natural\nchoice. In this article, we extend existing 2D recalibration methods to 3D and\npropose a generic compress-process-recalibrate pipeline for easy comparison of\nsuch blocks. We further introduce Project \u0026 Excite (PE) modules, customized for\n3D networks. In contrast to existing modules, Project \\\u0026 Excite does not\nperform global average pooling but compresses feature maps along different\nspatial dimensions of the tensor separately to retain more spatial information\nthat is subsequently used in the excitation step. We evaluate the modules on\ntwo challenging tasks, whole-brain segmentation of MRI scans and whole-body\nsegmentation of CT scans. We demonstrate that PE modules can be easily\nintegrated into 3D F-CNNs, boosting performance up to 0.3 in Dice Score and\noutperforming 3D extensions of other recalibration blocks, while only\nmarginally increasing the model complexity. Our code is publicly available on\nhttps://github.com/ai-med/squeeze_and_excitation .", "authors": ["Anne-Marie Rickmann", "Abhijit Guha Roy", "Ignacio Sarasua", "Christian Wachinger"], "category": "eess.IV", "comment": "Accepted for publication at IEEE Transactions on Medical Imaging", "img": "/static/thumbs/2002.10994v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10994v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10994v1", "published_time": "2/25/2020", "rawpid": "2002.10994", "tags": ["eess.IV", "cs.LG", "stat.ML"], "title": "Recalibrating 3D ConvNets with Project \u0026 Excite"}, {"abstract": "We present a reinforcement learning approach to goal based wealth management\nproblems such as optimization of retirement plans or target dated funds. In\nsuch problems, an investor seeks to achieve a financial goal by making periodic\ninvestments in the portfolio while being employed, and periodically draws from\nthe account when in retirement, in addition to the ability to re-balance the\nportfolio by selling and buying different assets (e.g. stocks). Instead of\nrelying on a utility of consumption, we present G-Learner: a reinforcement\nlearning algorithm that operates with explicitly defined one-step rewards, does\nnot assume a data generation process, and is suitable for noisy data. Our\napproach is based on G-learning - a probabilistic extension of the Q-learning\nmethod of reinforcement learning.\n  In this paper, we demonstrate how G-learning, when applied to a quadratic\nreward and Gaussian reference policy, gives an entropy-regulated Linear\nQuadratic Regulator (LQR). This critical insight provides a novel and\ncomputationally tractable tool for wealth management tasks which scales to high\ndimensional portfolios. In addition to the solution of the direct problem of\nG-learning, we also present a new algorithm, GIRL, that extends our goal-based\nG-learning approach to the setting of Inverse Reinforcement Learning (IRL)\nwhere rewards collected by the agent are not observed, and should instead be\ninferred. We demonstrate that GIRL can successfully learn the reward parameters\nof a G-Learner agent and thus imitate its behavior. Finally, we discuss\npotential applications of the G-Learner and GIRL algorithms for wealth\nmanagement and robo-advising.", "authors": ["Matthew Dixon", "Igor Halperin"], "category": "q-fin.PM", "comment": "", "img": "/static/thumbs/2002.10990v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10990v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10990v1", "published_time": "2/25/2020", "rawpid": "2002.10990", "tags": ["q-fin.PM", "cs.LG", "q-fin.CP", "stat.ML"], "title": "G-Learner and GIRL: Goal Based Wealth Management with Reinforcement\n  Learning"}, {"abstract": "This is the Proceedings of the AAAI-20 Workshop on Intelligent Process\nAutomation (IPA-20) which took place in New York, NY, USA on February 7th 2020.", "authors": ["Dell Zhang", "Andre Freitas", "Dacheng Tao", "Dawn Song"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/2001.05214v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2001.05214v2", "num_discussion": 0, "originally_published_time": "1/15/2020", "pid": "2001.05214v2", "published_time": "2/25/2020", "rawpid": "2001.05214", "tags": ["cs.AI"], "title": "Proceedings of the AAAI-20 Workshop on Intelligent Process Automation\n  (IPA-20)"}, {"abstract": "We tackle the problem of learning equilibria in simulation-based games. In\nsuch games, the players\u0027 utility functions cannot be described analytically, as\nthey are given through a black-box simulator that can be queried to obtain\nnoisy estimates of the utilities. This is the case in many real-world games in\nwhich a complete description of the elements involved is not available upfront,\nsuch as complex military settings and online auctions. In these situations, one\nusually needs to run costly simulation processes to get an accurate estimate of\nthe game outcome. As a result, solving these games begets the challenge of\ndesigning learning algorithms that can find (approximate) equilibria with high\nconfidence, using as few simulator queries as possible. Moreover, since running\nthe simulator during the game is unfeasible, the algorithms must first perform\na pure exploration learning phase and, then, use the (approximate) equilibrium\nlearned this way to play the game. In this work, we focus on two-player\nzero-sum games with infinite strategy spaces. Drawing from the best arm\nidentification literature, we design two algorithms with theoretical guarantees\nto learn maximin strategies in these games. The first one works in the\nfixed-confidence setting, guaranteeing the desired confidence level while\nminimizing the number of queries. Instead, the second algorithm fits the\nfixed-budget setting, maximizing the confidence without exceeding the given\nmaximum number of queries. First, we formally prove {\\delta}-PAC theoretical\nguarantees for our algorithms under some regularity assumptions, which are\nencoded by letting the utility functions be drawn from a Gaussian process.\nThen, we experimentally evaluate our techniques on a testbed made of randomly\ngenerated games and instances representing simple real-world security settings.", "authors": ["Alberto Marchesi", "Francesco Trov\u00f2", "Nicola Gatti"], "category": "cs.GT", "comment": "", "img": "/static/thumbs/1911.07755v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1911.07755v2", "num_discussion": 0, "originally_published_time": "11/18/2019", "pid": "1911.07755v2", "published_time": "2/25/2020", "rawpid": "1911.07755", "tags": ["cs.GT", "cs.LG"], "title": "Learning Probably Approximately Correct Maximin Strategies in\n  Simulation-Based Games with Infinite Strategy Spaces"}, {"abstract": "Deep Metric Learning (DML) is arguably one of the most influential lines of\nresearch for learning visual similarities with many proposed approaches every\nyear. Although the field benefits from the rapid progress, the divergence in\ntraining protocols, architectures, and parameter choices make an unbiased\ncomparison difficult. To provide a consistent reference point, we revisit the\nmost widely used DML objective functions and conduct a study of the crucial\nparameter choices as well as the commonly neglected mini-batch sampling\nprocess. Based on our analysis, we uncover a correlation between the embedding\nspace compression and the generalization performance of DML models. Exploiting\nthese insights, we propose a simple, yet effective, training regularization to\nreliably boost the performance of ranking-based DML models on various standard\nbenchmark datasets.", "authors": ["Karsten Roth", "Timo Milbich", "Samarth Sinha", "Prateek Gupta", "Bj\u00f6rn Ommer", "Joseph Paul Cohen"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2002.08473v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.08473v2", "num_discussion": 0, "originally_published_time": "2/19/2020", "pid": "2002.08473v2", "published_time": "2/25/2020", "rawpid": "2002.08473", "tags": ["cs.CV"], "title": "Revisiting Training Strategies and Generalization Performance in Deep\n  Metric Learning"}, {"abstract": "Modeling the processing chain that has produced a video is a difficult\nreverse engineering task, even when the camera is available. This makes model\nbased video processing a still more complex task. In this paper we propose a\nfully blind video denoising method, with two versions off-line and on-line.\nThis is achieved by fine-tuning a pre-trained AWGN denoising network to the\nvideo with a novel frame-to-frame training strategy. Our denoiser can be used\nwithout knowledge of the origin of the video or burst and the post processing\nsteps applied from the camera sensor. The on-line process only requires a\ncouple of frames before achieving visually-pleasing results for a wide range of\nperturbations. It nonetheless reaches state of the art performance for standard\nGaussian noise, and can be used off-line with still better performance.", "authors": ["Thibaud Ehret", "Axel Davy", "Jean-Michel Morel", "Gabriele Facciolo", "Pablo Arias"], "category": "cs.CV", "comment": "CVPR 2019", "img": "/static/thumbs/1811.12766v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1811.12766v3", "num_discussion": 0, "originally_published_time": "11/30/2018", "pid": "1811.12766v3", "published_time": "2/25/2020", "rawpid": "1811.12766", "tags": ["cs.CV"], "title": "Model-blind Video Denoising Via Frame-to-frame Training"}, {"abstract": "The prediction of upcoming events in industrial processes has been a\nlong-standing research goal since it enables optimization of manufacturing\nparameters, planning of equipment maintenance and more importantly prediction\nand eventually prevention of defects. While existing approaches have\naccomplished substantial progress, they are mostly limited to processing of one\ndimensional signals or require parameter tuning to model environmental\nparameters. In this paper, we propose an alternative approach based on deep\nneural networks that simulates changes in the 3D structure of a monitored\nobject in a batch based on previous 3D measurements. In particular, we propose\nan architecture based on 3D Convolutional Neural Networks (3DCNN) in order to\nmodel the geometric variations in manufacturing parameters and predict upcoming\nevents related to sub-optimal performance. We validate our framework on a\nmicroelectronics use-case using the recently published PCB scans dataset where\nwe simulate changes on the shape and volume of glue deposited on an Liquid\nCrystal Polymer (LCP) substrate before the attachment of integrated circuits\n(IC). Experimental evaluation examines the impact of different choices in the\ncost function during training and shows that the proposed method can be\nefficiently used for defect prediction.", "authors": ["Nikolaos Dimitriou", "Lampros Leontaris", "Thanasis Vafeiadis", "Dimosthenis Ioannidis", "Tracy Wotherspoon", "Gregory Tinker", "Dimitrios Tzovaras"], "category": "cs.CV", "comment": "21 pages, 5 figures", "img": "/static/thumbs/2002.10986v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10986v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10986v1", "published_time": "2/25/2020", "rawpid": "2002.10986", "tags": ["cs.CV", "cs.LG", "eess.IV"], "title": "A Deep Learning Framework for Simulation and Defect Prediction Applied\n  in Microelectronics"}, {"abstract": "Coordinate-wise minimization is a simple popular method for large-scale\noptimization. Unfortunately, for general (non-differentiable) convex problems\nit may not find global minima. We present a class of linear programs that\ncoordinate-wise minimization solves exactly. We show that dual LP relaxations\nof several well-known combinatorial optimization problems are in this class and\nthe method finds a global minimum with sufficient accuracy in reasonable\nruntimes. Moreover, for extensions of these problems that no longer are in this\nclass the method yields reasonably good suboptima. Though the presented LP\nrelaxations can be solved by more efficient methods (such as max-flow), our\nresults are theoretically non-trivial and can lead to new large-scale\noptimization algorithms in the future.", "authors": ["Tom\u00e1\u0161 Dlask", "Tom\u00e1\u0161 Werner"], "category": "math.OC", "comment": "", "img": "/static/thumbs/2001.10467v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2001.10467v4", "num_discussion": 0, "originally_published_time": "1/28/2020", "pid": "2001.10467v4", "published_time": "2/25/2020", "rawpid": "2001.10467", "tags": ["math.OC", "cs.CV"], "title": "A Class of Linear Programs Solvable by Coordinate-wise Minimization"}, {"abstract": "Although person re-identification (ReID) has achieved significant improvement\nrecently by enforcing part alignment, it is still a challenging task when it\ncomes to distinguishing visually similar identities or identifying occluded\nperson. In these scenarios, magnifying details in each part features and\nselectively fusing them together may provide a feasible solution. In this\npaper, we propose MagnifierNet, a novel network which accurately mines details\nfor each semantic region and selectively fuse all semantic feature\nrepresentations. Apart from conventional global branch, our proposed network is\ncomposed of a Semantic Regularization Branch (SRB) as learning regularizer and\na Semantic Fusion Branch (SFB) towards selectively semantic fusion. The SRB\nlearns with limited number of semantic regions randomly sampled in each batch,\nwhich forces the network to learn detailed representation for each semantic\nregion, and the SFB selectively fuses semantic region information in a\nsequential manner, focusing on beneficial information while neglecting\nirrelevant features or noises. In addition, we introduce a novel loss function\n\"Semantic Diversity Loss\" (SD Loss) to facilitate feature diversity and\nimproves regularization among all semantic regions. State-of-the-art\nperformance has been achieved on multiple datasets by large margins. Notably,\nwe improve SOTA on CUHK03-Labeled Dataset by 12.6% in mAP and 8.9% in Rank-1.\nWe also outperform existing works on CUHK03-Detected Dataset by 13.2% in mAP\nand 7.8% in Rank-1 respectively, which demonstrates the effectiveness of our\nmethod.", "authors": ["Yushi Lan", "Yuan Liu", "Maoqing Tian", "Xinchi Zhou", "Xuesen Zhang", "Shuai Yi", "Hongsheng Zhou"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2002.10979v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10979v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10979v1", "published_time": "2/25/2020", "rawpid": "2002.10979", "tags": ["cs.CV"], "title": "MagnifierNet: Towards Semantic Regularization and Fusion for Person\n  Re-identification"}, {"abstract": "A common source of defects in manufacturing miniature Printed Circuits Boards\n(PCB) is the attachment of silicon die or other wire bondable components on a\nLiquid Crystal Polymer (LCP) substrate. Typically, a conductive glue is\ndispensed prior to attachment with defects caused either by insufficient or\nexcessive glue. The current practice in electronics industry is to examine the\ndeposited glue by a human operator a process that is both time consuming and\ninefficient especially in preproduction runs where the error rate is high. In\nthis paper we propose a system that automates fault diagnosis by accurately\nestimating the volume of glue deposits before and even after die attachment. To\nthis end a modular scanning system is deployed that produces high resolution\npoint clouds whereas the actual estimation of glue volume is performed by\n(R)egression-Net (RNet), a 3D Convolutional Neural Network (3DCNN). RNet\noutperforms other deep architectures and is able to estimate the volume either\ndirectly from the point cloud of a glue deposit or more interestingly after die\nattachment when only a small part of glue is visible around each die. The\nentire methodology is evaluated under operational conditions where the proposed\nsystem achieves accurate results without delaying the manufacturing process.", "authors": ["Nikolaos Dimitriou", "Lampros Leontaris", "Thanasis Vafeiadis", "Dimosthenis Ioannidis", "Tracy Wotherspoon", "Gregory Tinker", "Dimitrios Tzovaras"], "category": "cs.CV", "comment": "10 pages, 12 figures. in IEEE Transactions on Industrial Electronics,\n  2019 (early access)", "img": "/static/thumbs/2002.10974v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10974v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10974v1", "published_time": "2/25/2020", "rawpid": "2002.10974", "tags": ["cs.CV", "cs.LG", "eess.IV"], "title": "Fault Diagnosis in Microelectronics Attachment via Deep Learning\n  Analysis of 3D Laser Scans"}, {"abstract": "Generative adversarial networks (GANs) have shown outstanding performance on\na broad range of computer vision problems, but often require enormous training\ndata and computational resources. Several works propose a transfer learning\nscheme to handle this issue, but they are prone to overfitting or too\nrestrictive to learn the distribution shift. In this paper, we find that simply\nfine-tuning the networks while freezing the lower layers of the discriminator\nsurprisingly works well. The simple baseline, freeze $D$, significantly\noutperforms the prior methods in both unconditional and conditional GANs, under\nStyleGAN and SNGAN-projection architectures and Animal Face, Anime Face, Oxford\nFlower, CUB-200-2011, and Caltech-256 datasets. Code and results are available\nin https://github.com/sangwoomo/freezeD.", "authors": ["Sangwoo Mo", "Minsu Cho", "Jinwoo Shin"], "category": "cs.CV", "comment": "Tech report; High resolution images are in\n  https://github.com/sangwoomo/freezeD", "img": "/static/thumbs/2002.10964v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10964v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10964v1", "published_time": "2/25/2020", "rawpid": "2002.10964", "tags": ["cs.CV", "cs.LG", "stat.ML"], "title": "Freeze Discriminator: A Simple Baseline for Fine-tuning GANs"}, {"abstract": "Model-free reinforcement learning is known to be memory and computation\nefficient and more amendable to large scale problems. In this paper, two\nmodel-free algorithms are introduced for learning infinite-horizon\naverage-reward Markov Decision Processes (MDPs). The first algorithm reduces\nthe problem to the discounted-reward version and achieves\n$\\mathcal{O}(T^{2/3})$ regret after $T$ steps, under the minimal assumption of\nweakly communicating MDPs. To our knowledge, this is the first model-free\nalgorithm for general MDPs in this setting. The second algorithm makes use of\nrecent advances in adaptive algorithms for adversarial multi-armed bandits and\nimproves the regret to $\\mathcal{O}(\\sqrt{T})$, albeit with a stronger ergodic\nassumption. This result significantly improves over the $\\mathcal{O}(T^{3/4})$\nregret achieved by the only existing model-free algorithm by Abbasi-Yadkori et\nal. (2019a) for ergodic MDPs in the infinite-horizon average-reward setting.", "authors": ["Chen-Yu Wei", "Mehdi Jafarnia-Jahromi", "Haipeng Luo", "Hiteshi Sharma", "Rahul Jain"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1910.07072v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1910.07072v2", "num_discussion": 0, "originally_published_time": "10/15/2019", "pid": "1910.07072v2", "published_time": "2/25/2020", "rawpid": "1910.07072", "tags": ["cs.LG", "cs.AI", "stat.ML"], "title": "Model-free Reinforcement Learning in Infinite-horizon Average-reward\n  Markov Decision Processes"}, {"abstract": "Pointer-generator network is an extremely popular method of text\nsummarization. More recent works in this domain still build on top of the\nbaseline pointer generator by augmenting a content selection phase, or by\ndecomposing the decoder into a contextual network and a language model.\nHowever, all such models that are based on the pointer-generator base\narchitecture cannot generate novel words in the summary and mostly copy words\nfrom the source text. In our work, we first thoroughly investigate why the\npointer-generator network is unable to generate novel words, and then address\nthat by adding an Out-of-vocabulary (OOV) penalty. This enables us to improve\nthe amount of novelty/abstraction significantly. We use normalized n-gram\nnovelty scores as a metric for determining the level of abstraction. Moreover,\nwe also report rouge scores of our model since most summarization models are\nevaluated with R-1, R-2, R-L scores.", "authors": ["Satyaki Chakraborty", "Xinya Li", "Sayak Chakraborty"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/2002.10959v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10959v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10959v1", "published_time": "2/25/2020", "rawpid": "2002.10959", "tags": ["cs.CL"], "title": "A more abstractive summarization model"}, {"abstract": "Pre-trained language models (e.g., BERT (Devlin et al., 2018) and its\nvariants) have achieved remarkable success in varieties of NLP tasks. However,\nthese models usually consist of hundreds of millions of parameters which brings\nchallenges for fine-tuning and online serving in real-life applications due to\nlatency and capacity constraints. In this work, we present a simple and\neffective approach to compress large Transformer (Vaswani et al., 2017) based\npre-trained models, termed as deep self-attention distillation. The small model\n(student) is trained by deeply mimicking the self-attention module, which plays\na vital role in Transformer networks, of the large model (teacher).\nSpecifically, we propose distilling the self-attention module of the last\nTransformer layer of the teacher, which is effective and flexible for the\nstudent. Furthermore, we introduce the scaled dot-product between values in the\nself-attention module as the new deep self-attention knowledge, in addition to\nthe attention distributions (i.e., the scaled dot-product of queries and keys)\nthat have been used in existing works. Moreover, we show that introducing a\nteacher assistant (Mirzadeh et al., 2019) also helps the distillation of large\npre-trained Transformer models. Experimental results demonstrate that our model\noutperforms state-of-the-art baselines in different parameter size of student\nmodels. In particular, it retains more than 99% accuracy on SQuAD 2.0 and\nseveral GLUE benchmark tasks using 50% of the Transformer parameters and\ncomputations of the teacher model. The code and models are publicly available\nat https://github.com/microsoft/unilm/tree/master/minilm", "authors": ["Wenhui Wang", "Furu Wei", "Li Dong", "Hangbo Bao", "Nan Yang", "Ming Zhou"], "category": "cs.CL", "comment": "Code and models:\n  https://github.com/microsoft/unilm/tree/master/minilm", "img": "/static/thumbs/2002.10957v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10957v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10957v1", "published_time": "2/25/2020", "rawpid": "2002.10957", "tags": ["cs.CL"], "title": "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression\n  of Pre-Trained Transformers"}, {"abstract": "Graph Neural Networks (GNNs) have made significant advances on several\nfundamental inference tasks. As a result, there is a surge of interest in using\nthese models for making potentially important decisions in high-regret\napplications. However, despite GNNs\u0027 impressive performance, it has been\nobserved that carefully crafted perturbations on graph structures (or nodes\nattributes) lead them to make wrong predictions. Presence of these adversarial\nexamples raises serious security concerns. Most of the existing robust GNN\ndesign/training methods are only applicable to white-box settings where model\nparameters are known and gradient based methods can be used by performing\nconvex relaxation of the discrete graph domain. More importantly, these methods\nare not efficient and scalable which make them infeasible in time sensitive\ntasks and massive graph datasets. To overcome these limitations, we propose a\ngeneral framework which leverages the greedy search algorithms and zeroth-order\nmethods to obtain robust GNNs in a generic and an efficient manner. On several\napplications, we show that the proposed techniques are significantly less\ncomputationally expensive and, in some cases, more robust than the\nstate-of-the-art methods making them suitable to large-scale problems which\nwere out of the reach of traditional robust training methods.", "authors": ["Kaidi Xu", "Sijia Liu", "Pin-Yu Chen", "Mengshu Sun", "Caiwen Ding", "Bhavya Kailkhura", "Xue Lin"], "category": "cs.LG", "comment": "Accepted by ICASSP 2020", "img": "/static/thumbs/2002.10947v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10947v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10947v1", "published_time": "2/25/2020", "rawpid": "2002.10947", "tags": ["cs.LG", "stat.ML"], "title": "Towards an Efficient and General Framework of Robust Training for Graph\n  Neural Networks"}, {"abstract": "Federated learning (FL) has emerged as a prominent distributed learning\nparadigm. FL entails some pressing needs for developing novel parameter\nestimation approaches with theoretical guarantees of convergence, which are\nalso communication efficient, differentially private and Byzantine resilient in\nthe heterogeneous data distribution settings. Quantization-based SGD solvers\nhave been widely adopted in FL and the recently proposed SIGNSGD with majority\nvote shows a promising direction. However, no existing methods enjoy all the\naforementioned properties. In this paper, we propose an intuitively-simple yet\ntheoretically-sound method based on SIGNSGD to bridge the gap. We present\nStochastic-Sign SGD which utilizes novel stochastic-sign based gradient\ncompressors enabling the aforementioned properties in a unified framework. We\nalso present an error-feedback variant of the proposed Stochastic-Sign SGD\nwhich further improves the learning performance in FL. We test the proposed\nmethod with extensive experiments using deep neural networks on the MNIST\ndataset. The experimental results corroborate the effectiveness of the proposed\nmethod.", "authors": ["Richeng Jin", "Yufan Huang", "Xiaofan He", "Huaiyu Dai", "Tianfu Wu"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10940v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10940v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10940v1", "published_time": "2/25/2020", "rawpid": "2002.10940", "tags": ["cs.LG", "stat.ML"], "title": "Stochastic-Sign SGD for Federated Learning with Theoretical Guarantees"}, {"abstract": "Domain adaptation approaches seek to learn from a source domain and\ngeneralize it to an unseen target domain. At present, the state-of-the-art\ndomain adaptation approaches for subjective text classification problems are\nsemi-supervised; and use unlabeled target data along with labeled source data.\nIn this paper, we propose a novel method for domain adaptation of single-task\ntext classification problems based on a simple but effective idea of\ndiversity-based generalization that does not require unlabeled target data.\nDiversity plays the role of promoting the model to better generalize and be\nindiscriminate towards domain shift by forcing the model not to rely on same\nfeatures for prediction. We apply this concept on the most explainable\ncomponent of neural networks, the attention layer. To generate sufficient\ndiversity, we create a multi-head attention model and infuse a diversity\nconstraint between the attention heads such that each head will learn\ndifferently. We further expand upon our model by tri-training and designing a\nprocedure with an additional diversity constraint between the attention heads\nof the tri-trained classifiers. Extensive evaluation using the standard\nbenchmark dataset of Amazon reviews and a newly constructed dataset of Crisis\nevents shows that our fully unsupervised method matches with the competing\nsemi-supervised baselines. Our results demonstrate that machine learning\narchitectures that ensure sufficient diversity can generalize better;\nencouraging future research to design ubiquitously usable learning models\nwithout using unlabeled target data.", "authors": ["Jitin Krishnan", "Hemant Purohit", "Huzefa Rangwala"], "category": "cs.LG", "comment": "15 pages, 3 figures, Source Code Available", "img": "/static/thumbs/2002.10937v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10937v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10937v1", "published_time": "2/25/2020", "rawpid": "2002.10937", "tags": ["cs.LG", "cs.CL", "stat.ML"], "title": "Diversity-Based Generalization for Neural Unsupervised Text\n  Classification under Domain Shift"}, {"abstract": "Classification of whole-brain functional connectivity MRI data with\nconvolutional neural networks (CNNs) has shown promise, but the complexity of\nthese models impedes understanding of which aspects of brain activity\ncontribute to classification. While visualization techniques have been\ndeveloped to interpret CNNs, bias inherent in the method of encoding abstract\ninput data, as well as the natural variance of deep learning models, detract\nfrom the accuracy of these techniques. We introduce a stochastic encoding\nmethod in an ensemble of CNNs to classify functional connectomes by gender. We\napplied our method to resting-state and task data from the UK BioBank, using\ntwo visualization techniques to measure the salience of three brain networks\ninvolved in task- and resting-states, and their interaction. To regress\nconfounding factors such as head motion, age, and intracranial volume, we\nintroduced a multivariate balancing algorithm to ensure equal distributions of\nsuch covariates between classes in our data. We achieved a final AUROC of\n0.8459. We found that resting-state data classifies more accurately than task\ndata, with the inner salience network playing the most important role of the\nthree networks overall in classification of resting-state data and connections\nto the central executive network in task data.", "authors": ["Matthew Leming", "John Suckling"], "category": "q-bio.NC", "comment": "", "img": "/static/thumbs/2002.10936v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10936v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10936v1", "published_time": "2/25/2020", "rawpid": "2002.10936", "tags": ["q-bio.NC", "cs.LG", "stat.ML"], "title": "Stochastic encoding of graphs in deep learning allows for complex\n  analysis of gender classification in resting-state and task functional brain\n  networks from the UK Biobank"}, {"abstract": "Social engineers attempt to manipulate users into undertaking actions such as\ndownloading malware by clicking links or providing access to money or sensitive\ninformation. Natural language processing, computational sociolinguistics, and\nmedia-specific structural clues provide a means for detecting both the ask\n(e.g., buy gift card) and the risk/reward implied by the ask, which we call\nframing (e.g., lose your job, get a raise). We apply linguistic resources such\nas Lexical Conceptual Structure to tackle ask detection and also leverage\nstructural clues such as links and their proximity to identified asks to\nimprove confidence in our results. Our experiments indicate that the\nperformance of ask detection, framing detection, and identification of the top\nask is improved by linguistically motivated classes coupled with structural\nclues such as links. Our approach is implemented in a system that informs users\nabout social engineering risk situations.", "authors": ["Bonnie J. Dorr", "Archna Bhatia", "Adam Dalton", "Brodie Mather", "Bryanna Hebenstreit", "Sashank Santhanam", "Zhuo Cheng", "Samira Shaikh", "Alan Zemel", "Tomek Strzalkowski"], "category": "cs.CL", "comment": "Accepted at AAAI 2020", "img": "/static/thumbs/2002.10931v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10931v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10931v1", "published_time": "2/25/2020", "rawpid": "2002.10931", "tags": ["cs.CL"], "title": "Detecting Asks in SE attacks: Impact of Linguistic and Structural\n  Knowledge"}, {"abstract": "Many binary classification problems minimize misclassification above (or\nbelow) a threshold. We show that instances of ranking problems, accuracy at the\ntop or hypothesis testing may be written in this form. We propose a general\nframework to handle these classes of problems and show which known methods\n(both known and newly proposed) fall into this framework. We provide a\ntheoretical analysis of this framework and mention selected possible pitfalls\nthe methods may encounter. We suggest several numerical improvements including\nthe implicit derivative and stochastic gradient descent. We provide an\nextensive numerical study. Based both on the theoretical properties and\nnumerical experiments, we conclude the paper by suggesting which method should\nbe used in which situation.", "authors": ["Luk\u00e1\u0161 Adam", "V\u00e1clav M\u00e1cha", "V\u00e1clav \u0160m\u00eddl", "Tom\u00e1\u0161 Pevn\u00fd"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10923v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10923v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10923v1", "published_time": "2/25/2020", "rawpid": "2002.10923", "tags": ["cs.LG", "stat.ML", "90C15, 90C26, 49M05"], "title": "General Framework for Binary Classification on Top Samples"}, {"abstract": "Diffusion MRI (dMRI) is a unique imaging technique for in vivo\ncharacterization of tissue microstructure and white matter pathways. However,\nits relatively long acquisition time implies greater motion artifacts when\nimaging, for example, infants and Parkinson\u0027s disease patients. To accelerate\ndMRI acquisition, we propose in this paper (i) a diffusion encoding scheme,\ncalled Slice-Interleaved Diffusion Encoding (SIDE), that interleaves each\ndiffusion-weighted (DW) image volume with slices that are encoded with\ndifferent diffusion gradients, essentially allowing the slice-undersampling of\nimage volume associated with each diffusion gradient to significantly reduce\nacquisition time, and (ii) a method based on deep learning for effective\nreconstruction of DW images from the highly slice-undersampled data. Evaluation\nbased on the Human Connectome Project (HCP) dataset indicates that our method\ncan achieve a high acceleration factor of up to 6 with minimal information\nloss. Evaluation using dMRI data acquired with SIDE acquisition demonstrates\nthat it is possible to accelerate the acquisition by as much as 50 folds when\ncombined with multi-band imaging.", "authors": ["Yoonmi Hong", "Wei-Tang Chang", "Geng Chen", "Ye Wu", "Weili Lin", "Dinggang Shen", "Pew-Thian Yap"], "category": "physics.med-ph", "comment": "", "img": "/static/thumbs/2002.10908v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10908v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10908v1", "published_time": "2/25/2020", "rawpid": "2002.10908", "tags": ["physics.med-ph", "cs.LG", "eess.IV"], "title": "Multifold Acceleration of Diffusion MRI via Slice-Interleaved Diffusion\n  Encoding (SIDE)"}, {"abstract": "This paper considers if a reward function learned via inverse reinforcement\nfrom a human expert can be used as a feedback intervention to alter future\nhuman performance as desired (i.e., human to human apprenticeship learning). To\nlearn reward functions two new algorithms are developed: a kernel-based inverse\nreinforcement learning algorithm and a Monte Carlo reinforcement learning\nalgorithm. The algorithms are benchmarked against well-known alternatives\nwithin their respective corpus and are shown to outperform in terms of\nefficiency and optimality. To test the feedback intervention two randomized\nexperiments are performed with 3,256 human participants. The experimental\nresults demonstrate with significance that the rewards learned from \"expert\"\nindividuals are effective as feedback interventions. In addition to the\nalgorithmic contributions and successful experiments, the paper also describes\nthree reward function modifications to improve reward function feedback\ninterventions for humans.", "authors": ["Mark A. Rucker", "Layne T. Watson", "Laura E. Barnes", "Matthew S. Gerber"], "category": "cs.LG", "comment": "31 pages, 23 figures, Submitted to Journal of Artificial Intelligence\n  Research, \"for source code, ...", "img": "/static/thumbs/2002.10904v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10904v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10904v1", "published_time": "2/25/2020", "rawpid": "2002.10904", "tags": ["cs.LG", "stat.ML"], "title": "Human Apprenticeship Learning via Kernel-based Inverse Reinforcement\n  Learning"}, {"abstract": "Lexical relations describe how concepts are semantically related, in the form\nof relation triples. The accurate prediction of lexical relations between\nconcepts is challenging, due to the sparsity of patterns indicating the\nexistence of such relations. We propose the Knowledge-Enriched Meta-Learning\n(KEML) framework to address the task of lexical relation classification. In\nKEML, the LKB-BERT (Lexical Knowledge Base-BERT) model is presented to learn\nconcept representations from massive text corpora, with rich lexical knowledge\ninjected by distant supervision. A probabilistic distribution of auxiliary\ntasks is defined to increase the model\u0027s ability to recognize different types\nof lexical relations. We further combine a meta-learning process over the\nauxiliary task distribution and supervised learning to train the neural lexical\nrelation classifier. Experiments over multiple datasets show that KEML\noutperforms state-of-the-art methods.", "authors": ["Chengyu Wang", "Minghui Qiu", "Jun Huang", "Xiaofeng He"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/2002.10903v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10903v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10903v1", "published_time": "2/25/2020", "rawpid": "2002.10903", "tags": ["cs.CL"], "title": "KEML: A Knowledge-Enriched Meta-Learning Framework for Lexical Relation\n  Classification"}, {"abstract": "Large pre-trained sentence encoders like BERT start a new chapter in natural\nlanguage processing. A common practice to apply pre-trained BERT to sequence\nclassification tasks (e.g., classification of sentences or sentence pairs) is\nby feeding the embedding of [CLS] token (in the last layer) to a task-specific\nclassification layer, and then fine tune the model parameters of BERT and\nclassifier jointly. In this paper, we conduct systematic analysis over several\nsequence classification datasets to examine the embedding values of [CLS] token\nbefore the fine tuning phase, and present the biased embedding distribution\nissue---i.e., embedding values of [CLS] concentrate on a few dimensions and are\nnon-zero centered. Such biased embedding brings challenge to the optimization\nprocess during fine-tuning as gradients of [CLS] embedding may explode and\nresult in degraded model performance. We further propose several simple yet\neffective normalization methods to modify the [CLS] embedding during the\nfine-tuning. Compared with the previous practice, neural classification model\nwith the normalized embedding shows improvements on several text classification\ntasks, demonstrates the effectiveness of our method.", "authors": ["Wenxuan Zhou", "Junyi Du", "Xiang Ren"], "category": "cs.CL", "comment": "work in progress", "img": "/static/thumbs/1911.03918v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1911.03918v2", "num_discussion": 0, "originally_published_time": "11/10/2019", "pid": "1911.03918v2", "published_time": "2/25/2020", "rawpid": "1911.03918", "tags": ["cs.CL"], "title": "Improving BERT Fine-tuning with Embedding Normalization"}, {"abstract": "LIDAR semantic segmentation, which assigns a semantic label to each 3D point\nmeasured by the LIDAR, is becoming an essential task for many robotic\napplications such as autonomous driving. Fast and efficient semantic\nsegmentation methods are needed to match the strong computational and temporal\nrestrictions of many of these real-world applications.\n  This work presents 3D-MiniNet, a novel approach for LIDAR semantic\nsegmentation that combines 3D and 2D learning layers. It first learns a 2D\nrepresentation from the raw points through a novel projection which extracts\nlocal and global information from the 3D data. This representation is fed to an\nefficient 2D Fully Convolutional Neural Network (FCNN) that produces a 2D\nsemantic segmentation. These 2D semantic labels are re-projected back to the 3D\nspace and enhanced through a post-processing module. The main novelty in our\nstrategy relies on the projection learning module. Our detailed ablation study\nshows how each component contributes to the final performance of 3D-MiniNet. We\nvalidate our approach on well known public benchmarks (SemanticKITTI and\nKITTI), where 3D-MiniNet gets state-of-the-art results while being faster and\nmore parameter-efficient than previous methods.", "authors": ["I\u00f1igo Alonso", "Luis Riazuelo", "Luis Montesano", "Ana C. Murillo"], "category": "cs.CV", "comment": "8 pages, 4 figures", "img": "/static/thumbs/2002.10893v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10893v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10893v1", "published_time": "2/25/2020", "rawpid": "2002.10893", "tags": ["cs.CV"], "title": "3D-MiniNet: Learning a 2D Representation from Point Clouds for Fast and\n  Efficient 3D LIDAR Semantic Segmentation"}, {"abstract": "We present PointAugment, a new auto-augmentation framework that automatically\noptimizes and augments point cloud samples to enrich the data diversity when we\ntrain a classification network. Different from existing auto-augmentation\nmethods for 2D images, PointAugment is sample-aware and takes an adversarial\nlearning strategy to jointly optimize an augmentor network and a classifier\nnetwork, such that the augmentor can learn to produce augmented samples that\nbest fit the classifier. Moreover, we formulate a learnable point augmentation\nfunction with a shape-wise transformation and a point-wise displacement, and\ncarefully design loss functions to adopt the augmented samples based on the\nlearning progress of the classifier. Extensive experiments also confirm\nPointAugment\u0027s effectiveness and robustness to improve the performance of\nvarious networks on shape classification and retrieval.", "authors": ["Ruihui Li", "Xianzhi Li", "Pheng-Ann Heng", "Chi-Wing Fu"], "category": "cs.CV", "comment": "Accepted by CVPR 2020; code is\n  https://github.com/liruihui/PointAugment/", "img": "/static/thumbs/2002.10876v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10876v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10876v1", "published_time": "2/25/2020", "rawpid": "2002.10876", "tags": ["cs.CV"], "title": "PointAugment: an Auto-Augmentation Framework for Point Cloud\n  Classification"}, {"abstract": "Feature pyramid network (FPN) based models, which fuse the semantics and\nsalient details in a progressive manner, have been proven highly effective in\nsalient object detection. However, it is observed that these models often\ngenerate saliency maps with incomplete object structures or unclear object\nboundaries, due to the \\emph{indirect} information propagation among distant\nlayers that makes such fusion structure less effective. In this work, we\npropose a novel Cross-layer Feature Pyramid Network (CFPN), in which direct\ncross-layer communication is enabled to improve the progressive fusion in\nsalient object detection. Specifically, the proposed network first aggregates\nmulti-scale features from different layers into feature maps that have access\nto both the high- and low-level information. Then, it distributes the\naggregated features to all the involved layers to gain access to richer\ncontext. In this way, the distributed features per layer own both semantics and\nsalient details from all other layers simultaneously, and suffer reduced loss\nof important information. Extensive experimental results over six widely used\nsalient object detection benchmarks and with three popular backbones clearly\ndemonstrate that CFPN can accurately locate fairly complete salient regions and\neffectively segment the object boundaries.", "authors": ["Zun Li", "Congyan Lang", "Junhao Liew", "Qibin Hou", "Yidong Li", "Jiashi Feng"], "category": "cs.CV", "comment": "10 pages, 7 figures", "img": "/static/thumbs/2002.10864v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10864v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10864v1", "published_time": "2/25/2020", "rawpid": "2002.10864", "tags": ["cs.CV", "eess.IV"], "title": "Cross-layer Feature Pyramid Network for Salient Object Detection"}, {"abstract": "This paper provides a pair similarity optimization viewpoint on deep feature\nlearning, aiming to maximize the within-class similarity $s_p$ and minimize the\nbetween-class similarity $s_n$. We find a majority of loss functions, including\nthe triplet loss and the softmax plus cross-entropy loss, embed $s_n$ and $s_p$\ninto similarity pairs and seek to reduce $(s_n-s_p)$. Such an optimization\nmanner is inflexible, because the penalty strength on every single similarity\nscore is restricted to be equal. Our intuition is that if a similarity score\ndeviates far from the optimum, it should be emphasized. To this end, we simply\nre-weight each similarity to highlight the less-optimized similarity scores. It\nresults in a Circle loss, which is named due to its circular decision boundary.\nThe Circle loss has a unified formula for two elemental deep feature learning\napproaches, i.e. learning with class-level labels and pair-wise labels.\nAnalytically, we show that the Circle loss offers a more flexible optimization\napproach towards a more definite convergence target, compared with the loss\nfunctions optimizing $(s_n-s_p)$. Experimentally, we demonstrate the\nsuperiority of the Circle loss on a variety of deep feature learning tasks. On\nface recognition, person re-identification, as well as several fine-grained\nimage retrieval datasets, the achieved performance is on par with the state of\nthe art.", "authors": ["Yifan Sun", "Changmao Cheng", "Yuhan Zhang", "Chi Zhang", "Liang Zheng", "Zhongdao Wang", "Yichen Wei"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2002.10857v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10857v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10857v1", "published_time": "2/25/2020", "rawpid": "2002.10857", "tags": ["cs.CV"], "title": "Circle Loss: A Unified Perspective of Pair Similarity Optimization"}, {"abstract": "Topic models are widely used to discover the latent representation of a set\nof documents. The two canonical models are latent Dirichlet allocation, and\nGaussian latent Dirichlet allocation, where the former uses multinomial\ndistributions over words, and the latter uses multivariate Gaussian\ndistributions over pre-trained word embedding vectors as the latent topic\nrepresentations, respectively. Compared with latent Dirichlet allocation,\nGaussian latent Dirichlet allocation is limited in the sense that it does not\ncapture the polysemy of a word such as ``bank.\u0027\u0027 In this paper, we show that\nGaussian latent Dirichlet allocation could recover the ability to capture\npolysemy by introducing a hierarchical structure in the set of topics that the\nmodel can use to represent a given document. Our Gaussian hierarchical latent\nDirichlet allocation significantly improves polysemy detection compared with\nGaussian-based models and provides more parsimonious topic representations\ncompared with hierarchical latent Dirichlet allocation. Our extensive\nquantitative experiments show that our model also achieves better topic\ncoherence and held-out document predictive accuracy over a wide range of corpus\nand word embedding vectors.", "authors": ["Takahiro Yoshida", "Ryohei Hisano", "Takaaki Ohnishi"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/2002.10855v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10855v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10855v1", "published_time": "2/25/2020", "rawpid": "2002.10855", "tags": ["stat.ML", "cs.LG"], "title": "Gaussian Hierarchical Latent Dirichlet Allocation: Bringing Polysemy\n  Back"}, {"abstract": "In this paper, we consider a novel task, Spatio-Temporal Video Grounding for\nMulti-Form Sentences (STVG). Given an untrimmed video and a\ndeclarative/interrogative sentence depicting an object, STVG aims to localize\nthe spatiotemporal tube of the queried object. STVG has two challenging\nsettings: (1) We need to localize spatio-temporal object tubes from untrimmed\nvideos, where the object may only exist in a very small segment of the video;\n(2) We deal with multi-form sentences, including the declarative sentences with\nexplicit objects and interrogative sentences with unknown objects. Existing\nmethods cannot tackle the STVG task due to the ineffective tube pre-generation\nand the lack of object relationship modeling. Thus, we then propose a novel\nSpatio-Temporal Graph Reasoning Network (STGRN) for this task. First, we build\na spatio-temporal region graph to capture the region relationships with\ntemporal object dynamics, which involves the implicit and explicit spatial\nsubgraphs in each frame and the temporal dynamic subgraph across frames. We\nthen incorporate textual clues into the graph and develop the multi-step\ncross-modal graph reasoning. Next, we introduce a spatio-temporal localizer\nwith a dynamic selection method to directly retrieve the spatiotemporal tubes\nwithout tube pre-generation. Moreover, we contribute a large-scale video\ngrounding dataset VidSTG based on video relation dataset VidOR. The extensive\nexperiments demonstrate the effectiveness of our method.", "authors": ["Zhu Zhang", "Zhou Zhao", "Yang Zhao", "Qi Wang", "Huasheng Liu", "Lianli Gao"], "category": "cs.CV", "comment": "This paper is accepted by CVPR 2020", "img": "/static/thumbs/2001.06891v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2001.06891v2", "num_discussion": 0, "originally_published_time": "1/19/2020", "pid": "2001.06891v2", "published_time": "2/25/2020", "rawpid": "2001.06891", "tags": ["cs.CV"], "title": "Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form\n  Sentences"}, {"abstract": "We present SMILES-embeddings derived from the internal encoder state of a\nTransformer [1] model trained to canonize SMILES as a Seq2Seq problem. Using a\nCharNN [2] architecture upon the embeddings results in higher quality\ninterpretable QSAR/QSPR models on diverse benchmark datasets including\nregression and classification tasks. The proposed Transformer-CNN method uses\nSMILES augmentation for training and inference, and thus the prognosis is based\non an internal consensus. That both the augmentation and transfer learning are\nbased on embeddings allows the method to provide good results for small\ndatasets. We discuss the reasons for such effectiveness and draft future\ndirections for the development of the method. The source code and the\nembeddings needed to train a QSAR model are available on\nhttps://github.com/bigchem/transformer-cnn. The repository also has a\nstandalone program for QSAR prognosis which calculates individual atoms\ncontributions, thus interpreting the model\u0027s result. OCHEM [3] environment\n(https://ochem.eu) hosts the on-line implementation of the method proposed.", "authors": ["Pavel Karpov", "Guillaume Godin", "Igor V. Tetko"], "category": "q-bio.QM", "comment": "", "img": "/static/thumbs/1911.06603v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1911.06603v2", "num_discussion": 0, "originally_published_time": "10/21/2019", "pid": "1911.06603v2", "published_time": "2/25/2020", "rawpid": "1911.06603", "tags": ["q-bio.QM", "cs.CL", "cs.LG"], "title": "Transformer-CNN: Fast and Reliable tool for QSAR"}, {"abstract": "We explore a keyword-based spoken language understanding system, in which the\nintent of the user can directly be derived from the detection of a sequence of\nkeywords in the query. In this paper, we focus on an open-vocabulary keyword\nspotting method, allowing the user to define their own keywords without having\nto retrain the whole model. We describe the different design choices leading to\na fast and small-footprint system, able to run on tiny devices, for any\narbitrary set of user-defined keywords, without training data specific to those\nkeywords. The model, based on a quantized long short-term memory (LSTM) neural\nnetwork, trained with connectionist temporal classification (CTC), weighs less\nthan 500KB. Our approach takes advantage of some properties of the predictions\nof CTC-trained networks to calibrate the confidence scores and implement a fast\ndetection algorithm. The proposed system outperforms a standard keyword-filler\nmodel approach.", "authors": ["Th\u00e9odore Bluche", "Ma\u00ebl Primet", "Thibault Gisselbrecht"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/2002.10851v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10851v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10851v1", "published_time": "2/25/2020", "rawpid": "2002.10851", "tags": ["cs.CL"], "title": "Small-Footprint Open-Vocabulary Keyword Spotting with Quantized LSTM\n  Networks"}, {"abstract": "In image-to-image translation the goal is to learn a mapping from one image\ndomain to another. In the case of supervised approaches the mapping is learned\nfrom paired samples. However, collecting large sets of image pairs is often\neither prohibitively expensive or not possible. As a result, in recent years\nmore attention has been given to techniques that learn the mapping from\nunpaired sets.\n  In our work, we show that injecting implicit pairs into unpaired sets\nstrengthens the mapping between the two domains, improves the compatibility of\ntheir distributions, and leads to performance boosting of unsupervised\ntechniques by over 14% across several measurements.\n  The competence of the implicit pairs is further pronounced with the use of\npseudo-pairs, i.e., paired samples which only approximate a real pair. We\ndemonstrate the effect of the approximated implicit samples on image-to-image\ntranslation problems, where such pseudo-pairs may be synthesized in one\ndirection, but not in the other. We further show that pseudo-pairs are\nsignificantly more effective as implicit pairs in an unpaired setting, than\ndirectly using them explicitly in a paired setting.", "authors": ["Yiftach Ginger", "Dov Danon", "Hadar Averbuch-Elor", "Daniel Cohen-Or"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1904.06913v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1904.06913v2", "num_discussion": 0, "originally_published_time": "4/15/2019", "pid": "1904.06913v2", "published_time": "2/25/2020", "rawpid": "1904.06913", "tags": ["cs.CV", "cs.LG"], "title": "Implicit Pairs for Boosting Unpaired Image-to-Image Translation"}, {"abstract": "Dominance move (DoM) is a binary quality indicator to compare solution sets\nin multiobjective optimization. The indicator allows a more natural and\nintuitive relation when comparing solution sets. It is Pareto compliant and\ndoes not demand any parameters or reference sets. In spite of its advantages,\nthe combinatorial calculation nature is a limitation. The original formulation\npresents an efficient method to calculate it in a biobjective case only. This\nwork presents an assignment formulation to calculate DoM in problems with three\nobjectives or more. Some initial experiments, in the biobjective space, were\ndone to present the model correctness. Next, other experiments, using three\ndimensions, were also done to show how DoM could be compared with other\nindicators: inverted generational distance (IGD) and hypervolume (HV). Results\nshow the assignment formulation for DoM is valid for more than three\nobjectives. However, there are some strengths and weaknesses, which are\ndiscussed and detailed. Some notes, considerations, and future research paths\nconclude this work.", "authors": ["Claudio Lucio do Val Lopes", "Fl\u00e1vio Vin\u00edcius Cruzeiro Martins", "Elizabeth F. Wanner"], "category": "cs.NE", "comment": "", "img": "/static/thumbs/2002.10842v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10842v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10842v1", "published_time": "2/25/2020", "rawpid": "2002.10842", "tags": ["cs.NE"], "title": "An Assignment Problem Formulation for Dominance Move Indicator"}, {"abstract": "Convolutional neural networks (CNNs), in a few decades, have outperformed the\nexisting state of the art methods in classification context. However, in the\nway they were formalised, CNNs are bound to operate on euclidean spaces.\nIndeed, convolution is a signal operation that are defined on euclidean spaces.\nThis has restricted deep learning main use to euclidean-defined data such as\nsound or image. And yet, numerous computer application fields (among which\nnetwork analysis, computational social science, chemo-informatics or computer\ngraphics) induce non-euclideanly defined data such as graphs, networks or\nmanifolds. In this paper we propose a new convolution neural network\narchitecture, defined directly into graph space. Convolution and pooling\noperators are defined in graph domain. We show its usability in a\nback-propagation context. Experimental results show that our model performance\nis at state of the art level on simple tasks. It shows robustness with respect\nto graph domain changes and improvement with respect to other euclidean and\nnon-euclidean convolutional architectures.", "authors": ["Maxime Martineau", "Romain Raveaux", "Donatello Conte", "Gilles Venturini"], "category": "cs.CV", "comment": "arXiv admin note: text overlap with arXiv:1611.08402 by other authors", "img": "/static/thumbs/2002.09285v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.09285v2", "num_discussion": 0, "originally_published_time": "2/20/2020", "pid": "2002.09285v2", "published_time": "2/25/2020", "rawpid": "2002.09285", "tags": ["cs.CV", "cs.LG", "cs.NE"], "title": "A Convolutional Neural Network into graph space"}, {"abstract": "We propose a least-squares formulation to the noisy hand-eye calibration\nproblem using dual-quaternions, and introduce efficient algorithms to find the\nexact optimal solution, based on analytic properties of the problem, avoiding\nnon-linear optimization. We further present simple analytic approximate\nsolutions which provide remarkably good estimations compared to the exact\nsolution. In addition, we show how to generalize our solution to account for a\ngiven extrinsic prior in the cost function. To the best of our knowledge our\nalgorithm is the most efficient approach to optimally solve the hand-eye\ncalibration problem.", "authors": ["Amit Dekel", "Linus H\u00e4renstam-Nielsen", "Sergio Caccamo"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2002.10838v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10838v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10838v1", "published_time": "2/25/2020", "rawpid": "2002.10838", "tags": ["cs.CV", "cs.RO"], "title": "Optimal least-squares solution to the hand-eye calibration problem"}, {"abstract": "Inferring causal effects of a treatment, intervention or policy from\nobservational data is central to many applications. However, state-of-the-art\nmethods for causal inference seldom consider the possibility that covariates\nhave missing values, which is ubiquitous in many real-world analyses. Missing\ndata greatly complicate causal inference procedures as they require an adapted\nunconfoundedness hypothesis which can be difficult to justify in practice. We\ncircumvent this issue by considering latent confounders whose distribution is\nlearned through variational autoencoders adapted to missing values. They can be\nused either as a pre-processing step prior to causal inference but we also\nsuggest to embed them in a multiple imputation strategy to take into account\nthe variability due to missing values. Numerical experiments demonstrate the\neffectiveness of the proposed methodology especially for non-linear models\ncompared to competitors.", "authors": ["Imke Mayer", "Julie Josse", "F\u00e9lix Raimundo", "Jean-Philippe Vert"], "category": "stat.ME", "comment": "", "img": "/static/thumbs/2002.10837v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10837v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10837v1", "published_time": "2/25/2020", "rawpid": "2002.10837", "tags": ["stat.ME", "cs.LG", "stat.ML"], "title": "MissDeepCausal: Causal Inference from Incomplete Data Using Deep Latent\n  Variable Models"}, {"abstract": "Gesture recognition application over 802.11 ad/y waveforms is developed.\nSimultaneous gestures of slider-control and two-finger gesture for switching\nare detected based on Golay sequences of channel estimation fields of the\npackets.", "authors": ["Eran Hof", "Amichai Sanderovich", "Evyatar Hemo"], "category": "eess.SP", "comment": "", "img": "/static/thumbs/2002.10836v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10836v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10836v1", "published_time": "2/25/2020", "rawpid": "2002.10836", "tags": ["eess.SP", "cs.CV"], "title": "Gesture recognition with 60GHz 802.11 waveforms"}, {"abstract": "Pre-trained language models such as BERT have recently contributed to\nsignificant advances in Natural Language Processing tasks. Interestingly, while\nmultilingual BERT models have demonstrated impressive results, recent works\nhave shown how monolingual BERT can also be competitive in zero-shot\ncross-lingual settings. This suggests that the abstractions learned by these\nmodels can transfer across languages, even when trained on monolingual data. In\nthis paper, we investigate whether such generalization potential applies to\nother modalities, such as vision: does BERT contain abstractions that\ngeneralize beyond text? We introduce BERT-gen, an architecture for text\ngeneration based on BERT, able to leverage on either mono- or multi- modal\nrepresentations. The results reported under different configurations indicate a\npositive answer to our research question, and the proposed model obtains\nsubstantial improvements over the state-of-the-art on two established Visual\nQuestion Generation datasets.", "authors": ["Thomas Scialom", "Patrick Bordes", "Paul-Alexis Dray", "Jacopo Staiano", "Patrick Gallinari"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/2002.10832v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10832v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10832v1", "published_time": "2/25/2020", "rawpid": "2002.10832", "tags": ["cs.CL", "cs.CV", "cs.LG"], "title": "BERT Can See Out of the Box: On the Cross-modal Transferability of Text\n  Representations"}, {"abstract": "Growing needs in localising audiovisual content in multiple languages through\nsubtitles call for the development of automatic solutions for human subtitling.\nNeural Machine Translation (NMT) can contribute to the automatisation of\nsubtitling, facilitating the work of human subtitlers and reducing turn-around\ntimes and related costs. NMT requires high-quality, large, task-specific\ntraining data. The existing subtitling corpora, however, are missing both\nalignments to the source language audio and important information about\nsubtitle breaks. This poses a significant limitation for developing efficient\nautomatic approaches for subtitling, since the length and form of a subtitle\ndirectly depends on the duration of the utterance. In this work, we present\nMuST-Cinema, a multilingual speech translation corpus built from TED subtitles.\nThe corpus is comprised of (audio, transcription, translation) triplets.\nSubtitle breaks are preserved by inserting special symbols. We show that the\ncorpus can be used to build models that efficiently segment sentences into\nsubtitles and propose a method for annotating existing subtitling corpora with\nsubtitle breaks, conforming to the constraint of length.", "authors": ["Alina Karakanta", "Matteo Negri", "Marco Turchi"], "category": "cs.CL", "comment": "Accepted at LREC 2020", "img": "/static/thumbs/2002.10829v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10829v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10829v1", "published_time": "2/25/2020", "rawpid": "2002.10829", "tags": ["cs.CL"], "title": "MuST-Cinema: a Speech-to-Subtitles corpus"}, {"abstract": "This paper considers learning deep features from long-tailed data. We observe\nthat in the deep feature space, the head classes and the tail classes present\ndifferent distribution patterns. The head classes have a relatively large\nspatial span, while the tail classes have significantly small spatial span, due\nto the lack of intra-class diversity. This uneven distribution between head and\ntail classes distorts the overall feature space, which compromises the\ndiscriminative ability of the learned features. Intuitively, we seek to expand\nthe distribution of the tail classes by transferring from the head classes, so\nas to alleviate the distortion of the feature space. To this end, we propose to\nconstruct each feature into a \"feature cloud\". If a sample belongs to a tail\nclass, the corresponding feature cloud will have relatively large distribution\nrange, in compensation to its lack of diversity. It allows each tail sample to\npush the samples from other classes far away, recovering the intra-class\ndiversity of tail classes. Extensive experimental evaluations on person\nre-identification and face recognition tasks confirm the effectiveness of our\nmethod.", "authors": ["Jialun Liu", "Yifan Sun", "Chuchu Han", "Zhaopeng Dou", "Wenhui Li"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2002.10826v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10826v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10826v1", "published_time": "2/25/2020", "rawpid": "2002.10826", "tags": ["cs.CV"], "title": "Deep Representation Learning on Long-tailed Data: A Learnable Embedding\n  Augmentation Perspective"}, {"abstract": "Additionally to the extensive use in clinical medicine, biological age (BA)\nin legal medicine is used to assess unknown chronological age (CA) in\napplications where identification documents are not available. Automatic\nmethods for age estimation proposed in the literature are predicting point\nestimates, which can be misleading without the quantification of predictive\nuncertainty. In our multi-factorial age estimation method from MRI data, we\nused the Variational Inference approach to estimate the uncertainty of a\nBayesian CNN model. Distinguishing model uncertainty from data uncertainty, we\ninterpreted data uncertainty as biological variation, i.e. the range of\npossible CA of subjects having the same BA.", "authors": ["Stefan Eggenreich", "Christian Payer", "Martin Urschler", "Darko \u0160tern"], "category": "eess.IV", "comment": "accepted at Medical Imaging Meets NeurIPS 2019", "img": "/static/thumbs/2002.10819v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10819v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10819v1", "published_time": "2/25/2020", "rawpid": "2002.10819", "tags": ["eess.IV", "cs.LG", "stat.ML"], "title": "Variational Inference and Bayesian CNNs for Uncertainty Estimation in\n  Multi-Factorial Bone Age Prediction"}, {"abstract": "We develop a framework for the adaptive model predictive control of a linear\nsystem with unknown parameters and arbitrary bounded costs, in a critical\nsetting where failures are costly and should be prevented at all time. Our\napproach builds on two ideas: first, we incorporate prior knowledge of the\ndynamics in the form of a known structure that shapes uncertainty, which can be\ntightened as we collect interaction data by building high-confidence regions\nthrough least-square regression. Second, in order to handle this uncertainty we\nformulate a robust control objective. Leveraging tools from the interval\nprediction literature, we convert the confidence regions on parameters into\nconfidence sets on trajectories induced by the controls. These controls are\nthen optimised resorting to tree-based planning methods. We eventually relax\nour modeling assumptions with a multi-model extension based on a data-driven\nrobust model selection mechanism. The full procedure is designed to produce\nreasonable and safe behaviours at deployment while recovering an asymptotic\noptimality. We illustrate it on a practical case of autonomous driving at a\ncrossroads intersection among vehicles with uncertain behaviours.", "authors": ["Edouard Leurent", "Denis Efimov", "Odalric-Ambrym Maillard"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10816v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10816v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10816v1", "published_time": "2/25/2020", "rawpid": "2002.10816", "tags": ["cs.LG", "cs.SY", "eess.SY", "stat.ML"], "title": "Robust Estimation, Prediction and Control with Linear Dynamics and\n  Generic Costs"}, {"abstract": "Conditioning analysis uncovers the landscape of optimization objective by\nexploring the spectrum of its curvature matrix. It is well explored\ntheoretically for linear models. We extend this analysis to deep neural\nnetworks (DNNs). To this end, we propose a layer-wise conditioning analysis\nthat explores the optimization landscape with respect to each layer\nindependently. Such an analysis is theoretically supported under mild\nassumptions that approximately hold in practice. Based on our analysis, we show\nthat batch normalization (BN) can adjust the magnitude of the layer\nactivations/gradients, and thus stabilizes the training. However, such a\nstabilization can result in a false impression of a local minimum, which\nsometimes has detrimental effects on the learning. Besides, we experimentally\nobserve that BN can improve the layer-wise conditioning of the optimization\nproblem. Finally, we observe that the last linear layer of very deep residual\nnetwork has ill-conditioned behavior during training. We solve this problem by\nonly adding one BN layer before the last linear layer, which achieves improved\nperformance over the original residual networks, especially when the networks\nare deep.", "authors": ["Lei Huang", "Jie Qin", "Li Liu", "Fan Zhu", "Ling Shao"], "category": "cs.CV", "comment": "The code is available at: https://github.com/huangleiBuaa/LayerwiseCA", "img": "/static/thumbs/2002.10801v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10801v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10801v1", "published_time": "2/25/2020", "rawpid": "2002.10801", "tags": ["cs.CV", "cs.LG"], "title": "Exploring Learning Dynamics of DNNs via Layerwise Conditioning Analysis"}, {"abstract": "In light of the increasing availability of digitally recorded safety reports\nin the construction industry, it is important to develop methods to exploit\nthese data to improve our understanding of safety incidents and ability to\nlearn from them. In this study, we compare several approaches to automatically\nlearn injury precursors from raw construction accident reports. More precisely,\nwe experiment with two state-of-the-art deep learning architectures for Natural\nLanguage Processing (NLP), Convolutional Neural Networks (CNN) and Hierarchical\nAttention Networks (HAN), and with the established Term Frequency - Inverse\nDocument Frequency representation (TF-IDF) + Support Vector Machine (SVM)\napproach. For each model, we provide a method to identify (after training) the\ntextual patterns that are, on average, the most predictive of each safety\noutcome. We show that among those pieces of text, valid injury precursors can\nbe found. The proposed methods can also be used by the user to visualize and\nunderstand the models\u0027 predictions.", "authors": ["Henrietta Baker", "Matthew R. Hallowell", "Antoine J. -P. Tixier"], "category": "cs.CL", "comment": "Accepted for publication in Automation in Construction", "img": "/static/thumbs/1907.11769v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1907.11769v2", "num_discussion": 0, "originally_published_time": "7/26/2019", "pid": "1907.11769v2", "published_time": "2/25/2020", "rawpid": "1907.11769", "tags": ["cs.CL"], "title": "Automatically Learning Construction Injury Precursors from Text"}, {"abstract": "This paper significantly improves on, and finishes to validate, an approach\nproposed in previous research in which safety outcomes were predicted from\nattributes with machine learning. Like in the original study, we use Natural\nLanguage Processing (NLP) to extract fundamental attributes from raw incident\nreports and machine learning models are trained to predict safety outcomes. The\noutcomes predicted here are injury severity, injury type, body part impacted,\nand incident type. However, unlike in the original study, safety outcomes were\nnot extracted via NLP but were provided by independent human annotations,\neliminating any potential source of artificial correlation between predictors\nand predictands. Results show that attributes are still highly predictive,\nconfirming the validity of the original approach. Other improvements brought by\nthe current study include the use of (1) a much larger dataset featuring more\nthan 90,000 reports, (2) two new models, XGBoost and linear SVM (Support Vector\nMachines), (3) model stacking, (4) a more straightforward experimental setup\nwith more appropriate performance metrics, and (5) an analysis of per-category\nattribute importance scores. Finally, the injury severity outcome is well\npredicted, which was not the case in the original study. This is a significant\nadvancement.", "authors": ["Henrietta Baker", "Matthew R. Hallowell", "Antoine J. -P. Tixier"], "category": "cs.LG", "comment": "Accepted for publication in Automation in Construction", "img": "/static/thumbs/1908.05972v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1908.05972v2", "num_discussion": 0, "originally_published_time": "8/16/2019", "pid": "1908.05972v2", "published_time": "2/25/2020", "rawpid": "1908.05972", "tags": ["cs.LG", "stat.ML"], "title": "AI-based Prediction of Independent Construction Safety Outcomes from\n  Universal Attributes"}, {"abstract": "As Convolutional Neural Networks (CNNs) are increasingly being employed in\nsafety-critical applications, it is important that they behave reliably in the\nface of hardware errors. Transient hardware errors may percolate undesirable\nstate during execution, resulting in software-manifested errors which can\nadversely affect high-level decision making. This paper presents HarDNN, a\nsoftware-directed approach to identify vulnerable computations during a CNN\ninference and selectively protect them based on their propensity towards\ncorrupting the inference output in the presence of a hardware error. We show\nthat HarDNN can accurately estimate relative vulnerability of a feature map\n(fmap) in CNNs using a statistical error injection campaign, and explore\nheuristics for fast vulnerability assessment. Based on these results, we\nanalyze the tradeoff between error coverage and computational overhead that the\nsystem designers can use to employ selective protection. Results show that the\nimprovement in resilience for the added computation is superlinear with HarDNN.\nFor example, HarDNN improves SqueezeNet\u0027s resilience by 10x with just 30%\nadditional computations.", "authors": ["Abdulrahman Mahmoud", "Siva Kumar Sastry Hari", "Christopher W. Fletcher", "Sarita V. Adve", "Charbel Sakr", "Naresh Shanbhag", "Pavlo Molchanov", "Michael B. Sullivan", "Timothy Tsai", "Stephen W. Keckler"], "category": "cs.LG", "comment": "14 pages, 5 figures, a short version accepted for publication in\n  First Workshop on Secure and Resi...", "img": "/static/thumbs/2002.09786v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.09786v2", "num_discussion": 0, "originally_published_time": "2/22/2020", "pid": "2002.09786v2", "published_time": "2/25/2020", "rawpid": "2002.09786", "tags": ["cs.LG", "cs.CV", "stat.ML"], "title": "HarDNN: Feature Map Vulnerability Evaluation in CNNs"}, {"abstract": "Can we distinguish between two wireless transmitters sending exactly the same\nmessage, using the same protocol? The opportunity for doing so arises due to\nsubtle nonlinear variations across transmitters, even those made by the same\nmanufacturer. Since these effects are difficult to model explicitly, we\ninvestigate learning device fingerprints using complex-valued deep neural\nnetworks (DNNs) that take as input the complex baseband signal at the receiver.\nSuch fingerprints should be robust to ID spoofing, and to distribution shifts\nacross days and locations due to clock drift and variations in the wireless\nchannel. In this paper, we point out that, unless proactively discouraged from\ndoing so, DNNs learn these strong confounding features rather than the subtle\nnonlinear characteristics that are the basis for stable signatures. Thus, a\nnetwork trained on data collected during one day performs poorly on a different\nday, and networks allowed access to post-preamble information rely on\neasily-spoofed ID fields. We propose and evaluate strategies, based on\naugmentation and estimation, to promote generalization across realizations of\nthese confounding factors, using data from WiFi and ADS-B protocols. We\nconclude that, while DNN training has the advantage of not requiring explicit\nsignal models, significant modeling insights are required to focus the learning\non the effects we wish to capture.", "authors": ["Metehan Cekic", "Soorya Gopalakrishnan", "Upamanyu Madhow"], "category": "eess.SP", "comment": "", "img": "/static/thumbs/2002.10791v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10791v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10791v1", "published_time": "2/25/2020", "rawpid": "2002.10791", "tags": ["eess.SP", "cs.LG", "stat.ML"], "title": "Robust Wireless Fingerprinting: Generalizing Across Space and Time"}, {"abstract": "Conditional Stochastic Optimization (CSO) covers a variety of applications\nranging from meta-learning and causal inference to invariant learning. However,\nconstructing unbiased gradient estimates in CSO is challenging due to the\ncomposition structure. As an alternative, we propose a biased stochastic\ngradient descent (BSGD) algorithm and study the bias-variance tradeoff under\ndifferent structural assumptions. We establish the sample complexities of BSGD\nfor strongly convex, convex, and weakly convex objectives, under smooth and\nnon-smooth conditions. We also provide matching lower bounds of BSGD for convex\nCSO objectives. Extensive numerical experiments are conducted to illustrate the\nperformance of BSGD on robust logistic regression, model-agnostic meta-learning\n(MAML), and instrumental variable regression (IV).", "authors": ["Yifan Hu", "Siqi Zhang", "Xin Chen", "Niao He"], "category": "math.OC", "comment": "", "img": "/static/thumbs/2002.10790v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10790v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10790v1", "published_time": "2/25/2020", "rawpid": "2002.10790", "tags": ["math.OC", "cs.LG", "stat.ML"], "title": "Biased Stochastic Gradient Descent for Conditional Stochastic\n  Optimization"}, {"abstract": "It is well known that building analytical performance models in practice is\ndifficult because it requires a considerable degree of proficiency in the\nunderlying mathematics. In this paper, we propose a machine-learning approach\nto derive performance models from data. We focus on queuing networks, and\ncrucially exploit a deterministic approximation of their average dynamics in\nterms of a compact system of ordinary differential equations. We encode these\nequations into a recurrent neural network whose weights can be directly related\nto model parameters. This allows for an interpretable structure of the neural\nnetwork, which can be trained from system measurements to yield a white-box\nparameterized model that can be used for prediction purposes such as what-if\nanalyses and capacity planning. Using synthetic models as well as a real case\nstudy of a load-balancing system, we show the effectiveness of our technique in\nyielding models with high predictive power.", "authors": ["Giulio Garbi", "Emilio Incerto", "Mirco Tribastone"], "category": "cs.PF", "comment": "", "img": "/static/thumbs/2002.10788v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10788v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10788v1", "published_time": "2/25/2020", "rawpid": "2002.10788", "tags": ["cs.PF", "cs.LG", "cs.SE", "I.2.6; I.6; C.4; D.2.0; D.2.11"], "title": "Learning Queuing Networks by Recurrent Neural Networks"}, {"abstract": "The reparameterization trick has become one of the most useful tools in the\nfield of variational inference. However, the reparameterization trick is based\non the standardization transformation which restricts the scope of application\nof this method to distributions that have tractable inverse cumulative\ndistribution functions or are expressible as deterministic transformations of\nsuch distributions. In this paper, we generalized the reparameterization trick\nby allowing a general transformation. We discover that the proposed model is a\nspecial case of control variate indicating that the proposed model can combine\nthe advantages of CV and generalized reparameterization.", "authors": ["Anbang Wu", "Shuangxi Chen", "Chunming Wu"], "category": "cs.LG", "comment": "There is some errors in the proof to the conclusion, therefore\n  leading to untrusted conclusion, so...", "img": "/static/thumbs/1911.02681v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1911.02681v3", "num_discussion": 0, "originally_published_time": "11/6/2019", "pid": "1911.02681v3", "published_time": "2/25/2020", "rawpid": "1911.02681", "tags": ["cs.LG", "math.OC", "stat.ML"], "title": "Generalized Transformation-based Gradient"}, {"abstract": "An abstractive snippet is an originally created piece of text to summarize a\nweb page on a search engine results page. Compared to the conventional\nextractive snippets, which are generated by extracting phrases and sentences\nverbatim from a web page, abstractive snippets circumvent copyright issues;\neven more interesting is the fact that they open the door for personalization.\nAbstractive snippets have been evaluated as equally powerful in terms of user\nacceptance and expressiveness---but the key question remains: Can abstractive\nsnippets be automatically generated with sufficient quality?\n  This paper introduces a new approach to abstractive snippet generation: We\nidentify the first two large-scale sources for distant supervision, namely\nanchor contexts and web directories. By mining the entire ClueWeb09 and\nClueWeb12 for anchor contexts and by utilizing the DMOZ Open Directory Project,\nwe compile the Webis Abstractive Snippet Corpus 2020, comprising more than 3.5\nmillion triples of the form $\\langle$query, snippet, document$\\rangle$ as\ntraining examples, where the snippet is either an anchor context or a web\ndirectory description in lieu of a genuine query-biased abstractive snippet of\nthe web document. We propose a bidirectional abstractive snippet generation\nmodel and assess the quality of both our corpus and the generated abstractive\nsnippets with standard measures, crowdsourcing, and in comparison to the state\nof the art. The evaluation shows that our novel data sources along with the\nproposed model allow for producing usable query-biased abstractive snippets\nwhile minimizing text reuse.", "authors": ["Wei-Fan Chen", "Shahbaz Syed", "Benno Stein", "Matthias Hagen", "Martin Potthast"], "category": "cs.IR", "comment": "Accepted by WWW 2020", "img": "/static/thumbs/2002.10782v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10782v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10782v1", "published_time": "2/25/2020", "rawpid": "2002.10782", "tags": ["cs.IR", "cs.CL"], "title": "Abstractive Snippet Generation"}, {"abstract": "While tasks could come with varying the number of instances and classes in\nrealistic settings, the existing meta-learning approaches for few-shot\nclassification assume that the number of instances per task and class is fixed.\nDue to such restriction, they learn to equally utilize the meta-knowledge\nacross all the tasks, even when the number of instances per task and class\nlargely varies. Moreover, they do not consider distributional difference in\nunseen tasks, on which the meta-knowledge may have less usefulness depending on\nthe task relatedness. To overcome these limitations, we propose a novel\nmeta-learning model that adaptively balances the effect of the meta-learning\nand task-specific learning within each task. Through the learning of the\nbalancing variables, we can decide whether to obtain a solution by relying on\nthe meta-knowledge or task-specific learning. We formulate this objective into\na Bayesian inference framework and tackle it using variational inference. We\nvalidate our Bayesian Task-Adaptive Meta-Learning (Bayesian TAML) on multiple\nrealistic task- and class-imbalanced datasets, on which it significantly\noutperforms existing meta-learning approaches. Further ablation study confirms\nthe effectiveness of each balancing component and the Bayesian learning\nframework.", "authors": ["Hae Beom Lee", "Hayeon Lee", "Donghyun Na", "Saehoon Kim", "Minseop Park", "Eunho Yang", "Sung Ju Hwang"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1905.12917v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1905.12917v2", "num_discussion": 0, "originally_published_time": "5/30/2019", "pid": "1905.12917v2", "published_time": "2/25/2020", "rawpid": "1905.12917", "tags": ["cs.LG", "stat.ML"], "title": "Learning to Balance: Bayesian Meta-Learning for Imbalanced and\n  Out-of-distribution Tasks"}, {"abstract": "Neural networks with binary weights are computation-efficient and\nhardware-friendly, but their training is challenging because it involves a\ndiscrete optimization problem. Surprisingly, ignoring the discrete nature of\nthe problem and using gradient-based methods, such as Straight-Through\nEstimator, still works well in practice. This raises the question: are there\nprincipled approaches which justify such methods? In this paper, we propose\nsuch an approach using the Bayesian learning rule. The rule, when applied to\nestimate a Bernoulli distribution over the binary weights, results in an\nalgorithm which justifies some of the algorithmic choices made by the previous\napproaches. The algorithm not only obtains state-of-the-art performance, but\nalso enables uncertainty estimation for continual learning to avoid\ncatastrophic forgetting. Our work provides a principled approach for training\nbinary neural networks which justifies and extends existing approaches.", "authors": ["Xiangming Meng", "Roman Bachmann", "Mohammad Emtiyaz Khan"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10778v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10778v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10778v1", "published_time": "2/25/2020", "rawpid": "2002.10778", "tags": ["cs.LG", "stat.ML"], "title": "Training Binary Neural Networks using the Bayesian Learning Rule"}, {"abstract": "Body tissue composition is a long-known biomarker with high diagnostic and\nprognostic value in cardiovascular, oncological and orthopaedic diseases, but\nalso in rehabilitation medicine or drug dosage. In this study, the aim was to\ndevelop a fully automated, reproducible and quantitative 3D volumetry of body\ntissue composition from standard CT examinations of the abdomen in order to be\nable to offer such valuable biomarkers as part of routine clinical imaging.\nTherefore an in-house dataset of 40 CTs for training and 10 CTs for testing\nwere fully annotated on every fifth axial slice with five different semantic\nbody regions: abdominal cavity, bones, muscle, subcutaneous tissue, and\nthoracic cavity. Multi-resolution U-Net 3D neural networks were employed for\nsegmenting these body regions, followed by subclassifying adipose tissue and\nmuscle using known hounsfield unit limits. The S{\\o}rensen Dice scores averaged\nover all semantic regions was 0.9553 and the intra-class correlation\ncoefficients for subclassified tissues were above 0.99. Our results show that\nfully-automated body composition analysis on routine CT imaging can provide\nstable biomarkers across the whole abdomen and not just on L3 slices, which is\nhistorically the reference location for analysing body composition in the\nclinical routine.", "authors": ["Sven Koitka", "Lennard Kroll", "Eugen Malamutmann", "Arzu Oezcelik", "Felix Nensa"], "category": "eess.IV", "comment": "", "img": "/static/thumbs/2002.10776v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10776v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10776v1", "published_time": "2/25/2020", "rawpid": "2002.10776", "tags": ["eess.IV", "cs.CV"], "title": "Fully-automated Body Composition Analysis in Routine CT Imaging Using 3D\n  Semantic Segmentation Convolutional Neural Networks"}, {"abstract": "Building machine learning models that are \\textit{fair} with respect to an\nunprivileged group is a topical problem. Modern fairness-aware algorithms often\nignore causal effects and enforce fairness through modifications applicable to\nonly a subset of machine learning models. In this work, we propose a new\ndefinition of fairness that incorporates causality through the Controlled\nDirect Effect (CDE). We develop regularizations to tackle classical fairness\nmeasures and present a causal regularization that satisfies our new fairness\ndefinition by removing the impact of unprivileged group variables on the model\noutcomes as measured by the CDE. These regularizations are applicable to any\nmodel trained using by iteratively minimizing a loss through differentiation.\nWe demonstrate our approaches using both gradient boosting and logistic\nregression on: a synthetic dataset, the UCI Adult (Census) Dataset, and a\nreal-world credit-risk dataset. Our results were found to mitigate unfairness\nfrom the predictions with small reductions in model performance.", "authors": ["Pietro G. Di Stefano", "James M. Hickey", "Vlasios Vasileiou"], "category": "cs.AI", "comment": "10 pages, 4 figures", "img": "/static/thumbs/2002.10774v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10774v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10774v1", "published_time": "2/25/2020", "rawpid": "2002.10774", "tags": ["cs.AI", "stat.ML"], "title": "Counterfactual fairness: removing direct effects through regularization"}, {"abstract": "Text classification is one of the most important and fundamental tasks in\nnatural language processing. Performance of this task mainly dependents on text\nrepresentation learning. Currently, most existing learning frameworks mainly\nfocus on encoding local contextual information between words. These methods\nalways neglect to exploit global clues, such as label information, for encoding\ntext information. In this study, we propose a label-guided learning framework\nLguidedLearn for text representation and classification. Our method is novel\nbut simple that we only insert a label-guided encoding layer into the commonly\nused text representation learning schemas. That label-guided layer performs\nlabel-based attentive encoding to map the universal text embedding (encoded by\na contextual information learner) into different label spaces, resulting in\nlabel-wise embeddings. In our proposed framework, the label-guided layer can be\neasily and directly applied with a contextual encoding method to perform\njointly learning. Text information is encoded based on both the local\ncontextual information and the global label clues. Therefore, the obtained text\nembeddings are more robust and discriminative for text classification.\nExtensive experiments are conducted on benchmark datasets to illustrate the\neffectiveness of our proposed method.", "authors": ["Xien Liu", "Song Wang", "Xiao Zhang", "Xinxin You", "Ji Wu", "Dejing Dou"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/2002.10772v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10772v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10772v1", "published_time": "2/25/2020", "rawpid": "2002.10772", "tags": ["cs.CL", "cs.LG"], "title": "Label-guided Learning for Text Classification"}, {"abstract": "Graph convolutional network (GCN) is now an effective tool to deal with\nnon-Euclidean data, such as social networks in social behavior analysis,\nmolecular structure analysis in the field of chemistry, and skeleton-based\naction recognition. Graph convolutional kernel is one of the most significant\nfactors in GCN to extract nodes\u0027 feature, and some improvements of it have\nreached promising performance theoretically and experimentally. However, there\nis limited research about how exactly different data types and graph structures\ninfluence the performance of these kernels. Most existing methods used an\nadaptive convolutional kernel to deal with a given graph structure, which still\nnot reveals the internal reasons. In this paper, we started from theoretical\nanalysis of the spectral graph and studied the properties of existing graph\nconvolutional kernels. While taking some designed datasets with specific\nparameters into consideration, we revealed the self-smoothing phenomenon of\nconvolutional kernels. After that, we proposed the Poisson kernel that can\navoid self-smoothing without training any adaptive kernel. Experimental results\ndemonstrate that our Poisson kernel not only works well on the benchmark\ndataset where state-of-the-art methods work fine, but also is evidently\nsuperior to them in synthetic datasets.", "authors": ["Ziqing Yang", "Shoudong Han", "Jun Zhao"], "category": "cs.CV", "comment": "7 pages, 3 figures", "img": "/static/thumbs/2002.02589v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.02589v2", "num_discussion": 0, "originally_published_time": "2/7/2020", "pid": "2002.02589v2", "published_time": "2/25/2020", "rawpid": "2002.02589", "tags": ["cs.CV", "cs.LG"], "title": "Poisson Kernel Avoiding Self-Smoothing in Graph Convolutional Networks"}, {"abstract": "We propose to modify the common training protocols of optical flow, leading\nto sizable accuracy improvements without adding to the computational complexity\nof the training process. The improvement is based on observing the bias in\nsampling challenging data that exists in the current training protocol, and\nimproving the sampling process. In addition, we find that both regularization\nand augmentation should decrease during the training protocol.\n  Using a low parameters off-the-shelf model, the method is ranked first on the\nMPI Sintel benchmark among all other methods, improving the best two frames\nmethod accuracy by more than 10%. The method also surpasses all similar\narchitecture variants by more than 12% and 19.7% on the KITTI benchmarks,\nachieving the lowest Average End-Point Error on KITTI2012 among two-frame\nmethods, without using extra datasets.", "authors": ["Aviram Bar-Haim", "Lior Wolf"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2002.10770v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10770v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10770v1", "published_time": "2/25/2020", "rawpid": "2002.10770", "tags": ["cs.CV"], "title": "ScopeFlow: Dynamic Scene Scoping for Optical Flow"}, {"abstract": "In this paper we consider the question of whether it is possible to apply a\ngradient averaging strategy to improve on the sublinear convergence rates\nwithout any increase in storage. Our analysis reveals that a positive answer\nrequires an appropriate averaging strategy and iterations that satisfy the\nvariance dominant condition. As an interesting fact, we show that if the\niterative variance we defined is always dominant even a little bit in the\nstochastic gradient iterations, the proposed gradient averaging strategy can\nincrease the convergence rate $\\mathcal{O}(1/k)$ to $\\mathcal{O}(1/k^2)$ in\nprobability for the strongly convex objectives with Lipschitz gradients. This\nconclusion suggests how we should control the stochastic gradient iterations to\nimprove the rate of convergence.", "authors": ["Xin Xu", "Xiaopeng Luo"], "category": "math.OC", "comment": "20 pages, 1 figure", "img": "/static/thumbs/2002.10769v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10769v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10769v1", "published_time": "2/25/2020", "rawpid": "2002.10769", "tags": ["math.OC", "cs.LG", "cs.NA", "math.NA", "65K05, 68T05, 90C15, 90C30"], "title": "Can speed up the convergence rate of stochastic gradient methods to\n  $\\mathcal{O}(1/k^2)$ by a gradient averaging strategy?"}, {"abstract": "Although the sequence-to-sequence (encoder-decoder) model is considered the\nstate-of-the-art in deep learning sequence models, there is little research\ninto using this model for recovering missing sensor data. The key challenge is\nthat the missing sensor data problem typically comprises three sequences (a\nsequence of observed samples, followed by a sequence of missing samples,\nfollowed by another sequence of observed samples) whereas, the\nsequence-to-sequence model only considers two sequences (an input sequence and\nan output sequence). We address this problem by formulating a\nsequence-to-sequence in a novel way. A forward RNN encodes the data observed\nbefore the missing sequence and a backward RNN encodes the data observed after\nthe missing sequence. A decoder decodes the two encoders in a novel way to\npredict the missing data. We demonstrate that this model produces the lowest\nerrors in 12% more cases than the current state-of-the-art.", "authors": ["Joel Janek Dabrowski", "Ashfaqur Rahman"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10767v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10767v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10767v1", "published_time": "2/25/2020", "rawpid": "2002.10767", "tags": ["cs.LG", "stat.ML"], "title": "Sequence-to-Sequence Imputation of Missing Sensor Data"}, {"abstract": "Methods for taking into account external knowledge in Machine Learning models\nhave the potential to address outstanding issues in data-driven AI methods,\nsuch as improving safety and fairness, and can simplify training in the\npresence of scarce data. We propose a simple, but effective, method for\ninjecting constraints at training time in supervised learning, based on\ndecomposition and bi-level optimization: a master step is in charge of\nenforcing the constraints, while a learner step takes care of training the\nmodel. The process leads to approximate constraint satisfaction. The method is\napplicable to any ML approach for which the concept of label (or target) is\nwell defined (most regression and classification scenarios), and allows to\nreuse existing training algorithms with no modifications. We require no\nassumption on the constraints, although their properties affect the shape and\ncomplexity of the master problem. Convergence guarantees are hard to provide,\nbut we found that the approach performs well on ML tasks with fairness\nconstraints and on classical datasets with synthetic constraints.", "authors": ["Fabrizio Detassis", "Michele Lombardi", "Michela Milano"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10766v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10766v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10766v1", "published_time": "2/25/2020", "rawpid": "2002.10766", "tags": ["cs.LG", "cs.AI", "stat.ML"], "title": "Teaching the Old Dog New Tricks: Supervised Learning with Constraints"}, {"abstract": "We investigate the problem of fair recommendation in the context of two-sided\nonline platforms, comprising customers on one side and producers on the other.\nTraditionally, recommendation services in these platforms have focused on\nmaximizing customer satisfaction by tailoring the results according to the\npersonalized preferences of individual customers. However, our investigation\nreveals that such customer-centric design may lead to unfair distribution of\nexposure among the producers, which may adversely impact their well-being. On\nthe other hand, a producer-centric design might become unfair to the customers.\nThus, we consider fairness issues that span both customers and producers. Our\napproach involves a novel mapping of the fair recommendation problem to a\nconstrained version of the problem of fairly allocating indivisible goods. Our\nproposed FairRec algorithm guarantees at least Maximin Share (MMS) of exposure\nfor most of the producers and Envy-Free up to One item (EF1) fairness for every\ncustomer. Extensive evaluations over multiple real-world datasets show the\neffectiveness of FairRec in ensuring two-sided fairness while incurring a\nmarginal loss in the overall recommendation quality.", "authors": ["Gourab K. Patro", "Arpita Biswas", "Niloy Ganguly", "Krishna P. Gummadi", "Abhijnan Chakraborty"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/2002.10764v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10764v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10764v1", "published_time": "2/25/2020", "rawpid": "2002.10764", "tags": ["cs.AI", "cs.GT"], "title": "FairRec: Two-Sided Fairness for Personalized Recommendations in\n  Two-Sided Platforms"}, {"abstract": "We propose a new framework for imposing monotonicity constraints in a\nBayesian nonparametric setting based on numerical solutions of stochastic\ndifferential equations. We derive a nonparametric model of monotonic functions\nthat allows for interpretable priors and principled quantification of\nhierarchical uncertainty. We demonstrate the efficacy of the proposed model by\nproviding competitive results to other probabilistic monotonic models on a\nnumber of benchmark functions. In addition, we consider the utility of a\nmonotonic random process as a part of a hierarchical probabilistic model; we\nexamine the task of temporal alignment of time-series data where it is\nbeneficial to use a monotonic random process in order to preserve the\nuncertainty in the temporal warpings.", "authors": ["Ivan Ustyuzhaninov", "Ieva Kazlauskaite", "Carl Henrik Ek", "Neill D. F. Campbell"], "category": "stat.ML", "comment": "Proceedings of the 23nd International Conference on Artificial\n  Intelligence and Statistics (AISTAT...", "img": "/static/thumbs/1905.12930v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1905.12930v2", "num_discussion": 0, "originally_published_time": "5/30/2019", "pid": "1905.12930v2", "published_time": "2/25/2020", "rawpid": "1905.12930", "tags": ["stat.ML", "cs.LG"], "title": "Monotonic Gaussian Process Flow"}, {"abstract": "This paper proposes a communication strategy for decentralized learning on\nwireless systems. Our discussion is based on the decentralized parallel\nstochastic gradient descent (D-PSGD), which is one of the state-of-the-art\nalgorithms for decentralized learning. The main contribution of this paper is\nto raise a novel open question for decentralized learning on wireless systems:\nthere is a possibility that the density of a network topology significantly\ninfluences the runtime performance of D-PSGD. In general, it is difficult to\nguarantee delay-free communications without any communication deterioration in\nreal wireless network systems because of path loss and multi-path fading. These\nfactors significantly degrade the runtime performance of D-PSGD. To alleviate\nsuch problems, we first analyze the runtime performance of D-PSGD by\nconsidering real wireless systems. This analysis yields the key insights that\ndense network topology (1) does not significantly gain the training accuracy of\nD-PSGD compared to sparse one, and (2) strongly degrades the runtime\nperformance because this setting generally requires to utilize a low-rate\ntransmission. Based on these findings, we propose a novel communication\nstrategy, in which each node estimates optimal transmission rates such that\ncommunication time during the D-PSGD optimization is minimized under the\nconstraint of network density, which is characterized by radio propagation\nproperty. The proposed strategy enables to improve the runtime performance of\nD-PSGD in wireless systems. Numerical simulations reveal that the proposed\nstrategy is capable of enhancing the runtime performance of D-PSGD.", "authors": ["Koya Sato", "Yasuyuki Satoh", "Daisuke Sugimura"], "category": "cs.NI", "comment": "6 pages, 11 figures. Accepted for presentation at IEEE ICC 2020", "img": "/static/thumbs/2002.10758v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10758v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10758v1", "published_time": "2/25/2020", "rawpid": "2002.10758", "tags": ["cs.NI", "cs.LG"], "title": "Network-Density-Controlled Decentralized Parallel Stochastic Gradient\n  Descent in Wireless Systems"}, {"abstract": "Event detection (ED), a key subtask of information extraction, aims to\nrecognize instances of specific types of events in text. Recently, graph\nconvolutional networks (GCNs) over dependency trees have been widely used to\ncapture syntactic structure information and get convincing performances in\nevent detection. However, these works ignore the syntactic relation labels on\nthe tree, which convey rich and useful linguistic knowledge for event\ndetection. In this paper, we investigate a novel architecture named\nRelation-Aware GCN (RA-GCN), which efficiently exploits syntactic relation\nlabels and models the relation between words specifically. We first propose a\nrelation-aware aggregation module to produce expressive word representation by\naggregating syntactically connected words through specific relation.\nFurthermore, a context-aware relation update module is designed to explicitly\nupdate the relation representation between words, and these two modules work in\nthe mutual promotion way. Experimental results on the ACE2005 dataset show that\nour model achieves a new state-of-the-art performance for event detection.", "authors": ["Shiyao Cui", "Bowen Yu", "Tingwen Liu", "Zhenyu Zhang", "Xuebin Wang", "Jinqiao Shi"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/2002.10757v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10757v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10757v1", "published_time": "2/25/2020", "rawpid": "2002.10757", "tags": ["cs.CL"], "title": "Event Detection with Relation-Aware Graph Convolutional Neural Networks"}, {"abstract": "We consider a decentralized stochastic learning problem where data points are\ndistributed among computing nodes communicating over a directed graph. As the\nmodel size gets large, decentralized learning faces a major bottleneck that is\nthe heavy communication load due to each node transmitting large messages\n(model updates) to its neighbors. To tackle this bottleneck, we propose the\nquantized decentralized stochastic learning algorithm over directed graphs that\nis based on the push-sum algorithm in decentralized consensus optimization.\nMore importantly, we prove that our algorithm achieves the same convergence\nrates of the decentralized stochastic learning algorithm with\nexact-communication for both convex and non-convex losses. A key technical\nchallenge of the work is to prove exact convergence of the proposed\ndecentralized learning algorithm in the presence of quantization noise with\nunbounded variance over directed graphs. We provide numerical evaluations that\ncorroborate our main theoretical results and illustrate significant speed-up\ncompared to the exact-communication methods.", "authors": ["Hossein Taheri", "Aryan Mokhtari", "Hamed Hassani", "Ramtin Pedarsani"], "category": "cs.DC", "comment": "", "img": "/static/thumbs/2002.09964v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.09964v2", "num_discussion": 0, "originally_published_time": "2/23/2020", "pid": "2002.09964v2", "published_time": "2/25/2020", "rawpid": "2002.09964", "tags": ["cs.DC", "cs.LG", "cs.MA", "cs.SY", "eess.SP", "eess.SY"], "title": "Quantized Push-sum for Gossip and Decentralized Optimization over\n  Directed Graphs"}, {"abstract": "Conventional cell tracking methods detect multiple cellsin each frame\n(detection) and then associate the detec-tion results in successive time-frames\n(association). Mostcell tracking methods perform the association task\nindepen-dently from the detection task. However, there is no guar-antee of\npreserving coherence between these tasks, and lackof coherence may adversely\naffect tracking performance. Inthis paper, we propose the Motion and Position\nMap (MPM)that jointly represents both detection and association for notonly\nmigration but also cell division. It guarantees coher-ence such that if a cell\nis detected, the corresponding mo-tion flow can always be obtained. It is a\nsimple but powerfulmethod for multi-object tracking in dense environments.\nWecompared the proposed method with current tracking meth-ods under various\nconditions in real biological images andfound that it outperformed the\nstate-of-the-art (+5.2% im-provement compared to the second-best).", "authors": ["Junya Hayashida", "Kazuya Nishimura", "Ryoma Bise"], "category": "cs.CV", "comment": "8 pages, 11 figures, Accepted in CVPR 2020", "img": "/static/thumbs/2002.10749v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10749v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10749v1", "published_time": "2/25/2020", "rawpid": "2002.10749", "tags": ["cs.CV", "eess.IV"], "title": "MPM: Joint Representation of Motion and Position Map for Cell Tracking"}, {"abstract": "Spiking neural networks (SNNs) has attracted much attention due to its great\npotential of modeling time-dependent signals. The firing rate of spiking\nneurons is decided by control rate which is fixed manually in advance, and\nthus, whether the firing rate is adequate for modeling actual time series\nrelies on fortune. Though it is demanded to have an adaptive control rate, it\nis a non-trivial task because the control rate and the connection weights\nlearned during the training process are usually entangled. In this paper, we\nshow that the firing rate is related to the eigenvalue of the spike generation\nfunction. Inspired by this insight, by enabling the spike generation function\nto have adaptable eigenvalues rather than parametric control rates, we develop\nthe Bifurcation Spiking Neural Network (BSNN), which has an adaptive firing\nrate and is insensitive to the setting of control rates. Experiments validate\nthe effectiveness of BSNN on a broad range of tasks, showing that BSNN achieves\nsuperior performance to existing SNNs and is robust to the setting of control\nrates.", "authors": ["Shao-Qun Zhang", "Zhao-Yu Zhang", "Zhi-Hua Zhou"], "category": "cs.NE", "comment": "18 pages", "img": "/static/thumbs/1909.08341v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1909.08341v2", "num_discussion": 0, "originally_published_time": "9/18/2019", "pid": "1909.08341v2", "published_time": "2/25/2020", "rawpid": "1909.08341", "tags": ["cs.NE", "q-bio.NC"], "title": "Bifurcation Spiking Neural Network"}, {"abstract": "Given enough data, Deep Neural Networks (DNNs) are capable of learning\ncomplex input-output relations with high accuracy. In several domains, however,\ndata is scarce or expensive to retrieve, while a substantial amount of expert\nknowledge is available. It seems reasonable that if we can inject this\nadditional information in the DNN, we could ease the learning process. One such\ncase is that of Constraint Problems, for which declarative approaches exists\nand pure ML solutions have obtained mixed success. Using a classical\nconstrained problem as a case study, we perform controlled experiments to probe\nthe impact of progressively adding domain and empirical knowledge in the DNN.\nOur results are very encouraging, showing that (at least in our setup)\nembedding domain knowledge at training time can have a considerable effect and\nthat a small amount of empirical knowledge is sufficient to obtain practically\nuseful results.", "authors": ["Mattia Silvestri", "Michele Lombardi", "Michela Milano"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/2002.10742v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10742v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10742v1", "published_time": "2/25/2020", "rawpid": "2002.10742", "tags": ["cs.AI", "cs.LG"], "title": "Injecting Domain Knowledge in Neural Networks: a Controlled Experiment\n  on a Constrained Problem"}, {"abstract": "Tree data are ubiquitous because they model a large variety of situations,\ne.g., the architecture of plants, the secondary structure of RNA, or the\nhierarchy of XML files. Nevertheless, the analysis of these non-Euclidean data\nis difficult per se. In this paper, we focus on the subtree kernel that is a\nconvolution kernel for tree data introduced by Vishwanathan and Smola in the\nearly 2000\u0027s. More precisely, we investigate the influence of the weight\nfunction from a theoretical perspective and in real data applications. We\nestablish on a 2-classes stochastic model that the performance of the subtree\nkernel is improved when the weight of leaves vanishes, which motivates the\ndefinition of a new weight function, learned from the data and not fixed by the\nuser as usually done. To this end, we define a unified framework for computing\nthe subtree kernel from ordered or unordered trees, that is particularly\nsuitable for tuning parameters. We show through eight real data classification\nproblems the great efficiency of our approach, in particular for small\ndatasets, which also states the high importance of the weight function.\nFinally, a visualization tool of the significant features is derived.", "authors": ["Romain Aza\u00efs", "Florian Ingels"], "category": "stat.ML", "comment": "35 pages", "img": "/static/thumbs/1904.05421v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1904.05421v3", "num_discussion": 0, "originally_published_time": "4/10/2019", "pid": "1904.05421v3", "published_time": "2/25/2020", "rawpid": "1904.05421", "tags": ["stat.ML", "cs.LG"], "title": "The Weight Function in the Subtree Kernel is Decisive"}, {"abstract": "Off-policy reinforcement learning (RL) is concerned with learning a rewarding\npolicy by executing another policy that gathers samples of experience. While\nthe former policy (i.e. target policy) is rewarding but in-expressive (in most\ncases, deterministic), doing well in the latter task, in contrast, requires an\nexpressive policy (i.e. behavior policy) that offers guided and effective\nexploration. Contrary to most methods that make a trade-off between optimality\nand expressiveness, disentangled frameworks explicitly decouple the two\nobjectives, which each is dealt with by a distinct separate policy. Although\nbeing able to freely design and optimize the two policies with respect to their\nown objectives, naively disentangling them can lead to inefficient learning or\nstability issues. To mitigate this problem, our proposed method Analogous\nDisentangled Actor-Critic (ADAC) designs analogous pairs of actors and critics.\nSpecifically, ADAC leverages a key property about Stein variational gradient\ndescent (SVGD) to constraint the expressive energy-based behavior policy with\nrespect to the target one for effective exploration. Additionally, an analogous\ncritic pair is introduced to incorporate intrinsic rewards in a principled\nmanner, with theoretical guarantees on the overall learning stability and\neffectiveness. We empirically evaluate environment-reward-only ADAC on 14\ncontinuous-control tasks and report the state-of-the-art on 10 of them. We\nfurther demonstrate ADAC, when paired with intrinsic rewards, outperform\nalternatives in exploration-challenging tasks.", "authors": ["Anji Liu", "Yitao Liang", "Guy Van den Broeck"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10738v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10738v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10738v1", "published_time": "2/25/2020", "rawpid": "2002.10738", "tags": ["cs.LG", "stat.ML"], "title": "Off-Policy Deep Reinforcement Learning with Analogous Disentangled\n  Exploration"}, {"abstract": "Code summarization generates brief natural language description given a\nsource code snippet, while code retrieval fetches relevant source code given a\nnatural language query. Since both tasks aim to model the association between\nnatural language and programming language, recent studies have combined these\ntwo tasks to improve their performance. However, researchers have yet been able\nto effectively leverage the intrinsic connection between the two tasks as they\ntrain these tasks in a separate or pipeline manner, which means their\nperformance can not be well balanced. In this paper, we propose a novel\nend-to-end model for the two tasks by introducing an additional code generation\ntask. More specifically, we explicitly exploit the probabilistic correlation\nbetween code summarization and code generation with dual learning, and utilize\nthe two encoders for code summarization and code generation to train the code\nretrieval task via multi-task learning. We have carried out extensive\nexperiments on an existing dataset of SQL and Python, and results show that our\nmodel can significantly improve the results of the code retrieval task over\nthe-state-of-art models, as well as achieve competitive performance in terms of\nBLEU score for the code summarization task.", "authors": ["Wei Ye", "Rui Xie", "Jinglei Zhang", "Tianxiang Hu", "Xiaoyin Wang", "Shikun Zhang"], "category": "cs.IR", "comment": "Published at The Web Conference (WWW) 2020, full paper", "img": "/static/thumbs/2002.10198v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10198v2", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10198v2", "published_time": "2/25/2020", "rawpid": "2002.10198", "tags": ["cs.IR", "cs.CL", "cs.SE"], "title": "Leveraging Code Generation to Improve Code Retrieval and Summarization\n  via Dual Learning"}, {"abstract": "This paper discussed the {\\it robust alignment} problem, that is, the problem\nof aligning the goals of algorithms with human preferences. It presented a\ngeneral roadmap to tackle this issue. Interestingly, this roadmap identifies 5\ncritical steps, as well as many relevant aspects of these 5 steps. In other\nwords, we have presented a large number of hopefully more tractable subproblems\nthat readers are highly encouraged to tackle. Hopefully, this combination\nallows to better highlight the most pressing problems, how every expertise can\nbe best used to, and how combining the solutions to subproblems might add up to\nsolve robust alignment.", "authors": ["L\u00ea Nguy\u00ean Hoang"], "category": "cs.AI", "comment": "21 pages, 2 figures", "img": "/static/thumbs/1809.01036v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1809.01036v4", "num_discussion": 0, "originally_published_time": "9/4/2018", "pid": "1809.01036v4", "published_time": "2/25/2020", "rawpid": "1809.01036", "tags": ["cs.AI"], "title": "A Roadmap for Robust End-to-End Alignment"}, {"abstract": "Patch adversarial attacks on images, in which the attacker can distort pixels\nwithin a region of bounded size, are an important threat model since they\nprovide a quantitative model for physical adversarial attacks. In this paper,\nwe introduce a certifiable defense against patch attacks that guarantees for a\ngiven image and patch attack size, no patch adversarial examples exist. Our\nmethod is related to the broad class of randomized smoothing robustness schemes\nwhich provide high-confidence probabilistic robustness certificates. By\nexploiting the fact that patch attacks are more constrained than general sparse\nattacks, we derive meaningfully large robustness certificates. Additionally,\nthe algorithm we propose is de-randomized, providing deterministic\ncertificates. To the best of our knowledge, there exists only one prior method\nfor certifiable defense against patch attacks, which relies on interval bound\npropagation. While this sole existing method performs well on MNIST, it has\nseveral limitations: it requires computationally expensive training, does not\nscale to ImageNet, and performs poorly on CIFAR-10. In contrast, our proposed\nmethod effectively addresses all of these issues: our classifier can be trained\nquickly, achieves high clean and certified robust accuracy on CIFAR-10, and\nprovides certificates at the ImageNet scale. For example, for a 5*5 patch\nattack on CIFAR-10, our method achieves up to around 57.8% certified accuracy\n(with a classifier around 83.9% clean accuracy), compared to at most 30.3%\ncertified accuracy for the existing method (with a classifier with around 47.8%\nclean accuracy), effectively establishing a new state-of-the-art. Code is\navailable at https://github.com/alevine0/patchSmoothing.", "authors": ["Alexander Levine", "Soheil Feizi"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10733v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10733v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10733v1", "published_time": "2/25/2020", "rawpid": "2002.10733", "tags": ["cs.LG", "cs.CV", "stat.ML"], "title": "(De)Randomized Smoothing for Certifiable Defense against Patch Attacks"}, {"abstract": "Each year, there are about 400\u0027000 new cases of kidney cancer worldwide\ncausing around 175\u0027000 deaths. For clinical decision making it is important to\nunderstand the morphometry of the tumor, which involves the time-consuming task\nof delineating tumor and kidney in 3D CT images. Automatic segmentation could\nbe an important tool for clinicians and researchers to also study the\ncorrelations between tumor morphometry and clinical outcomes. We present a\nsegmentation method which combines the popular U-Net convolutional neural\nnetwork architecture with post-processing based on statistical constraints of\nthe available training data. The full implementation, based on PyTorch, and the\ntrained weights can be found on GitHub.", "authors": ["Iwan Paolucci"], "category": "eess.IV", "comment": "KiTS 2019 challenge", "img": "/static/thumbs/2002.10727v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10727v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10727v1", "published_time": "2/25/2020", "rawpid": "2002.10727", "tags": ["eess.IV", "cs.CV"], "title": "Technical report: Kidney tumor segmentation using a 2D U-Net followed by\n  a statistical post-processing filter"}, {"abstract": "The success of deep neural networks relies on significant architecture\nengineering. Recently neural architecture search (NAS) has emerged as a promise\nto greatly reduce manual effort in network design by automatically searching\nfor optimal architectures, although typically such algorithms need an excessive\namount of computational resources, e.g., a few thousand GPU-days. To date, on\nchallenging vision tasks such as object detection, NAS, especially fast\nversions of NAS, is less studied. Here we propose to search for the decoder\nstructure of object detectors with search efficiency being taken into\nconsideration. To be more specific, we aim to efficiently search for the\nfeature pyramid network (FPN) as well as the prediction head of a simple\nanchor-free object detector, namely FCOS, using a tailored reinforcement\nlearning paradigm. With carefully designed search space, search algorithms and\nstrategies for evaluating network quality, we are able to efficiently search a\ntop-performing detection architecture within 4 days using 8 V100 GPUs. The\ndiscovered architecture surpasses state-of-the-art object detection models\n(such as Faster R-CNN, RetinaNet and FCOS) by 1.5 to 3.5 points in AP on the\nCOCO dataset, with comparable computation complexity and memory footprint,\ndemonstrating the efficacy of the proposed NAS for object detection.", "authors": ["Ning Wang", "Yang Gao", "Hao Chen", "Peng Wang", "Zhi Tian", "Chunhua Shen", "Yanning Zhang"], "category": "cs.CV", "comment": "9 pages, 9 figures, accepted by CVPR-2020", "img": "/static/thumbs/1906.04423v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1906.04423v4", "num_discussion": 0, "originally_published_time": "6/11/2019", "pid": "1906.04423v4", "published_time": "2/25/2020", "rawpid": "1906.04423", "tags": ["cs.CV"], "title": "NAS-FCOS: Fast Neural Architecture Search for Object Detection"}, {"abstract": "This paper proposes a learning method for denois-ing gyroscopes of Inertial\nMeasurement Units (IMUs) using ground truth data, to estimate in real time the\norientation (attitude) of a robot in dead reckoning. The obtained algorithm\noutperforms the state-of-the-art on the (unseen) test sequences. The obtained\nperformances are achieved thanks to a well chosen model, a proper loss function\nfor orientation increments, and through the identification of key points when\ntraining with high-frequency inertial data. Our approach builds upon a neural\nnetwork based on dilated convolutions, without requiring any recurrent neural\nnetwork. We demonstrate how efficient our strategy is for 3D attitude\nestimation on the EuRoC and TUM-VI datasets. Interestingly, we observe our dead\nreckoning algorithm manages to beat top-ranked visual-inertial odometry systems\nin terms of attitude estimation although it does not use vision sensors. We\nbelieve this paper offers new perspectives for visual-inertial localization and\nconstitutes a step toward more efficient learning methods involving IMUs. Our\nopen-source implementation is available at https://github.com/\nmbrossar/denoise-imu-gyro.", "authors": ["Martin Brossard", "Silvere Bonnabel", "Axel Barrau"], "category": "cs.RO", "comment": "", "img": "/static/thumbs/2002.10718v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10718v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10718v1", "published_time": "2/25/2020", "rawpid": "2002.10718", "tags": ["cs.RO", "stat.ML"], "title": "Denoising IMU Gyroscopes with Deep Learning for Open-Loop Attitude\n  Estimation"}, {"abstract": "Adversarial training augments the training set with perturbations to improve\nthe robust error (over worst-case perturbations), but it often leads to an\nincrease in the standard error (on unperturbed test inputs). Previous\nexplanations for this tradeoff rely on the assumption that no predictor in the\nhypothesis class has low standard and robust error. In this work, we precisely\ncharacterize the effect of augmentation on the standard error in linear\nregression when the optimal linear predictor has zero standard and robust\nerror. In particular, we show that the standard error could increase even when\nthe augmented perturbations have noiseless observations from the optimal linear\npredictor. We then prove that the recently proposed robust self-training (RST)\nestimator improves robust error without sacrificing standard error for\nnoiseless linear regression. Empirically, for neural networks, we find that RST\nwith different adversarial training methods improves both standard and robust\nerror for random and adversarial rotations and adversarial $\\ell_\\infty$\nperturbations in CIFAR-10.", "authors": ["Aditi Raghunathan", "Sang Michael Xie", "Fanny Yang", "John Duchi", "Percy Liang"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10716v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10716v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10716v1", "published_time": "2/25/2020", "rawpid": "2002.10716", "tags": ["cs.LG", "stat.ML"], "title": "Understanding and Mitigating the Tradeoff Between Robustness and\n  Accuracy"}, {"abstract": "Scene text detection and recognition has received increasing research\nattention. Existing methods can be roughly categorized into two groups:\ncharacter-based and segmentation-based. These methods either are costly for\ncharacter annotation or need to maintain a complex pipeline, which is often not\nsuitable for real-time applications. Here we address the problem by proposing\nthe Adaptive Bezier-Curve Network (ABCNet). Our contributions are three-fold:\n1) For the first time, we adaptively fit arbitrarily-shaped text by a\nparameterized Bezier curve. 2) We design a novel BezierAlign layer for\nextracting accurate convolution features of a text instance with arbitrary\nshapes, significantly improving the precision compared with previous methods.\n3) Compared with standard bounding box detection, our Bezier curve detection\nintroduces negligible computation overhead, resulting in superiority of our\nmethod in both efficiency and accuracy. Experiments on arbitrarily-shaped\nbenchmark datasets, namely Total-Text and CTW1500, demonstrate that ABCNet\nachieves state-of-the-art accuracy, meanwhile significantly improving the\nspeed. In particular, on Total-Text, our realtime version is over 10 times\nfaster than recent state-of-the-art methods with a competitive recognition\naccuracy. Code is available at https://tinyurl.com/AdelaiDet", "authors": ["Yuliang Liu", "Hao Chen", "Chunhua Shen", "Tong He", "Lianwen Jin", "Liangwei Wang"], "category": "cs.CV", "comment": "Accepted to Proc. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR) 2020", "img": "/static/thumbs/2002.10200v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10200v2", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10200v2", "published_time": "2/25/2020", "rawpid": "2002.10200", "tags": ["cs.CV"], "title": "ABCNet: Real-time Scene Text Spotting with Adaptive Bezier-Curve Network"}, {"abstract": "Lightweight architectural designs of Convolutional Neural Networks (CNNs)\ntogether with quantization have paved the way for the deployment of demanding\ncomputer vision applications on mobile devices. Parallel to this, alternative\nformulations to the convolution operation such as FFT, Strassen and Winograd,\nhave been adapted for use in CNNs offering further speedups. Winograd\nconvolutions are the fastest known algorithm for spatially small convolutions,\nbut exploiting their full potential comes with the burden of numerical error,\nrendering them unusable in quantized contexts. In this work we propose a\nWinograd-aware formulation of convolution layers which exposes the numerical\ninaccuracies introduced by the Winograd transformations to the learning of the\nmodel parameters, enabling the design of competitive quantized models without\nimpacting model size. We also address the source of the numerical error and\npropose a relaxation on the form of the transformation matrices, resulting in\nup to 10% higher classification accuracy on CIFAR-10. Finally, we propose\nwiNAS, a neural architecture search (NAS) framework that jointly optimizes a\ngiven macro-architecture for accuracy and latency leveraging Winograd-aware\nlayers. A Winograd-aware ResNet-18 optimized with wiNAS for CIFAR-10 results in\n2.66x speedup compared to im2row, one of the most widely used optimized\nconvolution implementations, with no loss in accuracy.", "authors": ["Javier Fernandez-Marques", "Paul N. Whatmough", "Andrew Mundy", "Matthew Mattina"], "category": "cs.LG", "comment": "Published as a conference paper at MLSys 2020", "img": "/static/thumbs/2002.10711v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10711v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10711v1", "published_time": "2/25/2020", "rawpid": "2002.10711", "tags": ["cs.LG", "cs.CV", "stat.ML"], "title": "Searching for Winograd-aware Quantized Networks"}, {"abstract": "Emotion-cause pair extraction (ECPE), as an emergent natural language\nprocessing task, aims at jointly investigating emotions and their underlying\ncauses in documents. It extends the previous emotion cause extraction (ECE)\ntask, yet without requiring a set of pre-given emotion clauses as in ECE.\nExisting approaches to ECPE generally adopt a two-stage method, i.e., (1)\nemotion and cause detection, and then (2) pairing the detected emotions and\ncauses. Such pipeline method, while intuitive, suffers from two critical\nissues, including error propagation across stages that may hinder the\neffectiveness, and high computational cost that would limit the practical\napplication of the method. To tackle these issues, we propose a multi-task\nlearning model that can extract emotions, causes and emotion-cause pairs\nsimultaneously in an end-to-end manner. Specifically, our model regards pair\nextraction as a link prediction task, and learns to link from emotion clauses\nto cause clauses, i.e., the links are directional. Emotion extraction and cause\nextraction are incorporated into the model as auxiliary tasks, which further\nboost the pair extraction. Experiments are conducted on an ECPE benchmarking\ndataset. The results show that our proposed model outperforms a range of\nstate-of-the-art approaches in terms of both effectiveness and efficiency.", "authors": ["Haolin Song", "Chen Zhang", "Qiuchi Li", "Dawei Song"], "category": "cs.CL", "comment": "7 pages, 3 figures, 5 tables", "img": "/static/thumbs/2002.10710v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10710v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10710v1", "published_time": "2/25/2020", "rawpid": "2002.10710", "tags": ["cs.CL"], "title": "End-to-end Emotion-Cause Pair Extraction via Learning to Link"}, {"abstract": "Imputation of missing data is a common application in various classification\nproblems where the feature training matrix has missingness. A widely used\nsolution to this imputation problem is based on the lazy learning technique,\n$k$-nearest neighbor (kNN) approach. However, most of the previous work on\nmissing data does not take into account the presence of the class label in the\nclassification problem. Also, existing kNN imputation methods use variants of\nMinkowski distance as a measure of distance, which does not work well with\nheterogeneous data. In this paper, we propose a novel iterative kNN imputation\ntechnique based on class weighted grey distance between the missing datum and\nall the training data. Grey distance works well in heterogeneous data with\nmissing instances. The distance is weighted by Mutual Information (MI) which is\na measure of feature relevance between the features and the class label. This\nensures that the imputation of the training data is directed towards improving\nclassification performance. This class weighted grey kNN imputation algorithm\ndemonstrates improved performance when compared to other kNN imputation\nalgorithms, as well as standard imputation algorithms such as MICE and\nmissForest, in imputation and classification problems. These problems are based\non simulated scenarios and UCI datasets with various rates of missingness.", "authors": ["Arkopal Choudhury", "Michael R. Kosorok"], "category": "stat.ML", "comment": "27 pages, 5 figures", "img": "/static/thumbs/2002.10709v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10709v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10709v1", "published_time": "2/25/2020", "rawpid": "2002.10709", "tags": ["stat.ML", "cs.LG", "stat.AP", "stat.ME"], "title": "Missing Data Imputation for Classification Problems"}, {"abstract": "Estimating the 3D translation and orientation of an object is a challenging\ntask that can be considered within augmented reality or robotic applications.\nIn this paper, we propose a novel approach to perform 6 DoF object pose\nestimation from a single RGB-D image in cluttered scenes. We adopt an hybrid\npipeline in two stages: data-driven and geometric respectively. The first\ndata-driven step consists of a classification CNN to estimate the object 2D\nlocation in the image from local patches, followed by a regression CNN trained\nto predict the 3D location of a set of keypoints in the camera coordinate\nsystem. We robustly perform local voting to recover the location of each\nkeypoint in the camera coordinate system. To extract the pose information, the\ngeometric step consists in aligning the 3D points in the camera coordinate\nsystem with the corresponding 3D points in world coordinate system by\nminimizing a registration error, thus computing the pose. Our experiments on\nthe standard dataset LineMod show that our approach more robust and accurate\nthan state-of-the-art methods.", "authors": ["Mathieu Gonzalez", "Amine Kacete", "Albert Murienne", "Eric Marchand"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2002.00911v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.00911v3", "num_discussion": 0, "originally_published_time": "2/3/2020", "pid": "2002.00911v3", "published_time": "2/25/2020", "rawpid": "2002.00911", "tags": ["cs.CV"], "title": "YOLOff: You Only Learn Offsets for robust 6DoF object pose estimation"}, {"abstract": "Though recent research has achieved remarkable progress in generating\nrealistic images with generative adversarial networks (GANs), the lack of\ntraining stability is still a lingering concern of most GANs, especially on\nhigh-resolution inputs and complex datasets. Since the randomly generated\ndistribution can hardly overlap with the real distribution, training GANs often\nsuffers from the gradient vanishing problem. A number of approaches have been\nproposed to address this issue by constraining the discriminator\u0027s capabilities\nusing empirical techniques, like weight clipping, gradient penalty, spectral\nnormalization etc. In this paper, we provide a more principled approach as an\nalternative solution to this issue. Instead of training the discriminator to\ndistinguish real and fake input samples, we investigate the relationship\nbetween paired samples by training the discriminator to separate paired samples\nfrom the same distribution and those from different distributions. To this end,\nwe explore a relation network architecture for the discriminator and design a\ntriplet loss which performs better generalization and stability. Extensive\nexperiments on benchmark datasets show that the proposed relation discriminator\nand new loss can provide significant improvement on variable vision tasks\nincluding unconditional and conditional image generation and image translation.\nOur source codes are available on the website:\n\\url{https://github.com/JosephineRabbit/Relation-GAN}", "authors": ["Runmin Wu", "Kunyao Zhang", "Lijun Wang", "Yue Wang", "Huchuan Lu", "Yizhou Yu"], "category": "cs.CV", "comment": "8 pages", "img": "/static/thumbs/2002.10174v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10174v2", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10174v2", "published_time": "2/25/2020", "rawpid": "2002.10174", "tags": ["cs.CV", "cs.LG", "eess.IV"], "title": "When Relation Networks meet GANs: Relation GANs with Triplet Loss"}, {"abstract": "We propose Localized Narratives, an efficient way to collect image captions\nwith dense visual grounding. We ask annotators to describe an image with their\nvoice while simultaneously hovering their mouse over the region they are\ndescribing. Since the voice and the mouse pointer are synchronized, we can\nlocalize every single word in the description. This dense visual grounding\ntakes the form of a mouse trace segment per word and is unique to our data. We\nannotate 628k images with Localized Narratives: the whole COCO dataset and 504k\nimages of the Open Images dataset, which we make publicly available. We provide\nan extensive analysis of these annotations and demonstrate their utility on two\napplications which benefit from our mouse trace: controlled image captioning\nand image generation.", "authors": ["Jordi Pont-Tuset", "Jasper Uijlings", "Soravit Changpinyo", "Radu Soricut", "Vittorio Ferrari"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1912.03098v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1912.03098v2", "num_discussion": 0, "originally_published_time": "12/6/2019", "pid": "1912.03098v2", "published_time": "2/25/2020", "rawpid": "1912.03098", "tags": ["cs.CV"], "title": "Connecting Vision and Language with Localized Narratives"}, {"abstract": "Are Graph Neural Networks (GNNs) fair? In many real world graphs, the\nformation of edges is related to certain node attributes (e.g. gender,\ncommunity, reputation). In this case, standard GNNs using these edges will be\nbiased by this information, as it is encoded in the structure of the adjacency\nmatrix itself. In this paper, we show that when metadata is correlated with the\nformation of node neighborhoods, unsupervised node embedding dimensions learn\nthis metadata. This bias implies an inability to control for important\ncovariates in real-world applications, such as recommendation systems. To solve\nthese issues, we introduce the Metadata-Orthogonal Node Embedding Training\n(MONET) unit, a general model for debiasing embeddings of nodes in a graph.\nMONET achieves this by ensuring that the node embeddings are trained on a\nhyperplane orthogonal to that of the node metadata. This effectively organizes\nunstructured embedding dimensions into an interpretable topology-only,\nmetadata-only division with no linear interactions. We illustrate the\neffectiveness of MONET though our experiments on a variety of real world\ngraphs, which shows that our method can learn and remove the effect of\narbitrary covariates in tasks such as preventing the leakage of political party\naffiliation in a blog network, and thwarting the gaming of embedding-based\nrecommendation systems.", "authors": ["John Palowitch", "Bryan Perozzi"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1909.11793v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1909.11793v2", "num_discussion": 0, "originally_published_time": "9/25/2019", "pid": "1909.11793v2", "published_time": "2/25/2020", "rawpid": "1909.11793", "tags": ["cs.LG", "cs.SI", "stat.ML"], "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training\n  Unit"}, {"abstract": "In recent years, different types of adversarial examples from different\nfields have emerged endlessly, including purely natural ones without\nperturbations. A variety of defenses are proposed and then broken quickly. Two\nfundamental questions need to be asked: What\u0027s the reason for the existence of\nadversarial examples and are adversarial examples unsolvable? In this paper, we\nwill show the reason for the existence of adversarial examples is there are\nnon-isomorphic natural explanations that can all explain data set.\nSpecifically, for two natural explanations of being true and provable,\nG\\\"odel\u0027s sentence is an adversarial example but ineliminable. It can\u0027t be\nsolved by the re-accumulation of data set or the re-improvement of learning\nalgorithm. Finally, from the perspective of computability, we will prove the\nincomputability for adversarial examples, which are unrecognizable.", "authors": ["Xiaodong Qi", "Lansheng Han"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10703v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10703v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10703v1", "published_time": "2/25/2020", "rawpid": "2002.10703", "tags": ["cs.LG", "cs.CV", "stat.ML"], "title": "G\u00f6del\u0027s Sentence Is An Adversarial Example But Unsolvable"}, {"abstract": "We introduce FPConv, a novel surface-style convolution operator designed for\n3D point cloud analysis. Unlike previous methods, FPConv doesn\u0027t require\ntransforming to intermediate representation like 3D grid or graph and directly\nworks on surface geometry of point cloud. To be more specific, for each point,\nFPConv performs a local flattening by automatically learning a weight map to\nsoftly project surrounding points onto a 2D grid. Regular 2D convolution can\nthus be applied for efficient feature learning. FPConv can be easily integrated\ninto various network architectures for tasks like 3D object classification and\n3D scene segmentation, and achieve compatible performance with existing\nvolumetric-type convolutions. More importantly, our experiments also show that\nFPConv can be a complementary of volumetric convolutions and jointly training\nthem can further boost overall performance into state-of-the-art results.", "authors": ["Yiqun Lin", "Zizheng Yan", "Haibin Huang", "Dong Du", "Ligang Liu", "Shuguang Cui", "Xiaoguang Han"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2002.10701v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10701v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10701v1", "published_time": "2/25/2020", "rawpid": "2002.10701", "tags": ["cs.CV"], "title": "FPConv: Learning Local Flattening for Point Convolution"}, {"abstract": "One of the tasks in aspect-based sentiment analysis is to extract aspect and\nopinion terms from review text. Our study focuses on evaluating transfer\nlearning using BERT (Devlin et al., 2019) to classify tokens from hotel reviews\nin bahasa Indonesia. We show that the default BERT model failed to outperform a\nsimple argmax method. However, changing the default BERT tokenizer to our\ncustom one can improve the F1 scores on our labels of interest by at least 5%.\nFor I-ASPECT and B-SENTIMENT, it can even increased the F1 scores by 11%. On\nentity-level evaluation, our tweak on the tokenizer can achieve F1 scores of\n87% and 89% for ASPECT and SENTIMENT labels respectively. These scores are only\n2% away from the best model by Fernando et al. (2019), but with much less\ntraining effort (8 vs 200 epochs).", "authors": ["Ali Akbar Septiandri", "Arie Pratama Sutiono"], "category": "cs.CL", "comment": "Some mistakes in the experiment", "img": "/static/thumbs/1909.11879v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1909.11879v3", "num_discussion": 0, "originally_published_time": "9/26/2019", "pid": "1909.11879v3", "published_time": "2/25/2020", "rawpid": "1909.11879", "tags": ["cs.CL"], "title": "Aspect and Opinion Term Extraction for Aspect Based Sentiment Analysis\n  of Hotel Reviews Using Transfer Learning"}, {"abstract": "Video question answering (VideoQA) is challenging as it requires modeling\ncapacity to distill dynamic visual artifacts and distant relations and to\nassociate them with linguistic concepts. We introduce a general-purpose\nreusable neural unit called Conditional Relation Network (CRN) that serves as a\nbuilding block to construct more sophisticated structures for representation\nand reasoning over video. CRN takes as input an array of tensorial objects and\na conditioning feature, and computes an array of encoded output objects. Model\nbuilding becomes a simple exercise of replication, rearrangement and stacking\nof these reusable units for diverse modalities and contextual information. This\ndesign thus supports high-order relational and multi-step reasoning. The\nresulting architecture for VideoQA is a CRN hierarchy whose branches represent\nsub-videos or clips, all sharing the same question as the contextual condition.\nOur evaluations on well-known datasets achieved new SoTA results, demonstrating\nthe impact of building a general-purpose reasoning unit on complex domains such\nas VideoQA.", "authors": ["Thao Minh Le", "Vuong Le", "Svetha Venkatesh", "Truyen Tran"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2002.10698v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10698v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10698v1", "published_time": "2/25/2020", "rawpid": "2002.10698", "tags": ["cs.CV"], "title": "Hierarchical Conditional Relation Networks for Video Question Answering"}, {"abstract": "Collaborative work often benefits from having teams or organizations with\nheterogeneous members. In this paper, we present a method to form such diverse\nteams from people arriving sequentially over time. We define a monotone\nsubmodular objective function that combines the diversity and quality of a team\nand propose an algorithm to maximize the objective while satisfying multiple\nconstraints. This allows us to balance both how diverse the team is and how\nwell it can perform the task at hand. Using crowd experiments, we show that, in\npractice, the algorithm leads to large gains in team diversity. Using\nsimulations, we show how to quantify the additional cost of forming diverse\nteams and how to address the problem of simultaneously maximizing diversity for\nseveral attributes (e.g., country of origin, gender). Our method has\napplications in collaborative work ranging from team formation, the assignment\nof workers to teams in crowdsourcing, and reviewer allocation to journal papers\narriving sequentially. Our code is publicly accessible for further research.", "authors": ["Faez Ahmed", "John Dickerson", "Mark Fuge"], "category": "cs.AI", "comment": "Journal of Mechanical Design", "img": "/static/thumbs/2002.10697v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10697v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10697v1", "published_time": "2/25/2020", "rawpid": "2002.10697", "tags": ["cs.AI", "cs.CY", "cs.LG"], "title": "Forming Diverse Teams from Sequentially Arriving People"}, {"abstract": "We develop Neuron Shapley as a new framework to quantify the contribution of\nindividual neurons to the prediction and performance of a deep network. By\naccounting for interactions across neurons, Neuron Shapley is more effective in\nidentifying important filters compared to common approaches based on activation\npatterns. Interestingly, removing just 30 filters with the highest Shapley\nscores effectively destroys the prediction accuracy of Inception-v3 on\nImageNet. Visualization of these few critical filters provides insights into\nhow the network functions. Neuron Shapley is a flexible framework and can be\napplied to identify responsible neurons in many tasks. We illustrate additional\napplications of identifying filters that are responsible for biased prediction\nin facial recognition and filters that are vulnerable to adversarial attacks.\nRemoving these filters is a quick way to repair models. Enabling all these\napplications is a new multi-arm bandit algorithm that we developed to\nefficiently estimate Neuron Shapley values.", "authors": ["Amirata Ghorbani", "James Zou"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/2002.09815v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.09815v2", "num_discussion": 0, "originally_published_time": "2/23/2020", "pid": "2002.09815v2", "published_time": "2/25/2020", "rawpid": "2002.09815", "tags": ["stat.ML", "cs.CV", "cs.LG", "cs.NE"], "title": "Neuron Shapley: Discovering the Responsible Neurons"}, {"abstract": "Deep neural network (DNN) predictions have been shown to be vulnerable to\ncarefully crafted adversarial perturbations. Specifically, image-agnostic\n(universal adversarial) perturbations added to any image can fool a target\nnetwork into making erroneous predictions. Departing from existing defense\nstrategies that work mostly in the image domain, we present a novel defense\nwhich operates in the DNN feature domain and effectively defends against such\nuniversal perturbations. Our approach identifies pre-trained convolutional\nfeatures that are most vulnerable to adversarial noise and deploys trainable\nfeature regeneration units which transform these DNN filter activations into\nresilient features that are robust to universal perturbations. Regenerating\nonly the top 50% adversarially susceptible activations in at most 6 DNN layers\nand leaving all remaining DNN activations unchanged, we outperform existing\ndefense strategies across different network architectures by more than 10% in\nrestored accuracy. We show that without any additional modification, our\ndefense trained on ImageNet with one type of universal attack examples\neffectively defends against other types of unseen universal attacks.", "authors": ["Tejas Borkar", "Felix Heide", "Lina Karam"], "category": "cs.CV", "comment": "Accepted to CVPR 2020", "img": "/static/thumbs/1906.03444v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1906.03444v3", "num_discussion": 0, "originally_published_time": "6/8/2019", "pid": "1906.03444v3", "published_time": "2/25/2020", "rawpid": "1906.03444", "tags": ["cs.CV"], "title": "Defending Against Universal Attacks Through Selective Feature\n  Regeneration"}, {"abstract": "Audio-Visual Scene-Aware Dialog (AVSD) is an extension from Video Question\nAnswering (QA) whereby the dialogue agent is required to generate natural\nlanguage responses to address user queries and carry on conversations. This is\na challenging task as it consists of video features of multiple modalities,\nincluding text, visual, and audio features. The agent also needs to learn\nsemantic dependencies among user utterances and system responses to make\ncoherent conversations with humans. In this work, we describe our submission to\nthe AVSD track of the 8th Dialogue System Technology Challenge. We adopt\ndot-product attention to combine text and non-text features of input video. We\nfurther enhance the generation capability of the dialogue agent by adopting\npointer networks to point to tokens from multiple source sequences in each\ngeneration step. Our systems achieve high performance in automatic metrics and\nobtain 5th and 6th place in human evaluation among all submissions.", "authors": ["Hung Le", "Nancy F. Chen"], "category": "cs.CL", "comment": "Accepted at DSTC Workshop at AAAI 2020", "img": "/static/thumbs/2002.10695v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10695v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10695v1", "published_time": "2/25/2020", "rawpid": "2002.10695", "tags": ["cs.CL", "cs.CV", "cs.LG"], "title": "Multimodal Transformer with Pointer Network for the DSTC8 AVSD Challenge"}, {"abstract": "Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) is a momentum version of\nstochastic gradient descent with properly injected Gaussian noise to find a\nglobal minimum. In this paper, non-asymptotic convergence analysis of SGHMC is\ngiven in the context of non-convex optimization, where subsampling techniques\nare used over an i.i.d dataset for gradient updates. Our results complement\nthose of [RRT17] and improve on those of [GGZ18].", "authors": ["Huy N. Chau", "Miklos Rasonyi"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1903.10328v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1903.10328v3", "num_discussion": 0, "originally_published_time": "3/25/2019", "pid": "1903.10328v3", "published_time": "2/25/2020", "rawpid": "1903.10328", "tags": ["stat.ML", "cs.LG"], "title": "Stochastic Gradient Hamiltonian Monte Carlo for Non-Convex Learning"}, {"abstract": "The best performing methods for 3D human pose estimation from monocular\nimages require large amounts of in-the-wild 2D and controlled 3D pose annotated\ndatasets which are costly and require sophisticated systems to acquire. To\nreduce this annotation dependency, we propose Multiview-Consistent Semi\nSupervised Learning (MCSS) framework that utilizes similarity in pose\ninformation from unannotated, uncalibrated but synchronized multi-view videos\nof human motions as additional weak supervision signal to guide 3D human pose\nregression. Our framework applies hard-negative mining based on temporal\nrelations in multi-view videos to arrive at a multi-view consistent pose\nembedding. When jointly trained with limited 3D pose annotations, our approach\nimproves the baseline by 25% and state-of-the-art by 8.7%, whilst using\nsubstantially smaller networks. Lastly, but importantly, we demonstrate the\nadvantages of the learned embedding and establish view-invariant pose retrieval\nbenchmarks on two popular, publicly available multi-view human pose datasets,\nHuman 3.6M and MPI-INF-3DHP, to facilitate future research.", "authors": ["Rahul Mitra", "Nitesh B. Gundavarapu", "Abhishek Sharma", "Arjun Jain"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1908.05293v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1908.05293v3", "num_discussion": 0, "originally_published_time": "8/14/2019", "pid": "1908.05293v3", "published_time": "2/25/2020", "rawpid": "1908.05293", "tags": ["cs.CV"], "title": "Multiview-Consistent Semi-Supervised Learning for 3D Human Pose\n  Estimation"}, {"abstract": "We propose a new framework for reasoning about information in complex\nsystems. Our foundation is based on a variational extension of Shannon\u0027s\ninformation theory that takes into account the modeling power and computational\nconstraints of the observer. The resulting \\emph{predictive\n$\\mathcal{V}$-information} encompasses mutual information and other notions of\ninformativeness such as the coefficient of determination. Unlike Shannon\u0027s\nmutual information and in violation of the data processing inequality,\n$\\mathcal{V}$-information can be created through computation. This is\nconsistent with deep neural networks extracting hierarchies of progressively\nmore informative features in representation learning. Additionally, we show\nthat by incorporating computational constraints, $\\mathcal{V}$-information can\nbe reliably estimated from data even in high dimensions with PAC-style\nguarantees. Empirically, we demonstrate predictive $\\mathcal{V}$-information is\nmore effective than mutual information for structure learning and fair\nrepresentation learning.", "authors": ["Yilun Xu", "Shengjia Zhao", "Jiaming Song", "Russell Stewart", "Stefano Ermon"], "category": "cs.LG", "comment": "ICLR 2020 (Talk)", "img": "/static/thumbs/2002.10689v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10689v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10689v1", "published_time": "2/25/2020", "rawpid": "2002.10689", "tags": ["cs.LG", "stat.ML"], "title": "A Theory of Usable Information Under Computational Constraints"}, {"abstract": "Crowd counting, i.e., estimating the number of people in a crowded area, has\nattracted much interest in the research community. Although many attempts have\nbeen reported, crowd counting remains an open real-world problem due to the\nvast scale variations in crowd density within the interested area, and severe\nocclusion among the crowd. In this paper, we propose a novel Pyramid\nDensity-Aware Attention-based network, abbreviated as PDANet, that leverages\nthe attention, pyramid scale feature and two branch decoder modules for\ndensity-aware crowd counting. The PDANet utilizes these modules to extract\ndifferent scale features, focus on the relevant information, and suppress the\nmisleading ones. We also address the variation of crowdedness levels among\ndifferent images with an exclusive Density-Aware Decoder (DAD). For this\npurpose, a classifier evaluates the density level of the input features and\nthen passes them to the corresponding high and low crowded DAD modules.\nFinally, we generate an overall density map by considering the summation of low\nand high crowded density maps as spatial attention. Meanwhile, we employ two\nlosses to create a precise density map for the input scene. Extensive\nevaluations conducted on the challenging benchmark datasets well demonstrate\nthe superior performance of the proposed PDANet in terms of the accuracy of\ncounting and generated density maps over the well-known state of the arts.", "authors": ["Saeed Amirgholipour", "Xiangjian He", "Wenjing Jia", "Dadong Wang", "Lei Liu"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2001.05643v6.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2001.05643v6", "num_discussion": 0, "originally_published_time": "1/16/2020", "pid": "2001.05643v6", "published_time": "2/25/2020", "rawpid": "2001.05643", "tags": ["cs.CV", "cs.LG"], "title": "PDANet: Pyramid Density-aware Attention Net for Accurate Crowd Counting"}, {"abstract": "Contrast maximisation estimates the motion captured in an event stream by\nmaximising the sharpness of the motion compensated event image. To carry out\ncontrast maximisation, many previous works employ iterative optimisation\nalgorithms, such as conjugate gradient, which require good initialisation to\navoid converging to bad local minima. To alleviate this weakness, we propose a\nnew globally optimal event-based motion estimation algorithm. Based-on-branch\nand bound (BnB), our method solves rotational (3DoF) motion estimation on event\nstreams, which supports practical applications such as video stabilisation and\nattitude estimation. Underpinning our method are novel bounding functions for\ncontrast maximisation, whose theoretical validity is rigorously established. We\nshow concrete examples from public datasets where globally optimal solutions\nare vital to the success of contrast maximisation. Despite its exact nature,\nour algorithm is currently able to process a 50, 000 event input in 300 seconds\n(a locally optimal solver takes 30 seconds on the same input), and has the\npotential to be further speeded-up using GPUs.", "authors": ["Daqi Liu", "\u00c1lvaro Parra", "Tat-Jun Chin"], "category": "cs.CV", "comment": "15 pages, 8 figures", "img": "/static/thumbs/2002.10686v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10686v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10686v1", "published_time": "2/25/2020", "rawpid": "2002.10686", "tags": ["cs.CV"], "title": "Globally Optimal Contrast Maximisation for Event-based Motion Estimation"}, {"abstract": "Latent block models are used for probabilistic biclustering, which is shown\nto be an effective method for analyzing various relational data sets. However,\nthere has been no statistical test method for determining the row and column\ncluster numbers of latent block models. Recent studies have constructed\nstatistical-test-based methods for stochastic block models, which assume that\nthe observed matrix is a square symmetric matrix and that the cluster\nassignments are the same for rows and columns. In this study, we developed a\nnew goodness-of-fit test for latent block models to test whether an observed\ndata matrix fits a given set of row and column cluster numbers, or it consists\nof more clusters in at least one direction of the row and the column. To\nconstruct the test method, we used a result from the random matrix theory for a\nsample covariance matrix. We experimentally demonstrated the effectiveness of\nthe proposed method by showing the asymptotic behavior of the test statistic\nand measuring the test accuracy.", "authors": ["Chihiro Watanabe", "Taiji Suzuki"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1906.03886v5.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1906.03886v5", "num_discussion": 0, "originally_published_time": "6/10/2019", "pid": "1906.03886v5", "published_time": "2/25/2020", "rawpid": "1906.03886", "tags": ["stat.ML", "cs.LG"], "title": "Goodness-of-fit Test for Latent Block Models"}, {"abstract": "PAC-Bayesian theory has received a growing attention in the machine learning\ncommunity. Our work extends the PAC-Bayesian theory by introducing several\nnovel change of measure inequalities for two families of divergences:\n$f$-divergences and $\\alpha$-divergences. First, we show how the variational\nrepresentation for $f$-divergences leads to novel change of measure\ninequalities. Second, we propose a multiplicative change of measure inequality\nfor $\\alpha$-divergences, which leads to tighter bounds under some technical\nconditions. Finally, we present several PAC-Bayesian bounds for various classes\nof random variables, by using our novel change of measure inequalities.", "authors": ["Yuki Ohnishi", "Jean Honorio"], "category": "cs.LG", "comment": "9 pages", "img": "/static/thumbs/2002.10678v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10678v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10678v1", "published_time": "2/25/2020", "rawpid": "2002.10678", "tags": ["cs.LG", "stat.ML"], "title": "Novel Change of Measure Inequalities and PAC-Bayesian Bounds"}, {"abstract": "We present a novel algorithm (DeepMNavigate) for global multi-agent\nnavigation in dense scenarios using deep reinforcement learning (DRL). Our\napproach uses local and global information for each robot from motion\ninformation maps. We use a three-layer CNN that takes these maps as input to\ngenerate a suitable action to drive each robot to its goal position. Our\napproach is general, learns an optimal policy using a multi-scenario,\nmulti-state training algorithm, and can directly handle raw sensor measurements\nfor local observations. We demonstrate the performance on dense, complex\nbenchmarks with narrow passages and environments with tens of agents. We\nhighlight the algorithm\u0027s benefits over prior learning methods and geometric\ndecentralized algorithms in complex scenarios.", "authors": ["Qingyang Tan", "Tingxiang Fan", "Jia Pan", "Dinesh Manocha"], "category": "cs.MA", "comment": "", "img": "/static/thumbs/1910.09441v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1910.09441v3", "num_discussion": 0, "originally_published_time": "10/4/2019", "pid": "1910.09441v3", "published_time": "2/25/2020", "rawpid": "1910.09441", "tags": ["cs.MA", "cs.AI", "cs.RO"], "title": "DeepMNavigate: Deep Reinforced Multi-Robot Navigation Unifying Local \u0026\n  Global Collision Avoidance"}, {"abstract": "Accurate and real-time surgical instrument segmentation is important in the\nendoscopic vision of robot-assisted surgery, and significant challenges are\nposed by frequent instrument-tissue contacts and continuous change of\nobservation perspective. For these challenging tasks more and more deep neural\nnetworks (DNN) models are designed in recent years. We are motivated to propose\na general embeddable approach to improve these current DNN segmentation models\nwithout increasing the model parameter number. Firstly, observing the limited\nrotation-invariance performance of DNN, we proposed the Multi-Angle Feature\nAggregation (MAFA) method, lever-aging active image rotation to gain richer\nvisual cues and make the prediction more robust to instrument orientation\nchanges. Secondly, in the end-to-end training stage, the auxiliary contour\nsupervision is utilized to guide the model to learn the boundary awareness, so\nthat the contour shape of segmentation mask is more precise. The effectiveness\nof the proposed methods is validated with ablation experiments con-ducted on\nnovel Sinus-Surgery datasets.", "authors": ["Fangbo Qin", "Shan Lin", "Yangming Li", "Randall A. Bly", "Kris S. Moe", "Blake Hannaford"], "category": "cs.CV", "comment": "Submitted to IEEE Robotics and Automation Letters", "img": "/static/thumbs/2002.10675v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10675v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10675v1", "published_time": "2/25/2020", "rawpid": "2002.10675", "tags": ["cs.CV"], "title": "Towards Better Surgical Instrument Segmentation in Endoscopic Vision:\n  Multi-Angle Feature Aggregation and Contour Supervision"}, {"abstract": "Batch Normalization (BatchNorm) is commonly used in Convolutional Neural\nNetworks (CNNs) to improve training speed and stability. However, there is\nstill limited consensus on why this technique is effective. This paper uses\nconcepts from the traditional adaptive filter domain to provide insight into\nthe dynamics and inner workings of BatchNorm. First, we show that the\nconvolution weight updates have natural modes whose stability and convergence\nspeed are tied to the eigenvalues of the input autocorrelation matrices, which\nare controlled by BatchNorm through the convolution layers\u0027 channel-wise\nstructure. Furthermore, our experiments demonstrate that the speed and\nstability benefits are distinct effects. At low learning rates, it is\nBatchNorm\u0027s amplification of the smallest eigenvalues that improves convergence\nspeed, while at high learning rates, it is BatchNorm\u0027s suppression of the\nlargest eigenvalues that ensures stability. Lastly, we prove that in the first\ntraining step, when normalization is needed most, BatchNorm satisfies the same\noptimization as Normalized Least Mean Square (NLMS), while it continues to\napproximate this condition in subsequent steps. The analyses provided in this\npaper lay the groundwork for gaining further insight into the operation of\nmodern neural network structures using adaptive filter theory.", "authors": ["Elaina Chai", "Mert Pilanci", "Boris Murmann"], "category": "cs.NE", "comment": "", "img": "/static/thumbs/2002.10674v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10674v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10674v1", "published_time": "2/25/2020", "rawpid": "2002.10674", "tags": ["cs.NE", "cs.LG", "eess.SP"], "title": "Separating the Effects of Batch Normalization on CNN Training Speed and\n  Stability Using Classical Adaptive Filter Theory"}, {"abstract": "Low rank matrix recovery problems appear widely in statistics, combinatorics,\nand imaging. One celebrated method for solving these problems is to formulate\nand solve a semidefinite program (SDP). It is often known that the exact\nsolution to the SDP with perfect data recovers the solution to the original low\nrank matrix recovery problem. It is more challenging to show that an\napproximate solution to the SDP formulated with noisy problem data acceptably\nsolves the original problem; arguments are usually ad hoc for each problem\nsetting, and can be complex.\n  In this note, we identify a set of conditions that we call regularity that\nlimit the error due to noisy problem data or incomplete convergence. In this\nsense, regular SDPs are robust: regular SDPs can be (approximately) solved\nefficiently at scale; and the resulting approximate solutions, even with noisy\ndata, can be trusted. Moreover, we show that regularity holds generically, and\nalso for many structured low rank matrix recovery problems, including the\nstochastic block model, $\\mathbb{Z}_2$ synchronization, and matrix completion.\nFormally, we call an SDP regular if it has a surjective constraint map, admits\na unique primal and dual solution pair, and satisfies strong duality and strict\ncomplementarity.\n  However, regularity is not a panacea: we show the Burer-Monteiro formulation\nof the SDP may have spurious second-order critical points, even for a regular\nSDP with a rank 1 solution.", "authors": ["Lijun Ding", "Madeleine Udell"], "category": "math.OC", "comment": "29 pages, 1 figure, and 1 table", "img": "/static/thumbs/2002.10673v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10673v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10673v1", "published_time": "2/25/2020", "rawpid": "2002.10673", "tags": ["math.OC", "cs.LG", "stat.ML"], "title": "On the regularity and conditioning of low rank semidefinite programs"}, {"abstract": "Internet of Things (IoT) have widely penetrated in different aspects of\nmodern life and many intelligent IoT services and applications are emerging.\nRecently, federated learning is proposed to train a globally shared model by\nexploiting a massive amount of user-generated data samples on IoT devices while\npreventing data leakage. However, the device, statistical and model\nheterogeneities inherent in the complex IoT environments pose great challenges\nto traditional federated learning, making it unsuitable to be directly\ndeployed. In this article we advocate a personalized federated learning\nframework in a cloud-edge architecture for intelligent IoT applications. To\ncope with the heterogeneity issues in IoT environments, we investigate emerging\npersonalized federated learning methods which are able to mitigate the negative\neffects caused by heterogeneity in different aspects. With the power of edge\ncomputing, the requirements for fast-processing capacity and low latency in\nintelligent IoT applications can also be achieved. We finally provide a case\nstudy of IoT based human activity recognition to demonstrate the effectiveness\nof personalized federated learning for intelligent IoT applications.", "authors": ["Qiong Wu", "Kaiwen He", "Xu Chen"], "category": "cs.NI", "comment": "Submitted for review", "img": "/static/thumbs/2002.10671v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10671v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10671v1", "published_time": "2/25/2020", "rawpid": "2002.10671", "tags": ["cs.NI", "cs.DC", "cs.LG"], "title": "Personalized Federated Learning for Intelligent IoT Applications: A\n  Cloud-Edge based Framework"}, {"abstract": "In this paper we explore the parameter efficiency of BERT $arXiv:1810.04805$\non version 2.0 of the Stanford Question Answering dataset (SQuAD2.0). We\nevaluate the parameter efficiency of BERT while freezing a varying number of\nfinal transformer layers as well as including the adapter layers proposed in\n$arXiv:1902.00751$. Additionally, we experiment with the use of context-aware\nconvolutional (CACNN) filters, as described in $arXiv:1709.08294v3$, as a final\naugmentation layer for the SQuAD2.0 tasks.\n  This exploration is motivated in part by $arXiv:1907.10597$, which made a\ncompelling case for broadening the evaluation criteria of artificial\nintelligence models to include various measures of resource efficiency. While\nwe do not evaluate these models based on their floating point operation\nefficiency as proposed in arXiv:1907.10597, we examine efficiency with respect\nto training time, inference time, and total number of model parameters. Our\nresults largely corroborate those of $arXiv:1902.00751$ for adapter modules,\nwhile also demonstrating that gains in F1 score from adding context-aware\nconvolutional filters are not practical due to the increase in training and\ninference time.", "authors": ["Eric Hulburd"], "category": "cs.CL", "comment": "11 pages, 5 figures, 3 tables", "img": "/static/thumbs/2002.10670v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10670v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10670v1", "published_time": "2/25/2020", "rawpid": "2002.10670", "tags": ["cs.CL", "cs.LG", "stat.ML"], "title": "Exploring BERT Parameter Efficiency on the Stanford Question Answering\n  Dataset v2.0"}, {"abstract": "In the era of intelligent computing, computational progress in text\nprocessing is an essential consideration. Many systems have been developed to\nprocess text over different languages. Though, there is considerable\ndevelopment, they still lack in understanding of the text, i.e., instead of\nkeeping text as knowledge, many treat text as a data. In this work we introduce\na text representation scheme which is influenced by human memory\ninfrastructure. Since texts are declarative in nature, a structural\norganization would foster efficient computation over text. We exploit long term\nepisodic memory to keep text information observed over time. This not only keep\nfragments of text in an organized fashion but also reduces redundancy and\nstores the temporal relation among them. Wordnet has been used to imitate\nsemantic memory, which works at word level to facilitate the understanding\nabout individual words within text. Experimental results of various operation\nperformed over episodic memory and growth of knowledge infrastructure over time\nis reported.", "authors": ["Sumant Pushp", "Pragya Kashmira", "Shyamanta M Hazarika"], "category": "cs.AI", "comment": "21 pages", "img": "/static/thumbs/2002.10665v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10665v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10665v1", "published_time": "2/25/2020", "rawpid": "2002.10665", "tags": ["cs.AI", "cs.CL"], "title": "Declarative Memory-based Structure for the Representation of Text Data"}, {"abstract": "This paper introduces and evaluates a novel training method for neural\nnetworks: Dual Variable Learning Rates (DVLR). Building on techniques and\ninsights from behavioral psychology, the dual learning rates are used to\nemphasize correct and incorrect responses differently, thereby making the\nfeedback to the network more specific. Further, the learning rates are varied\nas a function of the network\u0027s performance, thereby making it more efficient.\nDVLR was implemented on both a simple feedforward neural network and a\nconvolutional neural network. Both networks are trained faster and achieve an\nincreased accuracy on the MNIST and CIFAR-10 domains demonstrating that DVLR is\na promising, psychologically motivated technique for training neural network\nmodels.", "authors": ["Elizabeth Liner", "Risto Miikkulainen"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.03428v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.03428v2", "num_discussion": 0, "originally_published_time": "2/9/2020", "pid": "2002.03428v2", "published_time": "2/25/2020", "rawpid": "2002.03428", "tags": ["cs.LG", "stat.ML"], "title": "Improving Neural Network Learning Through Dual Variable Learning Rates"}, {"abstract": "Semantic segmentation for lightweight object parsing is a very challenging\ntask, because both accuracy and efficiency (e.g., execution speed, memory\nfootprint or computational complexity) should all be taken into account.\nHowever, most previous works pay too much attention to one-sided perspective,\neither accuracy or speed, and ignore others, which poses a great limitation to\nactual demands of intelligent devices. To tackle this dilemma, we propose a\nnovel lightweight architecture named Context-Integrated and Feature-Refined\nNetwork (CIFReNet). The core components of CIFReNet are the Long-skip\nRefinement Module (LRM) and the Multi-scale Context Integration Module (MCIM).\nThe LRM is designed to ease the propagation of spatial information between\nlow-level and high-level stages. Furthermore, channel attention mechanism is\nintroduced into the process of long-skip learning to boost the quality of\nlow-level feature refinement. Meanwhile, the MCIM consists of three cascaded\nDense Semantic Pyramid (DSP) blocks with image-level features, which is\npresented to encode multiple context information and enlarge the field of view.\nSpecifically, the proposed DSP block exploits a dense feature sampling strategy\nto enhance the information representations without significantly increasing the\ncomputation cost. Comprehensive experiments are conducted on three benchmark\ndatasets for object parsing including Cityscapes, CamVid, and Helen. As\nindicated, the proposed method reaches a better trade-off between accuracy and\nefficiency compared with the other state-of-the-art methods.", "authors": ["Bin Jiang", "Wenxuan Tu", "Chao Yang", "Junsong Yuan"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1907.11474v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1907.11474v3", "num_discussion": 0, "originally_published_time": "7/26/2019", "pid": "1907.11474v3", "published_time": "2/25/2020", "rawpid": "1907.11474", "tags": ["cs.CV"], "title": "Context-Integrated and Feature-Refined Network for Lightweight Object\n  Parsing"}, {"abstract": "Collective design and innovation are crucial in organizations. To investigate\nhow the collective design and innovation processes would be affected by the\ndiversity of knowledge and background of collective individual members, we\nconducted three collaborative design task experiments which involved nearly 300\nparticipants who worked together anonymously in a social network structure\nusing a custom-made computer-mediated collaboration platform. We compared the\nidea generation activity among three different background distribution\nconditions (clustered, random, and dispersed) with the help of the \"doc2vec\"\ntext representation machine learning algorithm. We also developed a new method\ncalled \"Idea Geography\" to visualize the idea utility terrain on a 2D problem\ndomain. The results showed that groups with random background allocation tended\nto produce the best design idea with highest utility values. It was also\nsuggested that the diversity of participants\u0027 backgrounds distribution on the\nnetwork might interact with each other to affect the diversity of ideas\ngenerated. The proposed idea geography successfully visualized that the\ncollective design processes did find the high utility area through exploration\nand exploitation in collaborative work.", "authors": ["Yiding Cao", "Yingjun Dong", "Minjun Kim", "Neil G. MacLaren", "Ankita Kulkarni", "Shelley D. Dionne", "Francis J. Yammarino", "Hiroki Sayama"], "category": "cs.SI", "comment": "16 pages, 10 figures, submitted to CSS 2019 (Computational Social\n  Science 2019)", "img": "/static/thumbs/1911.06353v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1911.06353v2", "num_discussion": 0, "originally_published_time": "11/14/2019", "pid": "1911.06353v2", "published_time": "2/25/2020", "rawpid": "1911.06353", "tags": ["cs.SI", "cs.LG"], "title": "Capturing the Production of the Innovative Ideas: An Online Social\n  Network Experiment and \"Idea Geography\" Visualization"}, {"abstract": "An open question in the Deep Learning community is why neural networks\ntrained with Gradient Descent generalize well on real datasets even though they\nare capable of fitting random data. We propose an approach to answering this\nquestion based on a hypothesis about the dynamics of gradient descent that we\ncall Coherent Gradients: Gradients from similar examples are similar and so the\noverall gradient is stronger in certain directions where these reinforce each\nother. Thus changes to the network parameters during training are biased\ntowards those that (locally) simultaneously benefit many examples when such\nsimilarity exists. We support this hypothesis with heuristic arguments and\nperturbative experiments and outline how this can explain several common\nempirical observations about Deep Learning. Furthermore, our analysis is not\njust descriptive, but prescriptive. It suggests a natural modification to\ngradient descent that can greatly reduce overfitting.", "authors": ["Satrajit Chatterjee"], "category": "cs.LG", "comment": "To appear in ICLR 2020", "img": "/static/thumbs/2002.10657v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10657v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10657v1", "published_time": "2/25/2020", "rawpid": "2002.10657", "tags": ["cs.LG", "cs.CV", "stat.ML"], "title": "Coherent Gradients: An Approach to Understanding Generalization in\n  Gradient Descent-based Optimization"}, {"abstract": "Many objective video quality assessment (VQA) algorithms include a key step\nof temporal pooling of frame-level quality scores. However, less attention has\nbeen paid to studying the relative efficiencies of different pooling methods on\nno-reference (blind) VQA. Here we conduct a large-scale comparative evaluation\nto assess the capabilities and limitations of multiple temporal pooling\nstrategies on blind VQA of user-generated videos. The study yields insights and\ngeneral guidance regarding the application and selection of temporal pooling\nmodels. In addition, we also propose an ensemble pooling model built on top of\nhigh-performing temporal pooling models. Our experimental results demonstrate\nthe relative efficacies of the evaluated temporal pooling models, using several\npopular VQA algorithms, and evaluated on two recent large-scale natural video\nquality databases. In addition to the new ensemble model, we provide a general\nrecipe for applying temporal pooling of frame-based quality predictions.", "authors": ["Zhengzhong Tu", "Chia-Ju Chen", "Li-Heng Chen", "Neil Birkbeck", "Balu Adsumilli", "Alan C. Bovik"], "category": "cs.MM", "comment": "", "img": "/static/thumbs/2002.10651v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10651v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10651v1", "published_time": "2/25/2020", "rawpid": "2002.10651", "tags": ["cs.MM", "cs.CV"], "title": "A Comparative Evaluation of Temporal Pooling Methods for Blind Video\n  Quality Assessment"}, {"abstract": "Existing face hallucination methods based on convolutional neural networks\n(CNN) have achieved impressive performance on low-resolution (LR) faces in a\nnormal illumination condition. However, their performance degrades dramatically\nwhen LR faces are captured in low or non-uniform illumination conditions. This\npaper proposes a Copy and Paste Generative Adversarial Network (CPGAN) to\nrecover authentic high-resolution (HR) face images while compensating for low\nand non-uniform illumination. To this end, we develop two key components in our\nCPGAN: internal and external Copy and Paste nets (CPnets). Specifically, our\ninternal CPnet exploits facial information residing in the input image to\nenhance facial details; while our external CPnet leverages an external HR face\nfor illumination compensation. A new illumination compensation loss is thus\ndeveloped to capture illumination from the external guided face image\neffectively. Furthermore, our method offsets illumination and upsamples facial\ndetails alternately in a coarse-to-fine fashion, thus alleviating the\ncorrespondence ambiguity between LR inputs and external HR inputs. Extensive\nexperiments demonstrate that our method manifests authentic HR face images in a\nuniform illumination condition and outperforms state-of-the-art methods\nqualitatively and quantitatively.", "authors": ["Yang Zhang", "Ivor Tsang", "Yawei Luo", "Changhui Hu", "Xiaobo Lu", "Xin Yu"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2002.10650v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10650v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10650v1", "published_time": "2/25/2020", "rawpid": "2002.10650", "tags": ["cs.CV"], "title": "Copy and Paste GAN: Face Hallucination from Shaded Thumbnails"}, {"abstract": "We propose a flexible framework that deals with both singer conversion and\nsingers vocal technique conversion. The proposed model is trained on\nnon-parallel corpora, accommodates many-to-many conversion, and leverages\nrecent advances of variational autoencoders. It employs separate encoders to\nlearn disentangled latent representations of singer identity and vocal\ntechnique separately, with a joint decoder for reconstruction. Conversion is\ncarried out by simple vector arithmetic in the learned latent spaces. Both a\nquantitative analysis as well as a visualization of the converted spectrograms\nshow that our model is able to disentangle singer identity and vocal technique\nand successfully perform conversion of these attributes. To the best of our\nknowledge, this is the first work to jointly tackle conversion of singer\nidentity and vocal technique based on a deep learning approach.", "authors": ["Yin-Jyun Luo", "Chin-Chen Hsu", "Kat Agres", "Dorien Herremans"], "category": "eess.AS", "comment": "Accepted to ICASSP 2020", "img": "/static/thumbs/1912.02613v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1912.02613v3", "num_discussion": 0, "originally_published_time": "12/3/2019", "pid": "1912.02613v3", "published_time": "2/25/2020", "rawpid": "1912.02613", "tags": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "title": "Singing Voice Conversion with Disentangled Representations of Singer and\n  Vocal Technique Using Variational Autoencoders"}, {"abstract": "The learning of hierarchical representations for image classification has\nexperienced an impressive series of successes due in part to the availability\nof large-scale labeled data for training. On the other hand, the trained\nclassifiers have traditionally been evaluated on small and fixed sets of test\nimages, which are deemed to be extremely sparsely distributed in the space of\nall natural images. It is thus questionable whether recent performance\nimprovements on the excessively re-used test sets generalize to real-world\nnatural images with much richer content variations. Inspired by efficient\nstimulus selection for testing perceptual models in psychophysical and\nphysiological studies, we present an alternative framework for comparing image\nclassifiers, which we name the MAximum Discrepancy (MAD) competition. Rather\nthan comparing image classifiers using fixed test images, we adaptively sample\na small test set from an arbitrarily large corpus of unlabeled images so as to\nmaximize the discrepancies between the classifiers, measured by the distance\nover WordNet hierarchy. Human labeling on the resulting model-dependent image\nsets reveals the relative performance of the competing classifiers, and\nprovides useful insights on potential ways to improve them. We report the MAD\ncompetition results of eleven ImageNet classifiers while noting that the\nframework is readily extensible and cost-effective to add future classifiers\ninto the competition. Codes can be found at https://github.com/TAMU-VITA/MAD.", "authors": ["Haotao Wang", "Tianlong Chen", "Zhangyang Wang", "Kede Ma"], "category": "cs.LG", "comment": "Accepted to ICLR 2020", "img": "/static/thumbs/2002.10648v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10648v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10648v1", "published_time": "2/25/2020", "rawpid": "2002.10648", "tags": ["cs.LG", "cs.CV", "stat.ML"], "title": "I Am Going MAD: Maximum Discrepancy Competition for Comparing\n  Classifiers Adaptively"}, {"abstract": "Deep networks were recently suggested to face the odds between accuracy (on\nclean natural images) and robustness (on adversarially perturbed images)\n(Tsipras et al., 2019). Such a dilemma is shown to be rooted in the inherently\nhigher sample complexity (Schmidt et al., 2018) and/or model capacity\n(Nakkiran, 2019), for learning a high-accuracy and robust classifier. In view\nof that, give a classification task, growing the model capacity appears to help\ndraw a win-win between accuracy and robustness, yet at the expense of model\nsize and latency, therefore posing challenges for resource-constrained\napplications. Is it possible to co-design model accuracy, robustness and\nefficiency to achieve their triple wins? This paper studies multi-exit networks\nassociated with input-adaptive efficient inference, showing their strong\npromise in achieving a \"sweet point\" in cooptimizing model accuracy, robustness\nand efficiency. Our proposed solution, dubbed Robust Dynamic Inference Networks\n(RDI-Nets), allows for each input (either clean or adversarial) to adaptively\nchoose one of the multiple output layers (early branches or the final one) to\noutput its prediction. That multi-loss adaptivity adds new variations and\nflexibility to adversarial attacks and defenses, on which we present a\nsystematical investigation. We show experimentally that by equipping existing\nbackbones with such robust adaptive inference, the resulting RDI-Nets can\nachieve better accuracy and robustness, yet with over 30% computational\nsavings, compared to the defended original models.", "authors": ["Ting-Kuei Hu", "Tianlong Chen", "Haotao Wang", "Zhangyang Wang"], "category": "cs.CV", "comment": "Published on ICLR 2020", "img": "/static/thumbs/2002.10025v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10025v2", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10025v2", "published_time": "2/25/2020", "rawpid": "2002.10025", "tags": ["cs.CV", "cs.LG"], "title": "Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by\n  Enabling Input-Adaptive Inference"}, {"abstract": "Generative moment matching networks (GMMNs) are introduced as dependence\nmodels for the joint innovation distribution of multivariate time series (MTS).\nFollowing the popular copula-GARCH approach for modeling dependent MTS data, a\nframework allowing us to take an alternative GMMN-GARCH approach is presented.\nFirst, ARMA-GARCH models are utilized to capture the serial dependence within\neach univariate marginal time series. Second, if the number of marginal time\nseries is large, principal component analysis (PCA) is used as a\ndimension-reduction step. Last, the remaining cross-sectional dependence is\nmodeled via a GMMN, our main contribution. GMMNs are highly flexible and easy\nto simulate from, which is a major advantage over the copula-GARCH approach.\nApplications involving yield curve modeling and the analysis of foreign\nexchange rate returns are presented to demonstrate the utility of our approach,\nespecially in terms of producing better empirical predictive distributions and\nmaking better probabilistic forecasts. All results are reproducible with the\ndemo GMMN_MTS_paper of the R package gnn.", "authors": ["Marius Hofert", "Avinash Prasad", "Mu Zhu"], "category": "stat.ME", "comment": "", "img": "/static/thumbs/2002.10645v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10645v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10645v1", "published_time": "2/25/2020", "rawpid": "2002.10645", "tags": ["stat.ME", "cs.LG", "stat.ML", "62H99, 65C60, 60E05, 00A72, 65C10, 62M10"], "title": "Multivariate time-series modeling with generative neural networks"}, {"abstract": "This work investigates the design of motion planning strategies that can\nincorporate non-rational perception of risks associated with uncertain spatial\ncosts. Our proposed method employs the Cumulative Prospect Theory (CPT) model\nto generate a perceived risk function across a given environment, which is\nscalable to high dimensional space. Using this, CPT-like perceived risks and\npath-length metrics are combined to define a cost function that is compliant\nwith the requirements of asymptotic optimality of sampling-based motion\nplanners (RRT*). The modeling capabilities of CPT are demonstrated in\nsimulation by producing a rich set of meaningful paths, capturing a range of\ndifferent risk perceptions in a custom environment. Furthermore, using a\nsimultaneous perturbation stochastic approximation (SPSA) method, we\ninvestigate the capacity of these CPT-based risk-perception planners to\napproximate arbitrary paths drawn in the environment. We compare this\nadaptability with Conditional Value at Risk (CVaR), another popular risk\nperception model. Our simulations show that CPT is richer and able to capture a\nlarger class of paths as compared to CVaR and expected risk in our setting.", "authors": ["Aamodh Suresh", "Sonia Martinez"], "category": "cs.RO", "comment": "10 pages and 7 figures. This revision adds more results and\n  comparisons along with more explanatio...", "img": "/static/thumbs/1904.02851v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1904.02851v2", "num_discussion": 0, "originally_published_time": "4/5/2019", "pid": "1904.02851v2", "published_time": "2/25/2020", "rawpid": "1904.02851", "tags": ["cs.RO", "cs.AI", "cs.LG", "cs.SY"], "title": "Planning under non-rational perception of uncertain spatial costs"}, {"abstract": "We consider the task of answering complex multi-hop questions using a corpus\nas a virtual knowledge base (KB). In particular, we describe a neural module,\nDrKIT, that traverses textual data like a KB, softly following paths of\nrelations between mentions of entities in the corpus. At each step the module\nuses a combination of sparse-matrix TFIDF indices and a maximum inner product\nsearch (MIPS) on a special index of contextual representations of the mentions.\nThis module is differentiable, so the full system can be trained end-to-end\nusing gradient based methods, starting from natural language inputs. We also\ndescribe a pretraining scheme for the contextual representation encoder by\ngenerating hard negative examples using existing knowledge bases. We show that\nDrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset,\ncutting the gap between text-based and KB-based state-of-the-art by 70%. On\nHotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking\napproach to retrieving the relevant passages required to answer a question.\nDrKIT is also very efficient, processing 10-100x more queries per second than\nexisting multi-hop systems.", "authors": ["Bhuwan Dhingra", "Manzil Zaheer", "Vidhisha Balachandran", "Graham Neubig", "Ruslan Salakhutdinov", "William W. Cohen"], "category": "cs.CL", "comment": "ICLR 2020", "img": "/static/thumbs/2002.10640v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10640v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10640v1", "published_time": "2/25/2020", "rawpid": "2002.10640", "tags": ["cs.CL", "cs.LG"], "title": "Differentiable Reasoning over a Virtual Knowledge Base"}, {"abstract": "Despite the widespread adoption of Transformer models for NLP tasks, the\nexpressive power of these models is not well-understood. In this paper, we\nestablish that Transformer models are universal approximators of continuous\npermutation equivariant sequence-to-sequence functions with compact support,\nwhich is quite surprising given the amount of shared parameters in these\nmodels. Furthermore, using positional encodings, we circumvent the restriction\nof permutation equivariance, and show that Transformer models can universally\napproximate arbitrary continuous sequence-to-sequence functions on a compact\ndomain. Interestingly, our proof techniques clearly highlight the different\nroles of the self-attention and the feed-forward layers in Transformers. In\nparticular, we prove that fixed width self-attention layers can compute\ncontextual mappings of the input sequences, playing a key role in the universal\napproximation property of Transformers. Based on this insight from our\nanalysis, we consider other simpler alternatives to self-attention layers and\nempirically evaluate them.", "authors": ["Chulhee Yun", "Srinadh Bhojanapalli", "Ankit Singh Rawat", "Sashank J. Reddi", "Sanjiv Kumar"], "category": "cs.LG", "comment": "23 pages, ICLR 2020 camera-ready version", "img": "/static/thumbs/1912.10077v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1912.10077v2", "num_discussion": 0, "originally_published_time": "12/20/2019", "pid": "1912.10077v2", "published_time": "2/25/2020", "rawpid": "1912.10077", "tags": ["cs.LG", "stat.ML"], "title": "Are Transformers universal approximators of sequence-to-sequence\n  functions?"}, {"abstract": "Learning to navigate in a visual environment following natural-language\ninstructions is a challenging task, because the multimodal inputs to the agent\nare highly variable, and the training data on a new task is often limited. In\nthis paper, we present the first pre-training and fine-tuning paradigm for\nvision-and-language navigation (VLN) tasks. By training on a large amount of\nimage-text-action triplets in a self-supervised learning manner, the\npre-trained model provides generic representations of visual environments and\nlanguage instructions. It can be easily used as a drop-in for existing VLN\nframeworks, leading to the proposed agent called Prevalent. It learns more\neffectively in new tasks and generalizes better in a previously unseen\nenvironment. The performance is validated on three VLN tasks. On the\nRoom-to-Room benchmark, our model improves the state-of-the-art from 47% to 51%\non success rate weighted by path length. Further, the learned representation is\ntransferable to other VLN tasks. On two recent tasks, vision-and-dialog\nnavigation and ``Help, Anna!\u0027\u0027 the proposed Prevalent leads to significant\nimprovement over existing methods, achieving a new state of the art.", "authors": ["Weituo Hao", "Chunyuan Li", "Xiujun Li", "Lawrence Carin", "Jianfeng Gao"], "category": "cs.CV", "comment": "To appear at CVPR 2020. The first two authors contributed equally to\n  this manuscript. Code: https:...", "img": "/static/thumbs/2002.10638v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10638v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10638v1", "published_time": "2/25/2020", "rawpid": "2002.10638", "tags": ["cs.CV", "cs.CL", "cs.LG", "cs.RO"], "title": "Towards Learning a Generic Agent for Vision-and-Language Navigation via\n  Pre-training"}, {"abstract": "Graphical model selection in Markov random fields is a fundamental problem in\nstatistics and machine learning. Two particularly prominent models, the Ising\nmodel and Gaussian model, have largely developed in parallel using different\n(though often related) techniques, and several practical algorithms with\nrigorous sample complexity bounds have been established for each. In this\npaper, we adapt a recently proposed algorithm of Klivans and Meka (FOCS, 2017),\nbased on the method of multiplicative weight updates, from the Ising model to\nthe Gaussian model, via non-trivial modifications to both the algorithm and its\nanalysis. The algorithm enjoys a sample complexity bound that is qualitatively\nsimilar to others in the literature, has a low runtime $O(mp^2)$ in the case of\n$m$ samples and $p$ nodes, and can trivially be implemented in an online\nmanner.", "authors": ["Anamay Chaturvedi", "Jonathan Scarlett"], "category": "stat.ML", "comment": "AISTATS 2020", "img": "/static/thumbs/2002.08663v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.08663v2", "num_discussion": 0, "originally_published_time": "2/20/2020", "pid": "2002.08663v2", "published_time": "2/25/2020", "rawpid": "2002.08663", "tags": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "math.ST", "stat.TH"], "title": "Learning Gaussian Graphical Models via Multiplicative Weights"}, {"abstract": "Koopman decomposition is a non-linear generalization of eigen decomposition,\nand is being increasingly utilized in the analysis of spatio-temporal dynamics.\nWell-known techniques such as the dynamic mode decomposition (DMD) and its\nvariants provide approximations to the Koopman operator, and have been applied\nextensively in many fluid dynamic problems. Despite being endowed with a richer\ndictionary of nonlinear observables, nonlinear variants of the DMD, such as\nextended/kernel dynamic mode decomposition (EDMD/KDMD) are seldom applied to\nlarge-scale problems primarily due to the difficulty of discerning the Koopman\ninvariant subspace from thousands of resulting Koopman triplets: eigenvalues,\neigenvectors, and modes. To address this issue, we revisit the formulation of\nEDMD and KDMD, and propose an algorithm based on multi-task feature learning to\nextract the most informative Koopman invariant subspace by removing redundant\nand spurious Koopman triplets. These algorithms can be viewed as sparsity\npromoting extensions of EDMD/KDMD and are presented in an open-source package.\nFurther, we extend KDMD to a continuous-time setting and show a relationship\nbetween the present algorithm, sparsity-promoting DMD and an empirical\ncriterion from the viewpoint of non-convex optimization. The effectiveness of\nour algorithm is demonstrated on examples ranging from simple dynamical systems\nto two-dimensional cylinder wake flows at different Reynolds numbers and a\nthree-dimensional turbulent ship air-wake flow. The latter two problems are\ndesigned such that very strong transients are present in the flow evolution,\nthus requiring accurate representation of decaying modes.", "authors": ["Shaowu Pan", "Nicholas Arnold-Medabalimi", "Karthik Duraisamy"], "category": "math.DS", "comment": "42 pages", "img": "/static/thumbs/2002.10637v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10637v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10637v1", "published_time": "2/25/2020", "rawpid": "2002.10637", "tags": ["math.DS", "physics.flu-dyn", "stat.ML", "37C30, 68T05"], "title": "Sparsity-promoting algorithms for the discovery of informative Koopman\n  invariant subspaces"}, {"abstract": "In cloud and edge computing models, it is important that compute devices at\nthe edge be as power efficient as possible. Long short-term memory (LSTM)\nneural networks have been widely used for natural language processing, time\nseries prediction and many other sequential data tasks. Thus, for these\napplications there is increasing need for low-power accelerators for LSTM model\ninference at the edge. In order to reduce power dissipation due to data\ntransfers within inference devices, there has been significant interest in\naccelerating vector-matrix multiplication (VMM) operations using non-volatile\nmemory (NVM) weight arrays. In NVM array-based hardware, reduced bit-widths\nalso significantly increases the power efficiency. In this paper, we focus on\nthe application of quantization-aware training algorithm to LSTM models, and\nthe benefits these models bring in terms of resilience against both\nquantization error and analog device noise. We have shown that only 4-bit NVM\nweights and 4-bit ADC/DACs are needed to produce equivalent LSTM network\nperformance as floating-point baseline. Reasonable levels of ADC quantization\nnoise and weight noise can be naturally tolerated within our NVMbased quantized\nLSTM network. Benchmark analysis of our proposed LSTM accelerator for inference\nhas shown at least 2.4x better computing efficiency and 40x higher area\nefficiency than traditional digital approaches (GPU, FPGA, and ASIC). Some\nother novel approaches based on NVM promise to deliver higher computing\nefficiency (up to 4.7x) but require larger arrays with potential higher error\nrates.", "authors": ["Wen Ma", "Pi-Feng Chiu", "Won Ho Choi", "Minghai Qin", "Daniel Bedau", "Martin Lueker-Boden"], "category": "cs.NE", "comment": "Published in: 2019 IEEE International Conference on Rebooting\n  Computing (ICRC)", "img": "/static/thumbs/2002.10636v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10636v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10636v1", "published_time": "2/25/2020", "rawpid": "2002.10636", "tags": ["cs.NE", "cs.ET"], "title": "Non-Volatile Memory Array Based Quantization- and Noise-Resilient LSTM\n  Neural Networks"}, {"abstract": "The variational autoencoder is a well defined deep generative model that\nutilizes an encoder-decoder framework where an encoding neural network outputs\na non-deterministic code for reconstructing an input. The encoder achieves this\nby sampling from a distribution for every input, instead of outputting a\ndeterministic code per input. The great advantage of this process is that it\nallows the use of the network as a generative model for sampling from the data\ndistribution beyond provided samples for training. We show in this work that\nutilizing batch normalization as a source for non-determinism suffices to turn\ndeterministic autoencoders into generative models on par with variational ones,\nso long as we add a suitable entropic regularization to the training objective.", "authors": ["Amur Ghose", "Abdullah Rashwan", "Pascal Poupart"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10631v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10631v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10631v1", "published_time": "2/25/2020", "rawpid": "2002.10631", "tags": ["cs.LG", "cs.CV", "stat.ML"], "title": "Batch norm with entropic regularization turns deterministic autoencoders\n  into generative models"}, {"abstract": "Accurate simulation of complex physical systems enables the development,\ntesting, and certification of control strategies before they are deployed into\nthe real systems. As simulators become more advanced, the analytical\ntractability of the differential equations and associated numerical solvers\nincorporated in the simulations diminishes, making them difficult to analyse. A\npotential solution is the use of probabilistic inference to assess the\nuncertainty of the simulation parameters given real observations of the system.\nUnfortunately the likelihood function required for inference is generally\nexpensive to compute or totally intractable. In this paper we propose to\nleverage the power of modern simulators and recent techniques in Bayesian\nstatistics for likelihood-free inference to design a control framework that is\nefficient and robust with respect to the uncertainty over simulation\nparameters. The posterior distribution over simulation parameters is propagated\nthrough a potentially non-analytical model of the system with the unscented\ntransform, and a variant of the information theoretical model predictive\ncontrol. This approach provides a more efficient way to evaluate trajectory\nroll outs than Monte Carlo sampling, reducing the online computation burden.\nExperiments show that the controller proposed attained superior performance and\nrobustness on classical control and robotics tasks when compared to models not\naccounting for the uncertainty over model parameters.", "authors": ["Lucas Barcelos", "Rafael Oliveira", "Rafael Possas", "Lionel Ott", "Fabio Ramos"], "category": "cs.RO", "comment": "To appear in ICRA 2020", "img": "/static/thumbs/2002.07379v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.07379v2", "num_discussion": 0, "originally_published_time": "2/18/2020", "pid": "2002.07379v2", "published_time": "2/25/2020", "rawpid": "2002.07379", "tags": ["cs.RO", "cs.LG"], "title": "DISCO: Double Likelihood-free Inference Stochastic Control"}, {"abstract": "Networked public goods games model scenarios in which self-interested agents\ndecide whether or how much to invest in an action that benefits not only\nthemselves, but also their network neighbors. Examples include vaccination,\nsecurity investment, and crime reporting. While every agent\u0027s utility is\nincreasing in their neighbors\u0027 joint investment, the specific form can vary\nwidely depending on the scenario. A principal, such as a policymaker, may wish\nto induce large investment from the agents. Besides direct incentives, an\nimportant lever here is the network structure itself: by adding and removing\nedges, for example, through community meetings, the principal can change the\nnature of the utility functions, resulting in different, and perhaps socially\npreferable, equilibrium outcomes. We initiate an algorithmic study of targeted\nnetwork modifications with the goal of inducing equilibria of a particular\nform. We study this question for a variety of equilibrium forms (induce all\nagents to invest, at least a given set $S$, exactly a given set $S$, at least\n$k$ agents), and for a variety of utility functions. While we show that the\nproblem is NP-complete for a number of these scenarios, we exhibit a broad\narray of scenarios in which the problem can be solved in polynomial time by\nnon-trivial reductions to (minimum-cost) matching problems.", "authors": ["David Kempe", "Sixie Yu", "Yevgeniy Vorobeychik"], "category": "cs.GT", "comment": "", "img": "/static/thumbs/2002.10627v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10627v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10627v1", "published_time": "2/25/2020", "rawpid": "2002.10627", "tags": ["cs.GT", "cs.MA"], "title": "Inducing Equilibria in Networked Public Goods Games through Network\n  Structure Modification"}, {"abstract": "The disparate experimental conditions in recent off-policy policy evaluation\n(OPE) literature make it difficult both for practitioners to choose a reliable\nestimator for their application domain, as well as for researchers to identify\nfruitful research directions. In this work, we present the first detailed\nempirical study of a broad suite of OPE methods. Based on thousands of\nexperiments and empirical analysis, we offer a summarized set of guidelines to\nadvance the understanding of OPE performance in practice, and suggest\ndirections for future research. Along the way, our empirical findings challenge\nseveral commonly held beliefs about which class of approaches tends to perform\nwell. Our accompanying software implementation serves as a first comprehensive\nbenchmark for OPE.", "authors": ["Cameron Voloshin", "Hoang M. Le", "Nan Jiang", "Yisong Yue"], "category": "cs.LG", "comment": "Main paper is 8 pages. The appendix contains many pages of tables", "img": "/static/thumbs/1911.06854v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1911.06854v2", "num_discussion": 0, "originally_published_time": "11/15/2019", "pid": "1911.06854v2", "published_time": "2/25/2020", "rawpid": "1911.06854", "tags": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "title": "Empirical Study of Off-Policy Policy Evaluation for Reinforcement\n  Learning"}, {"abstract": "Federated learning, as an emerging distributed training model of neural\nnetworks without collecting raw data, has attracted widespread attention.\nHowever, almost all existing researches of federated learning only consider\nprotecting the privacy of clients, but not preventing model iterates and final\nmodel parameters from leaking to untrusted clients and external attackers. In\nthis paper, we present the first bilateral privacy-preserving federated\nlearning scheme, which protects not only the raw training data of clients, but\nalso model iterates during the training phase as well as final model\nparameters. Specifically, we present an efficient privacy-preserving technique\nto mask or encrypt the global model, which not only allows clients to train\nover the noisy global model, but also ensures only the server can obtain the\nexact updated model. Detailed security analysis shows that clients can access\nneither model iterates nor the final global model; meanwhile, the server cannot\nobtain raw training data of clients from additional information used for\nrecovering the exact updated model. Finally, extensive experiments demonstrate\nthe proposed scheme has comparable model accuracy with traditional federated\nlearning without bringing much extra communication overhead.", "authors": ["Yan Feng", "Xue Yang", "Weijun Fang", "Shu-Tao Xia", "Xiaohu Tang"], "category": "cs.LG", "comment": "Submitted to ICML 2020", "img": "/static/thumbs/2002.09843v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.09843v2", "num_discussion": 0, "originally_published_time": "2/23/2020", "pid": "2002.09843v2", "published_time": "2/25/2020", "rawpid": "2002.09843", "tags": ["cs.LG", "cs.CR", "cs.CV", "stat.ML"], "title": "Practical and Bilateral Privacy-preserving Federated Learning"}, {"abstract": "Loop closure detection plays an important role in reducing localization drift\nin Simultaneous Localization And Mapping (SLAM). It aims to find repetitive\nscenes from historical data to reset localization. To tackle the loop closure\nproblem, existing methods often leverage on the matching of visual features,\nwhich achieve good accuracy but require high computational resources. However,\nfeature point based methods ignore the patterns of image, i.e., the shape of\nthe objects as well as the distribution of objects in an image. It is believed\nthat this information is usually unique for a scene and can be utilized to\nimprove the performance of traditional loop closure detection methods. In this\npaper we leverage and compress the information into a binary image to\naccelerate an existing fast loop closure detection method via binary content.\nThe proposed method can greatly reduce the computational cost without\nsacrificing recall rate. It consists of three parts: binary content\nconstruction, fast image retrieval and precise loop closure detection. No\noffline training is required. Our method is compared with the state-of-the-art\nloop closure detection methods and the results show that it outperforms the\ntraditional methods at both recall rate and speed.", "authors": ["Han Wang", "Juncheng Li", "Maopeng Ran", "Lihua Xie"], "category": "cs.CV", "comment": "IEEE International Conference on Control and Automation (ICCA) 2019", "img": "/static/thumbs/2002.10622v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10622v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10622v1", "published_time": "2/25/2020", "rawpid": "2002.10622", "tags": ["cs.CV", "cs.RO"], "title": "Fast Loop Closure Detection via Binary Content"}, {"abstract": "In this paper, we propose a derivative-free model learning framework for\nReinforcement Learning (RL) algorithms based on Gaussian Process Regression\n(GPR). In many mechanical systems, only positions can be measured by the\nsensing instruments. Then, instead of representing the system state as\nsuggested by the physics with a collection of positions, velocities, and\naccelerations, we define the state as the set of past position measurements.\nHowever, the equation of motions derived by physical first principles cannot be\ndirectly applied in this framework, being functions of velocities and\naccelerations. For this reason, we introduce a novel derivative-free\nphysically-inspired kernel, which can be easily combined with nonparametric\nderivative-free Gaussian Process models. Tests performed on two real platforms\nshow that the considered state definition combined with the proposed model\nimproves estimation performance and data-efficiency w.r.t. traditional models\nbased on GPR. Finally, we validate the proposed framework by solving two RL\ncontrol problems for two real robotic systems.", "authors": ["Alberto Dalla Libera", "Diego Romeres", "Devesh K. Jha", "Bill Yerazunis", "Daniel Nikovski"], "category": "cs.LG", "comment": "Accepted at RA-L", "img": "/static/thumbs/2002.10621v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10621v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10621v1", "published_time": "2/25/2020", "rawpid": "2002.10621", "tags": ["cs.LG", "cs.RO", "cs.SY", "eess.SP", "eess.SY", "stat.ML"], "title": "Model-Based Reinforcement Learning for Physical Systems Without Velocity\n  and Acceleration Measurements"}, {"abstract": "In this paper, we introduce a novel architecture to connecting adaptive\nlearning and neural networks into an arbitrary machine\u0027s control system\nparadigm. Two consecutive Recurrent Neural Networks (RNNs) are used together to\naccurately model the dynamic characteristics of electromechanical systems that\ninclude controllers, actuators and motors. The age-old method of achieving\ncontrol with the use of the- Proportional, Integral and Derivative constants is\nwell understood as a simplified method that does not capture the complexities\nof the inherent nonlinearities of complex control systems. In the context of\ncontrolling and simulating electromechanical systems, we propose an alternative\nto PID controllers, employing a sequence of two Recurrent Neural Networks. The\nfirst RNN emulates the behavior of the controller, and the second the\nactuator/motor. The second RNN when used in isolation, potentially serves as an\nadvantageous alternative to extant testing methods of electromechanical\nsystems.", "authors": ["Srikanth Chandar", "Harsha Sunder"], "category": "cs.LG", "comment": "14 pages, granted for publication in Communications in Computer and\n  Information Science (CCIS) pro...", "img": "/static/thumbs/2002.10228v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10228v2", "num_discussion": 0, "originally_published_time": "2/14/2020", "pid": "2002.10228v2", "published_time": "2/25/2020", "rawpid": "2002.10228", "tags": ["cs.LG", "cs.NE", "eess.SP"], "title": "Dynamic Systems Simulation and Control Using Consecutive Recurrent\n  Neural Networks"}, {"abstract": "We consider the problem of finding Nash equilibrium for two-player turn-based\nzero-sum games. Inspired by the AlphaGo Zero (AGZ) algorithm, we develop a\nReinforcement Learning based approach. Specifically, we propose\nExplore-Improve-Supervise (EIS) method that combines \"exploration\", \"policy\nimprovement\"\u0027 and \"supervised learning\" to find the value function and policy\nassociated with Nash equilibrium. We identify sufficient conditions for\nconvergence and correctness for such an approach. For a concrete instance of\nEIS where random policy is used for \"exploration\", Monte-Carlo Tree Search is\nused for \"policy improvement\" and Nearest Neighbors is used for \"supervised\nlearning\", we establish that this method finds an $\\varepsilon$-approximate\nvalue function of Nash equilibrium in $\\widetilde{O}(\\varepsilon^{-(d+4)})$\nsteps when the underlying state-space of the game is continuous and\n$d$-dimensional. This is nearly optimal as we establish a lower bound of\n$\\widetilde{\\Omega}(\\varepsilon^{-(d+2)})$ for any policy.", "authors": ["Devavrat Shah", "Varun Somani", "Qiaomin Xie", "Zhi Xu"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10620v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10620v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10620v1", "published_time": "2/25/2020", "rawpid": "2002.10620", "tags": ["cs.LG", "stat.ML"], "title": "On Reinforcement Learning for Turn-based Zero-sum Markov Games"}, {"abstract": "The standard objective in machine learning is to train a single model for all\nusers. However, in many learning scenarios, such as cloud computing and\nfederated learning, it is possible to learn one personalized model per user. In\nthis work, we present a systematic learning-theoretic study of personalization.\nWe propose and analyze three approaches: user clustering, data interpolation,\nand model interpolation. For all three approaches, we provide\nlearning-theoretic guarantees and efficient algorithms for which we also\ndemonstrate the performance empirically. All of our algorithms are model\nagnostic and work for any hypothesis class.", "authors": ["Yishay Mansour", "Mehryar Mohri", "Jae Ro", "Ananda Theertha Suresh"], "category": "cs.LG", "comment": "23 pages", "img": "/static/thumbs/2002.10619v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10619v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10619v1", "published_time": "2/25/2020", "rawpid": "2002.10619", "tags": ["cs.LG", "stat.ML"], "title": "Three Approaches for Personalization with Applications to Federated\n  Learning"}, {"abstract": "We study the linear subspace fitting problem in the overparameterized\nsetting, where the estimated subspace can perfectly interpolate the training\nexamples. Our scope includes the least-squares solutions to subspace fitting\ntasks with varying levels of supervision in the training data (i.e., the\nproportion of input-output examples of the desired low-dimensional mapping) and\northonormality of the vectors defining the learned operator. This flexible\nfamily of problems connects standard, unsupervised subspace fitting that\nenforces strict orthonormality with a corresponding regression task that is\nfully supervised and does not constrain the linear operator structure. This\nclass of problems is defined over a supervision-orthonormality plane, where\neach coordinate induces a problem instance with a unique pair of supervision\nlevel and softness of orthonormality constraints. We explore this plane and\nshow that the generalization errors of the corresponding subspace fitting\nproblems follow double descent trends as the settings become more supervised\nand less orthonormally constrained.", "authors": ["Yehuda Dar", "Paul Mayer", "Lorenzo Luzi", "Richard G. Baraniuk"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10614v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10614v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10614v1", "published_time": "2/25/2020", "rawpid": "2002.10614", "tags": ["cs.LG", "stat.ML"], "title": "Subspace Fitting Meets Regression: The Effects of Supervision and\n  Orthonormality Constraints on Double Descent of Generalization Errors"}, {"abstract": "Nowadays, devices are equipped with advanced sensors with higher\nprocessing/computing capabilities. Further, widespread Internet availability\nenables communication among sensing devices. As a result, vast amounts of data\nare generated on edge devices to drive Internet-of-Things (IoT), crowdsourcing,\nand other emerging technologies. The collected extensive data can be\npre-processed, scaled, classified, and finally, used for predicting future\nevents using machine learning (ML) methods. In traditional ML approaches, data\nis sent to and processed in a central server, which encounters communication\noverhead, processing delay, privacy leakage, and security issues. To overcome\nthese challenges, each client can be trained locally based on its available\ndata and by learning from the global model. This decentralized learning\nstructure is referred to as Federated Learning (FL). However, in large-scale\nnetworks, there may be clients with varying computational resource\ncapabilities. This may lead to implementation and scalability challenges for FL\ntechniques. In this paper, we first introduce some recently implemented\nreal-life applications of FL. We then emphasize on the core challenges of\nimplementing the FL algorithms from the perspective of resource limitations\n(e.g., memory, bandwidth, and energy budget) of client clients. We finally\ndiscuss open issues associated with FL and highlight future directions in the\nFL area concerning resource-constrained devices.", "authors": ["Ahmed Imteaj", "Urmish Thakker", "Shiqiang Wang", "Jian Li", "M. Hadi Amini"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10610v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10610v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10610v1", "published_time": "2/25/2020", "rawpid": "2002.10610", "tags": ["cs.LG", "cs.DC", "stat.ML"], "title": "Federated Learning for Resource-Constrained IoT Devices: Panoramas and\n  State-of-the-art"}, {"abstract": "Real world experiments are expensive, and thus it is important to reach a\ntarget in minimum number of experiments. Experimental processes often involve\ncontrol variables that changes over time. Such problems can be formulated as a\nfunctional optimisation problem. We develop a novel Bayesian optimisation\nframework for such functional optimisation of expensive black-box processes. We\nrepresent the control function using Bernstein polynomial basis and optimise in\nthe coefficient space. We derive the theory and practice required to\ndynamically adjust the order of the polynomial degree, and show how prior\ninformation about shape can be integrated. We demonstrate the effectiveness of\nour approach for short polymer fibre design and optimising learning rate\nschedules for deep networks.", "authors": ["Pratibha Vellanki", "Santu Rana", "Sunil Gupta", "David Rubin de Celis Leal", "Alessandra Sutti", "Murray Height", "Svetha Venkatesh"], "category": "cs.LG", "comment": "Submitted to AAAI 2019", "img": "/static/thumbs/1809.07260v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1809.07260v2", "num_discussion": 0, "originally_published_time": "9/19/2018", "pid": "1809.07260v2", "published_time": "2/25/2020", "rawpid": "1809.07260", "tags": ["cs.LG", "stat.ML"], "title": "Bayesian functional optimisation with shape prior"}, {"abstract": "We propose a statistical adaptive procedure called SALSA for automatically\nscheduling the learning rate (step size) in stochastic gradient methods. SALSA\nfirst uses a smoothed stochastic line-search procedure to gradually increase\nthe learning rate, then automatically switches to a statistical method to\ndecrease the learning rate. The line search procedure ``warms up\u0027\u0027 the\noptimization process, reducing the need for expensive trial and error in\nsetting an initial learning rate. The method for decreasing the learning rate\nis based on a new statistical test for detecting stationarity when using a\nconstant step size. Unlike in prior work, our test applies to a broad class of\nstochastic gradient algorithms without modification. The combined method is\nhighly robust and autonomous, and it matches the performance of the best\nhand-tuned learning rate schedules in our experiments on several deep learning\ntasks.", "authors": ["Pengchuan Zhang", "Hunter Lang", "Qiang Liu", "Lin Xiao"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/2002.10597v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10597v1", "num_discussion": 0, "originally_published_time": "2/25/2020", "pid": "2002.10597v1", "published_time": "2/25/2020", "rawpid": "2002.10597", "tags": ["stat.ML", "cs.LG"], "title": "Statistical Adaptive Stochastic Gradient Methods"}, {"abstract": "Knee Osteoarthritis (OA) is a common musculoskeletal disorder in the United\nStates. When diagnosed at early stages, lifestyle interventions such as\nexercise and weight loss can slow OA progression, but at later stages, only an\ninvasive option is available: total knee replacement (TKR). Though a generally\nsuccessful procedure, only 2/3 of patients who undergo the procedure report\ntheir knees feeling \u0027\u0027normal\u0027\u0027 post-operation, and complications can arise that\nrequire revision. This necessitates a model to identify a population at higher\nrisk of TKR, particularly at less advanced stages of OA, such that appropriate\ntreatments can be implemented that slow OA progression and delay TKR. Here, we\npresent a deep learning pipeline that leverages MRI images and clinical and\ndemographic information to predict TKR with AUC $0.834 \\pm 0.036$ (p \u003c 0.05).\nMost notably, the pipeline predicts TKR with AUC $0.943 \\pm 0.057$ (p \u003c 0.05)\nfor patients without OA. Furthermore, we develop occlusion maps for\ncase-control pairs in test data and compare regions used by the model in both,\nthereby identifying TKR imaging biomarkers. As such, this work takes strides\ntowards a pipeline with clinical utility, and the biomarkers identified further\nour understanding of OA progression and eventual TKR onset.", "authors": ["Aniket A. Tolpadi", "Jinhee J. Lee", "Valentina Pedoia", "Sharmila Majumdar"], "category": "eess.IV", "comment": "18 pages, 5 figures (4 in main article, 1 supplemental), 8 tables (5\n  in main article, 3 supplement...", "img": "/static/thumbs/2002.10591v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10591v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10591v1", "published_time": "2/24/2020", "rawpid": "2002.10591", "tags": ["eess.IV", "cs.CV", "I.4.9"], "title": "Deep learning predicts total knee replacement from magnetic resonance\n  images"}, {"abstract": "We present a Bayesian view of counterfactual risk minimization (CRM) for\noffline learning from logged bandit feedback. Using PAC-Bayesian analysis, we\nderive a new generalization bound for the truncated inverse propensity score\nestimator. We apply the bound to a class of Bayesian policies, which motivates\na novel, potentially data-dependent, regularization technique for CRM.\nExperimental results indicate that this technique outperforms standard $L_2$\nregularization, and that it is competitive with variance regularization while\nbeing both simpler to implement and more computationally efficient.", "authors": ["Ben London", "Ted Sandler"], "category": "cs.LG", "comment": "Extended version of the paper published at the 2019 International\n  Conference on Machine Learning (...", "img": "/static/thumbs/1806.11500v5.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.11500v5", "num_discussion": 0, "originally_published_time": "6/29/2018", "pid": "1806.11500v5", "published_time": "2/24/2020", "rawpid": "1806.11500", "tags": ["cs.LG", "stat.ML"], "title": "Bayesian Counterfactual Risk Minimization"}, {"abstract": "Model distillation aims to distill the knowledge of a complex model into a\nsimpler one. In this paper, we consider an alternative formulation called\ndataset distillation: we keep the model fixed and instead attempt to distill\nthe knowledge from a large training dataset into a small one. The idea is to\nsynthesize a small number of data points that do not need to come from the\ncorrect data distribution, but will, when given to the learning algorithm as\ntraining data, approximate the model trained on the original data. For example,\nwe show that it is possible to compress 60,000 MNIST training images into just\n10 synthetic distilled images (one per class) and achieve close to original\nperformance with only a few gradient descent steps, given a fixed network\ninitialization. We evaluate our method in various initialization settings and\nwith different learning objectives. Experiments on multiple datasets show the\nadvantage of our approach compared to alternative methods.", "authors": ["Tongzhou Wang", "Jun-Yan Zhu", "Antonio Torralba", "Alexei A. Efros"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1811.10959v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1811.10959v3", "num_discussion": 0, "originally_published_time": "11/27/2018", "pid": "1811.10959v3", "published_time": "2/24/2020", "rawpid": "1811.10959", "tags": ["cs.LG", "stat.ML"], "title": "Dataset Distillation"}, {"abstract": "In this paper, we propose and analyze SPARQ-SGD, which is an event-triggered\nand compressed algorithm for decentralized training of large-scale machine\nlearning models. Each node can locally compute a condition (event) which\ntriggers a communication where quantized and sparsified local model parameters\nare sent. In SPARQ-SGD each node takes at least a fixed number ($H$) of local\ngradient steps and then checks if the model parameters have significantly\nchanged compared to its last update; it communicates further compressed model\nparameters only when there is a significant change, as specified by a (design)\ncriterion. We prove that the SPARQ-SGD converges as $O(\\frac{1}{nT})$ and\n$O(\\frac{1}{\\sqrt{nT}})$ in the strongly-convex and non-convex settings,\nrespectively, demonstrating that such aggressive compression, including\nevent-triggered communication, model sparsification and quantization does not\naffect the overall convergence rate as compared to uncompressed decentralized\ntraining; thereby theoretically yielding communication efficiency for \"free\".\nWe evaluate SPARQ-SGD over real datasets to demonstrate significant amount of\nsavings in communication over the state-of-the-art.", "authors": ["Navjot Singh", "Deepesh Data", "Jemin George", "Suhas Diggavi"], "category": "stat.ML", "comment": "41 pages, 4 figures", "img": "/static/thumbs/1910.14280v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1910.14280v2", "num_discussion": 0, "originally_published_time": "10/31/2019", "pid": "1910.14280v2", "published_time": "2/24/2020", "rawpid": "1910.14280", "tags": ["stat.ML", "cs.DC", "cs.LG", "math.OC"], "title": "SPARQ-SGD: Event-Triggered and Compressed Communication in Decentralized\n  Stochastic Optimization"}, {"abstract": "Ergonomic analysis of human posture plays a vital role in understanding\nlong-term, work-related safety and health. Current analysis is often hindered\ndue to difficulties in estimating human posture. We introduce a new approach to\nthe problem of human posture estimation for teleoperation tasks which relies\nsolely on a haptic-input device for generating observations. We model the human\nupper body using a redundant, partially observable dynamical system. This\nallows us to naturally formulate the estimation problem as probabilistic\ninference and solve the inference problem using a standard particle filter. We\nshow that our approach accurately estimates the posture of different human\nusers without knowing their specific segment lengths. We evaluate our posture\nestimation approach from a haptic-input device by comparing it with the human\nposture estimates from a commercial motion capture system. Our results show\nthat the proposed algorithm successfully estimates human posture based only on\nthe trajectory of the haptic-input device stylus. We additionally show that\nergonomic risk estimates derived from our posture estimation approach are\ncomparable to those estimates from gold-standard, motion-capture based pose\nestimates.", "authors": ["Amir Yazdani", "Roya Sabbagh Novin", "Andrew Merryweather", "Tucker Hermans"], "category": "cs.RO", "comment": "", "img": "/static/thumbs/2002.10586v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10586v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10586v1", "published_time": "2/24/2020", "rawpid": "2002.10586", "tags": ["cs.RO", "cs.HC", "eess.SP"], "title": "Estimating Human Teleoperator Posture Using Only a Haptic-Input Device"}, {"abstract": "The impressive lifelong learning in animal brains is primarily enabled by\nplastic changes in synaptic connectivity. Importantly, these changes are not\npassive, but are actively controlled by neuromodulation, which is itself under\nthe control of the brain. The resulting self-modifying abilities of the brain\nplay an important role in learning and adaptation, and are a major basis for\nbiological reinforcement learning. Here we show for the first time that\nartificial neural networks with such neuromodulated plasticity can be trained\nwith gradient descent. Extending previous work on differentiable Hebbian\nplasticity, we propose a differentiable formulation for the neuromodulation of\nplasticity. We show that neuromodulated plasticity improves the performance of\nneural networks on both reinforcement learning and supervised learning tasks.\nIn one task, neuromodulated plastic LSTMs with millions of parameters\noutperform standard LSTMs on a benchmark language modeling task (controlling\nfor the number of parameters). We conclude that differentiable neuromodulation\nof plasticity offers a powerful new framework for training neural networks.", "authors": ["Thomas Miconi", "Aditya Rawal", "Jeff Clune", "Kenneth O. Stanley"], "category": "cs.NE", "comment": "Presented at the 7th International Conference on Learning\n  Representations (ICLR 2019)", "img": "/static/thumbs/2002.10585v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10585v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10585v1", "published_time": "2/24/2020", "rawpid": "2002.10585", "tags": ["cs.NE"], "title": "Backpropamine: training self-modifying neural networks with\n  differentiable neuromodulated plasticity"}, {"abstract": "Stochastic gradient descent (SGD) with constant momentum and its variants\nsuch as Adam are the optimization algorithms of choice for training deep neural\nnetworks (DNNs). Since DNN training is incredibly computationally expensive,\nthere is great interest in speeding up convergence. Nesterov accelerated\ngradient (NAG) improves the convergence rate of gradient descent (GD) for\nconvex optimization using a specially designed momentum; however, it\naccumulates error when an inexact gradient is used (such as in SGD), slowing\nconvergence at best and diverging at worst. In this paper, we propose Scheduled\nRestart SGD (SRSGD), a new NAG-style scheme for training DNNs. SRSGD replaces\nthe constant momentum in SGD by the increasing momentum in NAG but stabilizes\nthe iterations by resetting the momentum to zero according to a schedule. Using\na variety of models and benchmarks for image classification, we demonstrate\nthat, in training DNNs, SRSGD significantly improves convergence and\ngeneralization; for instance in training ResNet200 for ImageNet classification,\nSRSGD achieves an error rate of 20.93% vs. the benchmark of 22.13%. These\nimprovements become more significant as the network grows deeper. Furthermore,\non both CIFAR and ImageNet, SRSGD reaches similar or even better error rates\nwith fewer training epochs compared to the SGD baseline. We provide code for\nSRSGD at https://github.com/minhtannguyen/SRSGD.", "authors": ["Bao Wang", "Tan M. Nguyen", "Andrea L. Bertozzi", "Richard G. Baraniuk", "Stanley J. Osher"], "category": "cs.LG", "comment": "20 pages, 13 figures, 15 tables", "img": "/static/thumbs/2002.10583v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10583v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10583v1", "published_time": "2/24/2020", "rawpid": "2002.10583", "tags": ["cs.LG", "cs.NE", "stat.ML"], "title": "Scheduled Restart Momentum for Accelerated Stochastic Gradient Descent"}, {"abstract": "Adversarially robust machine learning has received much recent attention.\nHowever, prior attacks and defenses for non-parametric classifiers have been\ndeveloped in an ad-hoc or classifier-specific basis. In this work, we take a\nholistic look at adversarial examples for non-parametric classifiers, including\nnearest neighbors, decision trees, and random forests. We provide a general\ndefense method, adversarial pruning, that works by preprocessing the dataset to\nbecome well-separated. To test our defense, we provide a novel attack that\napplies to a wide range of non-parametric classifiers. Theoretically, we derive\nan optimally robust classifier, which is analogous to the Bayes Optimal. We\nshow that adversarial pruning can be viewed as a finite sample approximation to\nthis optimal classifier. We empirically show that our defense and attack are\neither better than or competitive with prior work on non-parametric\nclassifiers. Overall, our results provide a strong and broadly-applicable\nbaseline for future work on robust non-parametrics. Code available at\nhttps://github.com/yangarbiter/adversarial-nonparametrics/ .", "authors": ["Yao-Yuan Yang", "Cyrus Rashtchian", "Yizhen Wang", "Kamalika Chaudhuri"], "category": "cs.LG", "comment": "AISTATS 2020", "img": "/static/thumbs/1906.03310v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1906.03310v2", "num_discussion": 0, "originally_published_time": "6/7/2019", "pid": "1906.03310v2", "published_time": "2/24/2020", "rawpid": "1906.03310", "tags": ["cs.LG", "cs.CR", "cs.DS", "stat.ML"], "title": "Robustness for Non-Parametric Classification: A Generic Attack and\n  Defense"}, {"abstract": "With the advent of electronic interaction, dominance (or the assertion of\ncontrol over others) has acquired new dimensions. This study investigates the\ndynamics and characteristics of dominance in virtual interaction by analyzing\nelectronic chat transcripts of groups solving a hidden profile task. We\ninvestigate computer-mediated communication behavior patterns that demonstrate\ndominance and identify a number of relevant variables. These indicators are\ncalculated with automatic and manual coding of text transcripts. A comparison\nof both sets of variables indicates that automatic text analysis methods yield\nsimilar conclusions than manual coding. These findings are encouraging to\nadvance research in text analysis methods in general, and in the study of\nvirtual team dominance in particular.", "authors": ["Jim Samuel", "Richard Holowczak", "Raquel Benbunan-Fich", "Ilan Levine"], "category": "cs.SI", "comment": "", "img": "/static/thumbs/2002.10582v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10582v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10582v1", "published_time": "2/24/2020", "rawpid": "2002.10582", "tags": ["cs.SI", "cs.CL"], "title": "Automating Discovery of Dominance in Synchronous Computer-Mediated\n  Communication"}, {"abstract": "Many physical scenarios are naturally modeled as a set of multiple\nco-evolving systems. Recently, research in stochastic thermodynamics has\nconsidered such scenarios, e.g., by modeling the co-evolution of the systems as\na Bayes net. In particular, we now have a fluctuation theorem relating the\nentropy production of one of the systems in a Bayes net to the overall\nstructure of the Bayes net. Here I extend this recent research in four ways.\nFirst, I derive fluctuation theorems concerning arbitrary subsets of the\nsystems in the Bayes net. Second, I derive ``conditional\u0027\u0027 fluctuation theorems\n, governing the probability distribution of entropy production in an arbitrary\nsubset of the systems, conditioned on the entropy production in a different\nsubset of the systems. I then derive thermodynamic uncertainty relations\nrelating the total entropy production of all the systems in the Bayes net to\nthe set of all the precisions of probability currents within the individual\nsystems. I end with an example.", "authors": ["David H. Wolpert"], "category": "cond-mat.stat-mech", "comment": "14 pages, 0 figures - typos fixed from earlier version", "img": "/static/thumbs/1911.02700v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1911.02700v3", "num_discussion": 0, "originally_published_time": "11/7/2019", "pid": "1911.02700v3", "published_time": "2/24/2020", "rawpid": "1911.02700", "tags": ["cond-mat.stat-mech", "cs.LG", "stat.ML"], "title": "Uncertainty relations and fluctuation theorems for Bayes nets"}, {"abstract": "We turn the definition of individual fairness on its head---rather than\nascertaining the fairness of a model given a predetermined metric, we find a\nmetric for a given model that satisfies individual fairness. This can\nfacilitate the discussion on the fairness of a model, addressing the issue that\nit may be difficult to specify a priori a suitable metric. Our contributions\nare twofold: First, we introduce the definition of a minimal metric and\ncharacterize the behavior of models in terms of minimal metrics. Second, for\nmore complicated models, we apply the mechanism of randomized smoothing from\nadversarial robustness to make them individually fair under a given weighted\n$L^p$ metric. Our experiments show that adapting the minimal metrics of linear\nmodels to more complicated neural networks can lead to meaningful and\ninterpretable fairness guarantees at little cost to utility.", "authors": ["Samuel Yeom", "Matt Fredrikson"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.07738v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.07738v2", "num_discussion": 0, "originally_published_time": "2/18/2020", "pid": "2002.07738v2", "published_time": "2/24/2020", "rawpid": "2002.07738", "tags": ["cs.LG", "stat.ML"], "title": "Individual Fairness Revisited: Transferring Techniques from Adversarial\n  Robustness"}, {"abstract": "In this paper, a novel framework is proposed to optimize the downlink\nmulti-user communication of a millimeter wave base station, which is assisted\nby a reconfigurable intelligent reflector (IR). In particular, a channel\nestimation approach is developed to measure the channel state information (CSI)\nin real-time. First, for a perfect CSI scenario, the optimal precoding\ntransmission and power allocation is derived so as to maximize the sum of\ndownlink rates towards multiple users, followed by the optimization of IR\nreflection coefficient to enhance the upper bound of the downlink transmission.\nNext, in the imperfect CSI scenario, a distributional reinforcement learning\n(DRL) approach is proposed to learn the optimal IR reflection and maximize the\nexpectation of downlink capacity. In order to model the transmission rate\u0027s\nprobability distribution, a learning algorithm, based on quantile regression\n(QR), is developed, and the proposed QR-DRL method is proved to converge to a\nstable distribution of downlink transmission rate. Simulation results show\nthat, in the error-free CSI scenario, the proposed transmission approach yields\nover 20% and 2-fold increase in the downlink sum-rate, compared with a fixed IR\nreflection scheme and direct transmission scheme, respectively. Simulation\nresults also show that by increasing the number of IR components, the downlink\nrate can be improved faster than by increasing the number of antennas at the\nBS. Furthermore, under limited knowledge of CSI, simulation results show that\nthe proposed QR-DRL method, which learns a full distribution of the downlink\nrate, yields a better prediction accuracy and improves the downlink rate by 10%\nfor online deployments, compared with a Q-learning baseline.", "authors": ["Qianqian Zhang", "Walid Saad", "Mehdi Bennis"], "category": "cs.IT", "comment": "", "img": "/static/thumbs/2002.10572v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10572v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10572v1", "published_time": "2/24/2020", "rawpid": "2002.10572", "tags": ["cs.IT", "cs.LG", "math.IT"], "title": "Millimeter Wave Communications with an Intelligent Reflector:\n  Performance Optimization and Distributional Reinforcement Learning"}, {"abstract": "Semantic segmentation has made striking progress due to the success of deep\nconvolutional neural networks. Considering the demand of autonomous driving,\nreal-time semantic segmentation has become a research hotspot these years.\nHowever, few real-time RGB-D fusion semantic segmentation studies are carried\nout despite readily accessible depth information nowadays. In this paper, we\npropose a real-time fusion semantic segmentation network termed RFNet that\nefficiently exploits complementary features from depth information to enhance\nthe performance in an attention-augmented way, while running swiftly that is a\nnecessity for autonomous vehicles applications. Multi-dataset training is\nleveraged to incorporate unexpected small obstacle detection, enriching the\nrecognizable classes required to face unforeseen hazards in the real world. A\ncomprehensive set of experiments demonstrates the effectiveness of our\nframework. On \\textit{Cityscapes}, Our method outperforms previous\nstate-of-the-art semantic segmenters, with excellent accuracy and 22Hz\ninference speed at the full 2048$\\times$1024 resolution, outperforming most\nexisting RGB-D networks.", "authors": ["Lei Sun", "Kailun Yang", "Xinxin Hu", "Weijian Hu", "Kaiwei Wang"], "category": "cs.CV", "comment": "7 figures, 3 tables, submitted to RA-L with IROS2020", "img": "/static/thumbs/2002.10570v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10570v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10570v1", "published_time": "2/24/2020", "rawpid": "2002.10570", "tags": ["cs.CV", "cs.RO", "eess.IV"], "title": "Real-time Fusion Network for RGB-D Semantic Segmentation Incorporating\n  Unexpected Obstacle Detection for Road-driving Images"}, {"abstract": "Human motion prediction is a stochastic process: Given an observed sequence\nof poses, multiple future motions are plausible. Existing approaches to\nmodeling this stochasticity typically combine a random noise vector with\ninformation about the previous poses. This combination, however, is done in a\ndeterministic manner, which gives the network the flexibility to learn to\nignore the random noise. In this paper, we introduce an approach to\nstochastically combine the root of variations with previous pose information,\nwhich forces the model to take the noise into account. We exploit this idea for\nmotion prediction by incorporating it into a recurrent encoder-decoder network\nwith a conditional variational autoencoder block that learns to exploit the\nperturbations. Our experiments demonstrate that our model yields high-quality\npose sequences that are much more diverse than those from state-of-the-art\nstochastic motion prediction techniques.", "authors": ["Mohammad Sadegh Aliakbarian", "Fatemeh Sadat Saleh", "Mathieu Salzmann", "Lars Petersson", "Stephen Gould", "Amirhossein Habibian"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1908.00733v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1908.00733v2", "num_discussion": 0, "originally_published_time": "8/2/2019", "pid": "1908.00733v2", "published_time": "2/24/2020", "rawpid": "1908.00733", "tags": ["cs.LG", "cs.CV", "stat.ML"], "title": "Learning Variations in Human Motion via Mix-and-Match Perturbation"}, {"abstract": "This paper studies the trajectory optimization problem for an aerial vehicle\nwith the mission of flying between a pair of given initial and final locations.\nThe objective is to minimize the travel time of the aerial vehicle ensuring\nthat the communication connectivity constraint required for the safe operation\nof the aerial vehicle is satisfied. We consider two different criteria for the\nconnectivity constraint of the aerial vehicle which leads to two different\nscenarios. In the first scenario, we assume that the maximum continuous time\nduration that the aerial vehicle is out of the coverage of the ground base\nstations (GBSs) is limited to a given threshold. In the second scenario,\nhowever, we assume that the total time periods that the aerial vehicle is not\ncovered by the GBSs is restricted. Based on these two constraints, we formulate\ntwo trajectory optimization problems. To solve these non-convex problems, we\nuse an approach based on the double Q-learning method which is a model-free\nreinforcement learning technique and unlike the existing algorithms does not\nneed perfect knowledge of the environment. Moreover, in contrast to the\nwell-known Q-learning technique, our double Q-learning algorithm does not\nsuffer from the over-estimation issue. Simulation results show that although\nour algorithm does not require prior information of the environment, it works\nwell and shows near optimal performance.", "authors": ["Behzad Khamidehi", "Elvino S. Sousa"], "category": "cs.AI", "comment": "Accepted to appear in IEEE ICC 2020", "img": "/static/thumbs/2002.10563v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10563v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10563v1", "published_time": "2/24/2020", "rawpid": "2002.10563", "tags": ["cs.AI", "cs.NI", "eess.SP"], "title": "A Double Q-Learning Approach for Navigation of Aerial Vehicles with\n  Connectivity Constraint"}, {"abstract": "The task of using machine learning to approximate the mapping\n$\\mathbf{x}\\mapsto\\sum_{i=1}^d x_i^2$ with $x_i\\in[-1,1]$ seems to be a trivial\none. Given the knowledge of the separable structure of the function, one can\ndesign a sparse network to represent the function very accurately, or even\nexactly. When such structural information is not available, and we may only use\na dense neural network, the optimization procedure to find the sparse network\nembedded in the dense network is similar to finding the needle in a haystack,\nusing a given number of samples of the function. We demonstrate that the cost\n(measured by sample complexity) of finding the needle is directly related to\nthe Barron norm of the function. While only a small number of samples is needed\nto train a sparse network, the dense network trained with the same number of\nsamples exhibits large test loss and a large generalization gap. In order to\ncontrol the size of the generalization gap, we find that the use of explicit\nregularization becomes increasingly more important as $d$ increases. The\nnumerically observed sample complexity with explicit regularization scales as\n$\\mathcal{O}(d^{2.5})$, which is in fact better than the theoretically\npredicted sample complexity that scales as $\\mathcal{O}(d^{4})$. Without\nexplicit regularization (also called implicit regularization), the numerically\nobserved sample complexity is significantly higher and is close to\n$\\mathcal{O}(d^{4.5})$.", "authors": ["Jiefu Zhang", "Leonardo Zepeda-N\u00fa\u00f1ez", "Yuan Yao", "Lin Lin"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10561v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10561v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10561v1", "published_time": "2/24/2020", "rawpid": "2002.10561", "tags": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "title": "Learning the mapping $\\mathbf{x}\\mapsto \\sum_{i=1}^d x_i^2$: the cost of\n  finding the needle in a haystack"}, {"abstract": "Mining the shared features of same identity in different scene, and the\nunique features of different identity in same scene, are most significant\nchallenges in the field of person re-identification (ReID). Online Instance\nMatching (OIM) loss function and Triplet loss function are main methods for\nperson ReID. Unfortunately, both of them have drawbacks. OIM loss treats all\nsamples equally and puts no emphasis on hard samples. Triplet loss processes\nbatch construction in a complicated and fussy way and converges slowly. For\nthese problems, we propose a Triplet Online Instance Matching (TOIM) loss\nfunction, which lays emphasis on the hard samples and improves the accuracy of\nperson ReID effectively. It combines the advantages of OIM loss and Triplet\nloss and simplifies the process of batch construction, which leads to a more\nrapid convergence. It can be trained on-line when handle the joint detection\nand identification task. To validate our loss function, we collect and annotate\na large-scale benchmark dataset (UESTC-PR) based on images taken from\nsurveillance cameras, which contains 499 identities and 60,437 images. We\nevaluated our proposed loss function on Duke, Marker-1501 and UESTC-PR using\nResNet-50, and the result shows that our proposed loss function outperforms the\nbaseline methods by a maximum of 21.7%, including Softmax loss, OIM loss and\nTriplet loss.", "authors": ["Ye Li", "Guangqiang Yin", "Chunhui Liu", "Xiaoyu Yang", "Zhiguo Wang"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/2002.10560v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10560v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10560v1", "published_time": "2/24/2020", "rawpid": "2002.10560", "tags": ["cs.CV"], "title": "Triplet Online Instance Matching Loss for Person Re-identification"}, {"abstract": "Physics-informed deep learning (PIDL) has drawn tremendous interest in recent\nyears to solve computational physics problems. The basic concept of PIDL is to\nembed available physical laws to constrain/inform neural networks, with the\nneed of less rich data for training a reliable model. This can be achieved by\nincorporating the residual of the partial differential equations and the\ninitial/boundary conditions into the loss function. Through minimizing the loss\nfunction, the neural network would be able to approximate the solution to the\nphysical field of interest. In this paper, we propose a mixed-variable scheme\nof physics-informed neural network (PINN) for fluid dynamics and apply it to\nsimulate steady and transient laminar flows at low Reynolds numbers. The\npredicted velocity and pressure fields by the proposed PINN approach are\ncompared with the reference numerical solutions. Simulation results demonstrate\ngreat potential of the proposed PINN for fluid flow simulation with a high\naccuracy.", "authors": ["Chengping Rao", "Hao Sun", "Yang Liu"], "category": "physics.flu-dyn", "comment": "5 Pages and 7 Figures", "img": "/static/thumbs/2002.10558v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10558v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10558v1", "published_time": "2/24/2020", "rawpid": "2002.10558", "tags": ["physics.flu-dyn", "cs.LG", "physics.comp-ph"], "title": "Physics-informed deep learning for incompressible laminar flows"}, {"abstract": "We develop exact representations of two layer neural networks with rectified\nlinear units in terms of a single convex program with number of variables\npolynomial in the number of training samples and number of hidden neurons. Our\ntheory utilizes semi-infinite duality and minimum norm regularization.\nMoreover, we show that certain standard multi-layer convolutional neural\nnetworks are equivalent to L1 regularized linear models in a polynomial sized\ndiscrete Fourier feature space. We also introduce exact semi-definite\nprogramming representations of convolutional and fully connected linear\nmulti-layer networks which are polynomial size in both the sample size and\ndimension.", "authors": ["Mert Pilanci", "Tolga Ergen"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.10553v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10553v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10553v1", "published_time": "2/24/2020", "rawpid": "2002.10553", "tags": ["cs.LG", "cs.CC", "stat.ML"], "title": "Neural Networks are Convex Regularizers: Exact Polynomial-time Convex\n  Optimization Formulations for Two-Layer Networks"}, {"abstract": "Learning rich representation from data is an important task for deep\ngenerative models such as variational auto-encoder (VAE). However, by\nextracting high-level abstractions in the bottom-up inference process, the goal\nof preserving all factors of variations for top-down generation is compromised.\nMotivated by the concept of \"starting small\", we present a strategy to\nprogressively learn independent hierarchical representations from high- to\nlow-levels of abstractions. The model starts with learning the most abstract\nrepresentation, and then progressively grow the network architecture to\nintroduce new representations at different levels of abstraction. We\nquantitatively demonstrate the ability of the presented model to improve\ndisentanglement in comparison to existing works on two benchmark data sets\nusing three disentanglement metrics, including a new metric we proposed to\ncomplement the previously-presented metric of mutual information gap. We\nfurther present both qualitative and quantitative evidence on how the\nprogression of learning improves disentangling of hierarchical representations.\nBy drawing on the respective advantage of hierarchical representation learning\nand progressive learning, this is to our knowledge the first attempt to improve\ndisentanglement by progressively growing the capacity of VAE to learn\nhierarchical representations.", "authors": ["Zhiyuan Li", "Jaideep Vitthal Murkute", "Prashnna Kumar Gyawali", "Linwei Wang"], "category": "cs.LG", "comment": "Main text: 9 pages, 7 figures. Supplements: 4 pages", "img": "/static/thumbs/2002.10549v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.10549v1", "num_discussion": 0, "originally_published_time": "2/24/2020", "pid": "2002.10549v1", "published_time": "2/24/2020", "rawpid": "2002.10549", "tags": ["cs.LG", "cs.CV", "stat.ML"], "title": "Progressive Learning and Disentanglement of Hierarchical Representations"}, {"abstract": "We propose \\emph{Taylorized training} as an initiative towards better\nunderstanding neural network training at finite width. Taylorized training\ninvolves training the $k$-th order Taylor expansion of the neural network at\ninitialization, and is a principled extension of linearized training---a\nrecently proposed theory for understanding the success of deep learning.\n  We experiment with Taylorized training on modern neural network\narchitectures, and show that Taylorized training (1) agrees with full neural\nnetwork training increasingly better as we increase $k$, and (2) can\nsignificantly close the performance gap between linearized and full training.\nCompared with linearized training, higher-order training works in more\nrealistic settings such as standard parameterization and large (initial)\nlearning rate. We complement our experiments with theoretical results showing\nthat the approximation error of $k$-th order Taylorized models decay\nexponentially over $k$ in wide neural networks.", "authors": ["Yu Bai", "Ben Krause", "Huan Wang", "Caiming Xiong", "Richard Socher"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/2002.04010v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/2002.04010v2", "num_discussion": 0, "originally_published_time": "2/10/2020", "pid": "2002.04010v2", "published_time": "2/24/2020", "rawpid": "2002.04010", "tags": ["cs.LG", "stat.ML"], "title": "Taylorized Training: Towards Better Approximation of Neural Network\n  Training at Finite Width"}];
var pid_to_users = {};
var msg = "Showing most recent Arxiv papers:";
var render_format = "recent";
var username = "";
var numresults = "98923";
var show_prompt = "no";

var urlq = ''; // global will be read in to QueryString when load is done

// when page loads...
$(document).ready(function(){

	urlq = QueryString.q;

  // display message, if any
  if(msg !== '') { d3.select("#rtable").append('div').classed('msg', true).html(msg); }

  // add papers to #rtable
	var done = addPapers(10, false);
  if(done) { $("#loadmorebtn").hide(); }

  // set up inifinite scrolling for adding more papers
  $(window).on('scroll', function(){
    var scrollTop = $(document).scrollTop();
    var windowHeight = $(window).height();
    var bodyHeight = $(document).height() - windowHeight;
    var scrollPercentage = (scrollTop / bodyHeight);
    if(scrollPercentage > 0.9) {
      var done = addPapers(5, true);
      if(done) { $("#loadmorebtn").hide(); }
    }
  });

  // just in case scrolling is broken somehow, provide a button handler explicit
  $("#loadmorebtn").on('click', function(){
    var done = addPapers(5, true);
    if(done) { $("#loadmorebtn").hide(); }
  });

  if(papers.length === 0) { $("#loadmorebtn").hide(); }

	if(!(typeof urlq == 'undefined')) {
		d3.select("#qfield").attr('value', urlq.replace(/\+/g, " "));
	}

  var vf = QueryString.vfilter; if(typeof vf === 'undefined') { vf = 'all'; }
  var tf = QueryString.timefilter; if(typeof tf === 'undefined') { tf = 'week'; }
  var link_endpoint = '/';
  if(render_format === 'recent') { link_endpoint = ''; }
  if(render_format === 'top') { link_endpoint = 'top'; }
  if(render_format === 'recommend') { link_endpoint = 'recommend'; }
  if(render_format === 'friends') { link_endpoint = 'friends'; }
  if(render_format === 'toptwtr') { link_endpoint = 'toptwtr'; }
  if(render_format === 'discussions') { link_endpoint = 'discussions'; }

  var time_ranges = ['day', '3days', 'week', 'month', 'year', 'alltime'];
  var time_txt = {'day':'Last day', '3days': 'Last 3 days', 'week': 'Last week', 'month': 'Last month', 'year': 'Last year', 'alltime': 'All time'}
  var time_range = tf;

  // set up time filtering options
  if(render_format === 'recommend' || render_format === 'top' || render_format === 'recent' || render_format === 'friends') {
    // insert version filtering options for these views
    var elt = d3.select('#recommend-time-choice');
    var vflink = vf === 'all' ? '1' : 'all'; // toggle only showing v1 or not
    if(render_format === 'recent') {
      var aelt = elt.append('a').attr('href', '/'+link_endpoint+'?'+'&vfilter='+vflink); // leave out timefilter from this page
    } else {
      var aelt = elt.append('a').attr('href', '/'+link_endpoint+'?'+'timefilter='+time_range+'&vfilter='+vflink);
    }
    var delt = aelt.append('div').classed('vchoice', true).html('Only show v1');
    if(vf === '1') { delt.classed('vchoice-selected', true); }
  }

  // time choices for recommend/top
  if(render_format === 'recommend' || render_format === 'top' || render_format === 'friends') {
    // insert time filtering options for these two views
    var elt = d3.select('#recommend-time-choice');
    elt.append('div').classed('fdivider', true).html('|');
    for(var i=0;i<time_ranges.length;i++) {
      var time_range = time_ranges[i];
      var aelt = elt.append('a').attr('href', '/'+link_endpoint+'?'+'timefilter='+time_range+'&vfilter='+vf);
      var delt = aelt.append('div').classed('timechoice', true).html(time_txt[time_range]);
      if(tf == time_range) { delt.classed('timechoice-selected', true); } // also render as chosen
    }
  }

  // time choices for top tweets
  if(render_format === 'toptwtr') {
    var tf = QueryString.timefilter; if(typeof tf === 'undefined') { tf = 'day'; } // default here is day
    var time_ranges = ['day', 'week', 'month'];
    var elt = d3.select('#recommend-time-choice');
    for(var i=0;i<time_ranges.length;i++) {
      var time_range = time_ranges[i];
      var aelt = elt.append('a').attr('href', '/'+link_endpoint+'?'+'timefilter='+time_range);
      var delt = aelt.append('div').classed('timechoice', true).html(time_txt[time_range]);
      if(tf == time_range) { delt.classed('timechoice-selected', true); } // also render as chosen
    }
  }

  var xb = $("#xbanner");
  if(xb.length !== 0) {
    xb.click(function(){ $("#banner").slideUp('fast'); })
  }

  // in top tab: color current choice
  if( render_format === 'recent') { d3.select('#tabrecent').classed('tab-selected', true); }
  if( render_format === 'top') { d3.select('#tabtop').classed('tab-selected', true); }
  if( render_format === 'toptwtr') { d3.select('#tabtwtr').classed('tab-selected', true); }
  if( render_format === 'friends') { d3.select('#tabfriends').classed('tab-selected', true); }
  if( render_format === 'discussions') { d3.select('#tabdiscussions').classed('tab-selected', true); }
  if( render_format === 'recommend') { d3.select('#tabrec').classed('tab-selected', true); }
  if( render_format === 'library') { d3.select('#tablib').classed('tab-selected', true); }

  $("#goaway").on('click', function(){
    $("#prompt").slideUp('fast');
    $.post("/goaway", {}).done(function(data){ });
  });
});

</script>
</head>

<body>
<a href="https://github.com/karpathy/arxiv-sanity-preserver"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/38ef81f8aca64bb9a64448d0d70f1308ef5341ab/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6461726b626c75655f3132313632312e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png"></a>

<div id ="titdiv">

  <!-- User account information on top right -->
  <div id="userinfo">
    
    <form action="/login" method="post">
      User:
      <input type="text" name="username" class="input-no-border">
      Pass:
      <input type="password" name="password" class="input-no-border">
      <input type="submit" value="Login or Create" class="btn-fancy">
    </form>
    
  </div>

  <!-- Site information/banner on top left -->
	<a href="/">
	<div id="tittxt">
		<h1>Arxiv Sanity Preserver</h1>
		Built in spare time by <a href="https://twitter.com/karpathy">@karpathy</a> to accelerate research.<br>
		Serving last 98923 papers from cs.[CV|CL|LG|AI|NE]/stat.ML
	</div>
	</a>
</div>

<div id="flashesdiv">

    

</div>


<div id="banner">
  <div style="float:right;cursor:pointer;" id="xbanner">X</div>
  New to arxiv-sanity? Check out the <a href="https://youtu.be/S2GY3gh6qC8" target="_blank">introduction video</a>.
</div>


<div id="sbox">
  <form action="/search" method="get">
  	<input name="q" type="text" id="qfield">
  </form>
  <div id="search_hint"></div>
</div>



<div id="pagebar">
  <div class="pagelink" id="tabrecent"><a href="/">most recent</a></div>
  <div class="pagelink" id="tabtop"><a href="/top">top recent</a></div>
  <div class="pagelink" id="tabtwtr"><a href="/toptwtr">top hype</a></div>
  <div class="pagelink" id="tabfriends"><a href="/friends">friends</a></div>
  <div class="pagelink" id="tabdiscussions"><a href="/discussions">discussions</a></div>
  <div class="pagelink" id="tabrec"><a href="/recommend">recommended</a></div>
  <div class="pagelink" id="tablib"><a href="/library">library</a></div>
</div>

<!-- this div will be rendered into dynamcially at init with JS -->
<div id="recommend-time-choice" class="centerdiv"></div>

<div id="maindiv">

<div id="rtable"></div>

<div id="loadmore">
  <button id="loadmorebtn">Load more</button>
</div>

</div>

<br><br><br><br><br><br>
</body>

</html>